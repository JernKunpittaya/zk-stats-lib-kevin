{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ezkl==5.0.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 1)) (5.0.8)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 2)) (2.1.1)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 3)) (2.31.0)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 4)) (1.11.4)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 5)) (1.26.2)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 6)) (3.8.2)\n",
      "Requirement already satisfied: statistics in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 7)) (1.0.3.5)\n",
      "Requirement already satisfied: onnx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 8)) (1.15.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.13.1)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.2.1)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (2023.10.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (1.12)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (4.8.0)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.1.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (3.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (1.4.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (4.45.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (3.1.1)\n",
      "Requirement already satisfied: docutils>=0.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from statistics->-r ../../requirements.txt (line 7)) (0.20.1)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from onnx->-r ../../requirements.txt (line 8)) (4.25.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.7->matplotlib->-r ../../requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch->-r ../../requirements.txt (line 2)) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy->torch->-r ../../requirements.txt (line 2)) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ezkl\n",
    "import torch\n",
    "from torch import nn\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export model\n",
    "def export_onnx(model, data_tensor_array, model_loc):\n",
    "  circuit = model()\n",
    "\n",
    "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "  # print(device)\n",
    "\n",
    "  circuit.to(device)\n",
    "\n",
    "  # Flips the neural net into inference mode\n",
    "  circuit.eval()\n",
    "  input_names = []\n",
    "  dynamic_axes = {}\n",
    "\n",
    "  data_tensor_tuple = ()\n",
    "  for i in range(len(data_tensor_array)):\n",
    "    data_tensor_tuple += (data_tensor_array[i],)\n",
    "    input_index = \"input\"+str(i+1)\n",
    "    input_names.append(input_index)\n",
    "    dynamic_axes[input_index] = {0 : 'batch_size'}\n",
    "  dynamic_axes[\"output\"] = {0 : 'batch_size'}\n",
    "\n",
    "  # Export the model\n",
    "  torch.onnx.export(circuit,               # model being run\n",
    "                      data_tensor_tuple,                   # model input (or a tuple for multiple inputs)\n",
    "                      model_loc,            # where to save the model (can be a file or file-like object)\n",
    "                      export_params=True,        # store the trained parameter weights inside the model file\n",
    "                      opset_version=11,          # the ONNX version to export the model to\n",
    "                      do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                      input_names = input_names,   # the model's input names\n",
    "                      output_names = ['output'], # the model's output names\n",
    "                      dynamic_axes=dynamic_axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode is either \"accuracy\" or \"resources\"\n",
    "\n",
    "def gen_settings(comb_data_path, onnx_filename, scale, mode, settings_filename):\n",
    "  print(\"==== Generate & Calibrate Setting ====\")\n",
    "  # Set input to be Poseidon Hash, and param of computation graph to be public\n",
    "  # Poseidon is not homomorphic additive, maybe consider Pedersens or Dory commitment.\n",
    "  gip_run_args = ezkl.PyRunArgs()\n",
    "  gip_run_args.input_visibility = \"hashed\"  # matrix and generalized inverse commitments\n",
    "  gip_run_args.output_visibility = \"public\"   # no parameters used\n",
    "  gip_run_args.param_visibility = \"private\" # should be Tensor(True)--> to enforce arbitrary data in w\n",
    "\n",
    " # generate settings\n",
    "  ezkl.gen_settings(onnx_filename, settings_filename, py_run_args=gip_run_args)\n",
    "  if scale ==\"default\":\n",
    "    ezkl.calibrate_settings(\n",
    "    comb_data_path, onnx_filename, settings_filename, mode)\n",
    "  else:\n",
    "    ezkl.calibrate_settings(\n",
    "    comb_data_path, onnx_filename, settings_filename, mode, scales = scale)\n",
    "\n",
    "  assert os.path.exists(settings_filename)\n",
    "  assert os.path.exists(comb_data_path)\n",
    "  assert os.path.exists(onnx_filename)\n",
    "  f_setting = open(settings_filename, \"r\")\n",
    "  print(\"scale: \", scale)\n",
    "  print(\"setting: \", f_setting.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifier_init(verifier_model, verifier_model_path, verifier_compiled_model_path, dummy_data_path_array, settings_path, srs_path, pk_path, vk_path, scale, mode):\n",
    "\n",
    "  # load data from dummy_data_path_array into dummy_data_array\n",
    "  dummy_data_tensor_array = []\n",
    "  comb_dummy_data = []\n",
    "  for path in dummy_data_path_array:\n",
    "    dummy_data = np.array(json.loads(open(path, \"r\").read())[\"input_data\"][0])\n",
    "    # print(\"dumm: \", dummy_data)\n",
    "    dummy_data_tensor_array.append(torch.reshape(torch.tensor(dummy_data), (1, len(dummy_data),1 )))\n",
    "    comb_dummy_data.append(dummy_data.tolist())\n",
    "  # export onnx file\n",
    "  export_onnx(verifier_model,dummy_data_tensor_array, verifier_model_path)\n",
    "\n",
    "  comb_dummy_data_path = os.path.join('generated/comb_dummy_data.json')\n",
    "  # Serialize data into file:\n",
    "  json.dump(dict(input_data = comb_dummy_data), open(comb_dummy_data_path, 'w' ))\n",
    "\n",
    "  # gen + calibrate setting\n",
    "  gen_settings(comb_dummy_data_path, verifier_model_path, scale, mode, settings_path)\n",
    "\n",
    "  # compile circuit\n",
    "  res = ezkl.compile_circuit(verifier_model_path, verifier_compiled_model_path, settings_path)\n",
    "  assert res == True\n",
    "\n",
    "  # srs path\n",
    "  res = ezkl.get_srs(srs_path, settings_path)\n",
    "\n",
    "  # setupt vk, pk param for use..... prover can use same pk or can init their own!\n",
    "  print(\"==== setting up ezkl ====\")\n",
    "  start_time = time.time()\n",
    "  res = ezkl.setup(\n",
    "        verifier_compiled_model_path,\n",
    "        vk_path,\n",
    "        pk_path,\n",
    "        srs_path)\n",
    "  end_time = time.time()\n",
    "  time_setup = end_time -start_time\n",
    "  print(f\"Time setup: {time_setup} seconds\")\n",
    "\n",
    "  assert res == True\n",
    "  assert os.path.isfile(vk_path)\n",
    "  assert os.path.isfile(pk_path)\n",
    "  assert os.path.isfile(settings_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prover_gen(prover_model, data_path_array, witness_path, prover_model_path, prover_compiled_model_path, settings_path, proof_path):\n",
    "  # load data from data_path\n",
    "  # data = json.loads(open(data_path, \"r\").read())[\"input_data\"][0]\n",
    "  # data_tensor = torch.reshape(torch.tensor(data), (1, len(data),1 ))\n",
    "\n",
    "\n",
    "  data_tensor_array = []\n",
    "  comb_data = []\n",
    "  for path in data_path_array:\n",
    "    data = np.array(json.loads(open(path, \"r\").read())[\"input_data\"][0])\n",
    "    # print(\"dumm: \", dummy_data)\n",
    "    data_tensor_array.append(torch.reshape(torch.tensor(data), (1, len(data),1 )))\n",
    "    comb_data.append(data.tolist())\n",
    "\n",
    "  # export onnx file\n",
    "  export_onnx(prover_model, data_tensor_array, prover_model_path)\n",
    "\n",
    "  comb_data_path = os.path.join('generated/comb_data.json')\n",
    "  # Serialize data into file:\n",
    "  json.dump(dict(input_data = comb_data), open(comb_data_path, 'w' ))\n",
    "\n",
    "  res = ezkl.compile_circuit(prover_model_path, prover_compiled_model_path, settings_path)\n",
    "  assert res == True\n",
    "  # now generate the witness file\n",
    "  print('==== Generating Witness ====')\n",
    "  witness = ezkl.gen_witness(comb_data_path, prover_compiled_model_path, witness_path)\n",
    "  assert os.path.isfile(witness_path)\n",
    "  # print(witness[\"outputs\"])\n",
    "  settings = json.load(open(settings_path))\n",
    "  output_scale = settings['model_output_scales']\n",
    "  print(\"witness boolean: \", ezkl.vecu64_to_float(witness['outputs'][0][0], output_scale[0]))\n",
    "  for i in range(len(witness['outputs'][1])):\n",
    "    print(\"witness result\", i+1,\":\", ezkl.vecu64_to_float(witness['outputs'][1][i], output_scale[1]))\n",
    "\n",
    "  # GENERATE A PROOF\n",
    "  print(\"==== Generating Proof ====\")\n",
    "  start_time = time.time()\n",
    "  res = ezkl.prove(\n",
    "        witness_path,\n",
    "        prover_compiled_model_path,\n",
    "        pk_path,\n",
    "        proof_path,\n",
    "        srs_path,\n",
    "        \"single\",\n",
    "    )\n",
    "\n",
    "  print(\"proof: \" ,res)\n",
    "  end_time = time.time()\n",
    "  time_gen_prf = end_time -start_time\n",
    "  print(f\"Time gen prf: {time_gen_prf} seconds\")\n",
    "  assert os.path.isfile(proof_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifier_verify(proof_path, settings_path, vk_path, srs_path):\n",
    "  # enforce boolean statement to be true\n",
    "  settings = json.load(open(settings_path))\n",
    "  output_scale = settings['model_output_scales']\n",
    "\n",
    "  proof = json.load(open(proof_path))\n",
    "  num_inputs = len(settings['model_input_scales'])\n",
    "  print(\"num_inputs: \", num_inputs)\n",
    "  proof[\"instances\"][0][num_inputs] = ezkl.float_to_vecu64(1.0, output_scale[0])\n",
    "  json.dump(proof, open(proof_path, 'w'))\n",
    "\n",
    "  print(\"prf instances: \", proof['instances'])\n",
    "\n",
    "  print(\"proof boolean: \", ezkl.vecu64_to_float(proof['instances'][0][num_inputs], output_scale[0]))\n",
    "  for i in range(num_inputs+1, len(proof['instances'][0])):\n",
    "    print(\"proof result\",i-num_inputs,\":\", ezkl.vecu64_to_float(proof['instances'][0][i], output_scale[1]))\n",
    "\n",
    "\n",
    "  res = ezkl.verify(\n",
    "        proof_path,\n",
    "        settings_path,\n",
    "        vk_path,\n",
    "        srs_path,\n",
    "    )\n",
    "\n",
    "  assert res == True\n",
    "  print(\"verified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init path\n",
    "os.makedirs(os.path.dirname('generated/'), exist_ok=True)\n",
    "verifier_model_path = os.path.join('generated/verifier.onnx')\n",
    "prover_model_path = os.path.join('generated/prover.onnx')\n",
    "verifier_compiled_model_path = os.path.join('generated/verifier.compiled')\n",
    "prover_compiled_model_path = os.path.join('generated/prover.compiled')\n",
    "pk_path = os.path.join('generated/test.pk')\n",
    "vk_path = os.path.join('generated/test.vk')\n",
    "proof_path = os.path.join('generated/test.pf')\n",
    "settings_path = os.path.join('generated/settings.json')\n",
    "srs_path = os.path.join('generated/kzg.srs')\n",
    "witness_path = os.path.join('generated/witness.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=======================  ZK-STATS FLOW ======================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join('data.json')\n",
    "dummy_data_path = os.path.join('generated/dummy_data.json')\n",
    "\n",
    "f_raw_input = open(data_path, \"r\")\n",
    "data = json.loads(f_raw_input.read())[\"input_data\"][0]\n",
    "data_tensor = torch.reshape(torch.tensor(data),(1, len(data), 1))\n",
    "\n",
    "#  dummy data for data consumer: make the bound approx same as real data\n",
    "dummy_data = np.random.uniform(min(data), max(data), len(data))\n",
    "json.dump({\"input_data\":[dummy_data.tolist()]}, open(dummy_data_path, 'w'))\n",
    "\n",
    "dummy_data_tensor = torch.reshape(torch.tensor(dummy_data), (1, len(dummy_data),1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_theory_output = torch.var(dummy_data_tensor, correction = 1)\n",
    "dummy_data_mean = torch.mean(dummy_data_tensor)\n",
    "# print(dummy_theory_output)\n",
    "# print(torch.sum(torch.pow(dummy_data_tensor-torch.mean(dummy_data_tensor), 2))/(dummy_data_tensor.size()[1]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Generate & Calibrate Setting ====\n",
      "scale:  [0]\n",
      "setting:  {\"run_args\":{\"tolerance\":{\"val\":0.0,\"scale\":1.0},\"input_scale\":0,\"param_scale\":0,\"scale_rebase_multiplier\":10,\"lookup_range\":[0,39922],\"logrows\":16,\"num_inner_cols\":1,\"variables\":[[\"batch_size\",1]],\"input_visibility\":{\"Hashed\":{\"hash_is_public\":true,\"outlets\":[]}},\"output_visibility\":\"Public\",\"param_visibility\":\"Private\"},\"num_rows\":14432,\"total_assignments\":1515,\"total_const_size\":1,\"model_instance_shapes\":[[1],[1]],\"model_output_scales\":[0,0],\"model_input_scales\":[0],\"module_sizes\":{\"kzg\":[],\"poseidon\":[14432,[1]],\"elgamal\":[0,[0]]},\"required_lookups\":[\"Abs\",{\"Div\":{\"denom\":100.0}},{\"GreaterThan\":{\"a\":0.0}}],\"check_mode\":\"UNSAFE\",\"version\":\"5.0.8\",\"num_blinding_factors\":null}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== setting up ezkl ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time setup: 5.098599910736084 seconds\n"
     ]
    }
   ],
   "source": [
    "# Verifier/ data consumer side:\n",
    "class verifier_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(verifier_model, self).__init__()\n",
    "        # w represents mean in this case\n",
    "        self.w = nn.Parameter(data = dummy_theory_output, requires_grad = False)\n",
    "        self.data_mean = nn.Parameter(data = dummy_data_mean, requires_grad = False)\n",
    "\n",
    "    def forward(self,X):\n",
    "        # some expression of tolerance to error in the inference\n",
    "        return (torch.logical_and(torch.abs(torch.sum((X-self.data_mean)*(X-self.data_mean))-self.w*(X.size()[1]-1))<0.01*self.w*(X.size()[1]-1),torch.abs(torch.sum(X)-X.size()[1]*(self.data_mean))<0.01*torch.sum(X) ),self.w)\n",
    "\n",
    "verifier_init(verifier_model, verifier_model_path, verifier_compiled_model_path, [dummy_data_path], settings_path, srs_path, pk_path, vk_path,[0], \"resources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theory output:  tensor(212.5777)\n",
      "==== Generating Witness ====\n",
      "witness boolean:  1.0\n",
      "witness result 1 : 213.0\n",
      "==== Generating Proof ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proof:  {'instances': [[[10512373747352303962, 11798585516934984832, 13421675179368312123, 2200257403316998104], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287], [7791745561945701274, 3148105443081642255, 5687306643140073025, 2796439279989524607]]], 'proof': '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', 'transcript_type': 'EVM'}\n",
      "Time gen prf: 6.416290044784546 seconds\n"
     ]
    }
   ],
   "source": [
    "# Prover/ data owner side\n",
    "theory_output = torch.var(data_tensor, correction = 1)\n",
    "data_mean = torch.mean(data_tensor)\n",
    "print(\"theory output: \", theory_output)\n",
    "class prover_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(prover_model, self).__init__()\n",
    "        # w represents mean in this case\n",
    "        self.w = nn.Parameter(data = theory_output, requires_grad = False)\n",
    "        self.data_mean = nn.Parameter(data = data_mean, requires_grad = False)\n",
    "    def forward(self,X):\n",
    "        # some expression of tolerance to error in the inference\n",
    "       return (torch.logical_and(torch.abs(torch.sum((X-self.data_mean)*(X-self.data_mean))-self.w*(X.size()[1]-1))<0.01*self.w*(X.size()[1]-1),torch.abs(torch.sum(X)-X.size()[1]*(self.data_mean))<0.01*torch.sum(X)),self.w)\n",
    "prover_gen(prover_model, [data_path], witness_path, prover_model_path, prover_compiled_model_path, settings_path, proof_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_inputs:  1\n",
      "prf instances:  [[[10512373747352303962, 11798585516934984832, 13421675179368312123, 2200257403316998104], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287], [7791745561945701274, 3148105443081642255, 5687306643140073025, 2796439279989524607]]]\n",
      "proof boolean:  1.0\n",
      "proof result 1 : 213.0\n",
      "verified\n"
     ]
    }
   ],
   "source": [
    "# Verifier verifies\n",
    "verifier_verify(proof_path, settings_path, vk_path, srs_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
