{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ezkl==5.0.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 1)) (5.0.8)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 2)) (2.1.1)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 3)) (2.31.0)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 4)) (1.11.4)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 5)) (1.26.2)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 6)) (3.8.2)\n",
      "Requirement already satisfied: statistics in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 7)) (1.0.3.5)\n",
      "Requirement already satisfied: onnx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 8)) (1.15.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.13.1)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.2.1)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (2023.10.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (1.12)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (4.8.0)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.1.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (3.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (1.4.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (4.45.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (3.1.1)\n",
      "Requirement already satisfied: docutils>=0.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from statistics->-r ../../requirements.txt (line 7)) (0.20.1)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from onnx->-r ../../requirements.txt (line 8)) (4.25.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.7->matplotlib->-r ../../requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch->-r ../../requirements.txt (line 2)) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy->torch->-r ../../requirements.txt (line 2)) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ezkl\n",
    "import torch\n",
    "from torch import nn\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../../core.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init path\n",
    "os.makedirs(os.path.dirname('shared/'), exist_ok=True)\n",
    "os.makedirs(os.path.dirname('prover/'), exist_ok=True)\n",
    "verifier_model_path = os.path.join('shared/verifier.onnx')\n",
    "prover_model_path = os.path.join('prover/prover.onnx')\n",
    "verifier_compiled_model_path = os.path.join('shared/verifier.compiled')\n",
    "prover_compiled_model_path = os.path.join('prover/prover.compiled')\n",
    "pk_path = os.path.join('shared/test.pk')\n",
    "vk_path = os.path.join('shared/test.vk')\n",
    "proof_path = os.path.join('shared/test.pf')\n",
    "settings_path = os.path.join('shared/settings.json')\n",
    "srs_path = os.path.join('shared/kzg.srs')\n",
    "witness_path = os.path.join('prover/witness.json')\n",
    "# this is private to prover since it contains actual data\n",
    "comb_data_path = os.path.join('prover/comb_data.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=======================  ZK-STATS FLOW ======================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join('data.json')\n",
    "dummy_data_path = os.path.join('shared/dummy_data.json')\n",
    "\n",
    "f_raw_input = open(data_path, \"r\")\n",
    "data = json.loads(f_raw_input.read())[\"input_data\"][0]\n",
    "data_tensor = torch.reshape(torch.tensor(data),(1, len(data), 1))\n",
    "\n",
    "#  dummy data for data consumer: make the bound approx same as real data\n",
    "dummy_data = np.random.uniform(min(data), max(data), len(data))\n",
    "json.dump({\"input_data\":[dummy_data.tolist()]}, open(dummy_data_path, 'w'))\n",
    "\n",
    "dummy_data_tensor = torch.reshape(torch.tensor(dummy_data), (1, len(dummy_data),1 ))\n",
    "gt30_dummy_data_tensor = dummy_data_tensor[dummy_data_tensor > 30].reshape(1,-1,1)\n",
    "new_dummy_size = torch.tensor(gt30_dummy_data_tensor.size()[1] )\n",
    "dummy_theory_output = torch.mean(gt30_dummy_data_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/y9dw12v976ngdmqz4l7wbsnr0000gn/T/ipykernel_42565/3656555878.py:14: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  index_array = torch.tensor(range(int(len_ratio*X.size()[1])))\n",
      "/var/folders/89/y9dw12v976ngdmqz4l7wbsnr0000gn/T/ipykernel_42565/3656555878.py:14: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  index_array = torch.tensor(range(int(len_ratio*X.size()[1])))\n",
      "/var/folders/89/y9dw12v976ngdmqz4l7wbsnr0000gn/T/ipykernel_42565/3656555878.py:15: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "  for index in index_array:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check_bool:  tensor(239., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/y9dw12v976ngdmqz4l7wbsnr0000gn/T/ipykernel_42565/3656555878.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if check_bool==self.new_size:\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/onnx/utils.py:1686: UserWarning: The exported ONNX model failed ONNX shape inference. The model will not be executable by the ONNX Runtime. If this is unintended and you believe there is a bug, please report an issue at https://github.com/pytorch/pytorch/issues. Error reported by strict ONNX shape inference: [ShapeInferenceError] (op_type:ConstantOfShape, node name: /ConstantOfShape): input typestr: T1, has unsupported type: tensor(float) (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/jit/serialization/export.cpp:1421.)\n",
      "  _C._check_onnx_proto(proto)\n"
     ]
    }
   ],
   "source": [
    "# Verifier/ data consumer side: send desired calculation\n",
    "class verifier_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(verifier_model, self).__init__()\n",
    "        # w represents mean in this case\n",
    "        self.w = nn.Parameter(data = dummy_theory_output, requires_grad = False)\n",
    "        self.new_size = nn.Parameter(data = new_dummy_size,requires_grad = False )\n",
    "        self.new_X = nn.Parameter(data = gt30_dummy_data_tensor,requires_grad = False )\n",
    "\n",
    "    def forward(self,X):\n",
    "        # where part\n",
    "        len_ratio =  self.new_size/X.size()[1]\n",
    "        result = torch.zeros(len_ratio*X.size()[1]).reshape(1,-1,1)\n",
    "        index_array = torch.tensor(range(int(len_ratio*X.size()[1])))\n",
    "        for index in index_array:\n",
    "            result[0][index][0] = self.new_X[0][index][0]\n",
    "        check_bool = torch.sum((torch.abs(X[X>30].reshape(1,-1,1)-self.new_X)<0.01*self.new_X).double())\n",
    "        print(\"check_bool: \", check_bool)\n",
    "        if check_bool==self.new_size:\n",
    "            value = torch.abs(torch.sum(result)-result.size()[1]*(self.w))<0.01*result.size()[1]*(self.w)\n",
    "        else:\n",
    "            value = torch.tensor(0)\n",
    "\n",
    "        return (value, self.w)\n",
    "    \n",
    "verifier_define_calculation(verifier_model, verifier_model_path, [dummy_data_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/y9dw12v976ngdmqz4l7wbsnr0000gn/T/ipykernel_42565/2567632164.py:19: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  index_array = torch.tensor(range(int(len_ratio*X.size()[1])))\n",
      "/var/folders/89/y9dw12v976ngdmqz4l7wbsnr0000gn/T/ipykernel_42565/2567632164.py:19: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  index_array = torch.tensor(range(int(len_ratio*X.size()[1])))\n",
      "/var/folders/89/y9dw12v976ngdmqz4l7wbsnr0000gn/T/ipykernel_42565/2567632164.py:20: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "  for index in index_array:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new tensor:  torch.Size([1, 272, 1])\n",
      "Theory_output:  tensor(52.3676)\n",
      "check_bool:  tensor(272., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/y9dw12v976ngdmqz4l7wbsnr0000gn/T/ipykernel_42565/2567632164.py:24: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if check_bool==self.new_size:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Generate & Calibrate Setting ====\n",
      "scale:  [0]\n",
      "setting:  {\"run_args\":{\"tolerance\":{\"val\":0.0,\"scale\":1.0},\"input_scale\":0,\"param_scale\":0,\"scale_rebase_multiplier\":10,\"lookup_range\":[0,0],\"logrows\":14,\"num_inner_cols\":1,\"variables\":[[\"batch_size\",1]],\"input_visibility\":{\"Hashed\":{\"hash_is_public\":true,\"outlets\":[]}},\"output_visibility\":\"Public\",\"param_visibility\":\"Private\"},\"num_rows\":14432,\"total_assignments\":300,\"total_const_size\":0,\"model_instance_shapes\":[[1],[1]],\"model_output_scales\":[0,0],\"model_input_scales\":[0],\"module_sizes\":{\"kzg\":[],\"poseidon\":[14432,[1]],\"elgamal\":[0,[0]]},\"required_lookups\":[],\"check_mode\":\"UNSAFE\",\"version\":\"5.0.8\",\"num_blinding_factors\":null}\n"
     ]
    }
   ],
   "source": [
    "# prover calculates settings, send to verifier\n",
    "gt30_data_tensor = data_tensor[data_tensor > 30].reshape(1,-1,1)\n",
    "new_size = torch.tensor(gt30_data_tensor.size()[1] )\n",
    "print(\"new tensor: \", gt30_data_tensor.size())\n",
    "# gt30_data_tensor = torch.reshape(gt30_data_tensor_raw, (1, int(gt30_data_tensor_raw.size()[0]), 1))\n",
    "theory_output = torch.mean(gt30_data_tensor)\n",
    "print(\"Theory_output: \", theory_output)\n",
    "class prover_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(prover_model, self).__init__()\n",
    "        # w represents mean in this case\n",
    "        self.w = nn.Parameter(data = theory_output, requires_grad = False)\n",
    "        self.new_size = nn.Parameter(data = new_size,requires_grad = False )\n",
    "        self.new_X = nn.Parameter(data = gt30_data_tensor,requires_grad = False )\n",
    "    def forward(self,X):\n",
    "        # where part\n",
    "        len_ratio =  self.new_size/X.size()[1]\n",
    "        result = torch.zeros(len_ratio*X.size()[1]).reshape(1,-1,1)\n",
    "        index_array = torch.tensor(range(int(len_ratio*X.size()[1])))\n",
    "        for index in index_array:\n",
    "            result[0][index][0] = self.new_X[0][index][0]\n",
    "        check_bool = torch.sum((torch.abs(X[X>30].reshape(1,-1,1)-self.new_X)<0.01*self.new_X).double())\n",
    "        print(\"check_bool: \", check_bool)\n",
    "        if check_bool==self.new_size:\n",
    "            value = torch.abs(torch.sum(result)-result.size()[1]*(self.w))<0.01*result.size()[1]*(self.w)\n",
    "        else:\n",
    "            value = torch.tensor(0)\n",
    "\n",
    "        return (value, self.w)\n",
    "\n",
    "prover_gen_settings([data_path], comb_data_path, prover_model,prover_model_path, [0], \"resources\", settings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== setting up ezkl ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n",
      "spawning module 2\n",
      "spawning module 0\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time setup: 1.3034610748291016 seconds\n",
      "=======================================\n",
      "Theory output:  tensor(52.3676)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Generating Witness ====\n",
      "witness boolean:  1.0\n",
      "witness result 1 : 52.0\n",
      "==== Generating Proof ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proof:  {'instances': [[[17970410297053518904, 9046703063145816218, 2851759239208196922, 164045840560226117], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287], [1460628720732602093, 15005283833837523956, 127539993950163949, 306168462079750959]]], 'proof': '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', 'transcript_type': 'EVM'}\n",
      "Time gen prf: 1.5841529369354248 seconds\n"
     ]
    }
   ],
   "source": [
    "# Here verifier & prover can concurrently call setup since all params are public to get pk. \n",
    "# Here write as verifier function to emphasize that verifier must calculate its own vk to be sure\n",
    "verifier_setup(verifier_model_path, verifier_compiled_model_path, settings_path, srs_path,vk_path, pk_path )\n",
    "\n",
    "print(\"=======================================\")\n",
    "# Prover generates proof\n",
    "print(\"Theory output: \", theory_output)\n",
    "prover_gen_proof(prover_model_path, comb_data_path, witness_path, prover_compiled_model_path, settings_path, proof_path, pk_path, srs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_inputs:  1\n",
      "prf instances:  [[[17970410297053518904, 9046703063145816218, 2851759239208196922, 164045840560226117], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287], [1460628720732602093, 15005283833837523956, 127539993950163949, 306168462079750959]]]\n",
      "proof boolean:  1.0\n",
      "proof result 1 : 52.0\n",
      "verified\n"
     ]
    }
   ],
   "source": [
    "# Verifier verifies\n",
    "verifier_verify(proof_path, settings_path, vk_path, srs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
