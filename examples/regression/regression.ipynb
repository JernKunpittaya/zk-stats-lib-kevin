{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ezkl==5.0.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 1)) (5.0.8)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 2)) (2.1.1)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 3)) (2.31.0)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 4)) (1.11.4)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 5)) (1.26.2)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 6)) (3.8.2)\n",
      "Requirement already satisfied: statistics in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 7)) (1.0.3.5)\n",
      "Requirement already satisfied: onnx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 8)) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (4.8.0)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.1.2)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (1.12)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.13.1)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (2023.10.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (4.45.1)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (10.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (1.4.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (3.1.1)\n",
      "Requirement already satisfied: docutils>=0.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from statistics->-r ../../requirements.txt (line 7)) (0.20.1)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from onnx->-r ../../requirements.txt (line 8)) (4.25.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.7->matplotlib->-r ../../requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch->-r ../../requirements.txt (line 2)) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy->torch->-r ../../requirements.txt (line 2)) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ezkl\n",
    "import torch\n",
    "from torch import nn\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export model\n",
    "def export_onnx(model, data_tensor_array, model_loc):\n",
    "  circuit = model()\n",
    "\n",
    "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "  # print(device)\n",
    "\n",
    "  circuit.to(device)\n",
    "\n",
    "  # Flips the neural net into inference mode\n",
    "  circuit.eval()\n",
    "  input_names = []\n",
    "  dynamic_axes = {}\n",
    "\n",
    "  data_tensor_tuple = ()\n",
    "  for i in range(len(data_tensor_array)):\n",
    "    data_tensor_tuple += (data_tensor_array[i],)\n",
    "    input_index = \"input\"+str(i+1)\n",
    "    input_names.append(input_index)\n",
    "    dynamic_axes[input_index] = {0 : 'batch_size'}\n",
    "  dynamic_axes[\"output\"] = {0 : 'batch_size'}\n",
    "\n",
    "  # Export the model\n",
    "  torch.onnx.export(circuit,               # model being run\n",
    "                      data_tensor_tuple,                   # model input (or a tuple for multiple inputs)\n",
    "                      model_loc,            # where to save the model (can be a file or file-like object)\n",
    "                      export_params=True,        # store the trained parameter weights inside the model file\n",
    "                      opset_version=11,          # the ONNX version to export the model to\n",
    "                      do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                      input_names = input_names,   # the model's input names\n",
    "                      output_names = ['output'], # the model's output names\n",
    "                      dynamic_axes=dynamic_axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode is either \"accuracy\" or \"resources\"\n",
    "\n",
    "def gen_settings(comb_data_path, onnx_filename, scale, mode, settings_filename):\n",
    "  print(\"==== Generate & Calibrate Setting ====\")\n",
    "  # Set input to be Poseidon Hash, and param of computation graph to be public\n",
    "  # Poseidon is not homomorphic additive, maybe consider Pedersens or Dory commitment.\n",
    "  gip_run_args = ezkl.PyRunArgs()\n",
    "  gip_run_args.input_visibility = \"hashed\"  # matrix and generalized inverse commitments\n",
    "  gip_run_args.output_visibility = \"public\"   # no parameters used\n",
    "  gip_run_args.param_visibility = \"private\" # should be Tensor(True)--> to enforce arbitrary data in w\n",
    "\n",
    " # generate settings\n",
    "  ezkl.gen_settings(onnx_filename, settings_filename, py_run_args=gip_run_args)\n",
    "  if scale ==\"default\":\n",
    "    ezkl.calibrate_settings(\n",
    "    comb_data_path, onnx_filename, settings_filename, mode)\n",
    "  else:\n",
    "    ezkl.calibrate_settings(\n",
    "    comb_data_path, onnx_filename, settings_filename, mode, scales = scale)\n",
    "\n",
    "  assert os.path.exists(settings_filename)\n",
    "  assert os.path.exists(comb_data_path)\n",
    "  assert os.path.exists(onnx_filename)\n",
    "  f_setting = open(settings_filename, \"r\")\n",
    "  print(\"scale: \", scale)\n",
    "  print(\"setting: \", f_setting.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifier_init(verifier_model, verifier_model_path, verifier_compiled_model_path, dummy_data_path_array, settings_path, srs_path, pk_path, vk_path, scale, mode):\n",
    "\n",
    "  # load data from dummy_data_path_array into dummy_data_array\n",
    "  dummy_data_tensor_array = []\n",
    "  comb_dummy_data = []\n",
    "  for path in dummy_data_path_array:\n",
    "    dummy_data = np.array(json.loads(open(path, \"r\").read())[\"input_data\"][0])\n",
    "    # print(\"dumm: \", dummy_data)\n",
    "    dummy_data_tensor_array.append(torch.reshape(torch.tensor(dummy_data), (1, len(dummy_data),1 )))\n",
    "    comb_dummy_data.append(dummy_data.tolist())\n",
    "  # export onnx file\n",
    "  export_onnx(verifier_model,dummy_data_tensor_array, verifier_model_path)\n",
    "\n",
    "  comb_dummy_data_path = os.path.join('generated/comb_dummy_data.json')\n",
    "  # Serialize data into file:\n",
    "  json.dump(dict(input_data = comb_dummy_data), open(comb_dummy_data_path, 'w' ))\n",
    "\n",
    "  # gen + calibrate setting\n",
    "  gen_settings(comb_dummy_data_path, verifier_model_path, scale, mode, settings_path)\n",
    "\n",
    "  # compile circuit\n",
    "  res = ezkl.compile_circuit(verifier_model_path, verifier_compiled_model_path, settings_path)\n",
    "  assert res == True\n",
    "\n",
    "  # srs path\n",
    "  res = ezkl.get_srs(srs_path, settings_path)\n",
    "\n",
    "  # setupt vk, pk param for use..... prover can use same pk or can init their own!\n",
    "  print(\"==== setting up ezkl ====\")\n",
    "  start_time = time.time()\n",
    "  res = ezkl.setup(\n",
    "        verifier_compiled_model_path,\n",
    "        vk_path,\n",
    "        pk_path,\n",
    "        srs_path)\n",
    "  end_time = time.time()\n",
    "  time_setup = end_time -start_time\n",
    "  print(f\"Time setup: {time_setup} seconds\")\n",
    "\n",
    "  assert res == True\n",
    "  assert os.path.isfile(vk_path)\n",
    "  assert os.path.isfile(pk_path)\n",
    "  assert os.path.isfile(settings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prover_gen(prover_model, data_path_array, witness_path, prover_model_path, prover_compiled_model_path, settings_path, proof_path):\n",
    "  # load data from data_path\n",
    "  # data = json.loads(open(data_path, \"r\").read())[\"input_data\"][0]\n",
    "  # data_tensor = torch.reshape(torch.tensor(data), (1, len(data),1 ))\n",
    "\n",
    "\n",
    "  data_tensor_array = []\n",
    "  comb_data = []\n",
    "  for path in data_path_array:\n",
    "    data = np.array(json.loads(open(path, \"r\").read())[\"input_data\"][0])\n",
    "    # print(\"dumm: \", dummy_data)\n",
    "    data_tensor_array.append(torch.reshape(torch.tensor(data), (1, len(data),1 )))\n",
    "    comb_data.append(data.tolist())\n",
    "\n",
    "  # export onnx file\n",
    "  export_onnx(prover_model, data_tensor_array, prover_model_path)\n",
    "\n",
    "  comb_data_path = os.path.join('generated/comb_data.json')\n",
    "  # Serialize data into file:\n",
    "  json.dump(dict(input_data = comb_data), open(comb_data_path, 'w' ))\n",
    "\n",
    "  res = ezkl.compile_circuit(prover_model_path, prover_compiled_model_path, settings_path)\n",
    "  assert res == True\n",
    "  # now generate the witness file\n",
    "  print('==== Generating Witness ====')\n",
    "  witness = ezkl.gen_witness(comb_data_path, prover_compiled_model_path, witness_path)\n",
    "  assert os.path.isfile(witness_path)\n",
    "  # print(witness[\"outputs\"])\n",
    "  settings = json.load(open(settings_path))\n",
    "  output_scale = settings['model_output_scales']\n",
    "  print(\"witness boolean: \", ezkl.vecu64_to_float(witness['outputs'][0][0], output_scale[0]))\n",
    "  for i in range(len(witness['outputs'][1])):\n",
    "    print(\"witness result\", i+1,\":\", ezkl.vecu64_to_float(witness['outputs'][1][i], output_scale[1]))\n",
    "\n",
    "  # GENERATE A PROOF\n",
    "  print(\"==== Generating Proof ====\")\n",
    "  start_time = time.time()\n",
    "  res = ezkl.prove(\n",
    "        witness_path,\n",
    "        prover_compiled_model_path,\n",
    "        pk_path,\n",
    "        proof_path,\n",
    "        srs_path,\n",
    "        \"single\",\n",
    "    )\n",
    "\n",
    "  print(\"proof: \" ,res)\n",
    "  end_time = time.time()\n",
    "  time_gen_prf = end_time -start_time\n",
    "  print(f\"Time gen prf: {time_gen_prf} seconds\")\n",
    "  assert os.path.isfile(proof_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifier_verify(proof_path, settings_path, vk_path, srs_path):\n",
    "  # enforce boolean statement to be true\n",
    "  settings = json.load(open(settings_path))\n",
    "  output_scale = settings['model_output_scales']\n",
    "\n",
    "  proof = json.load(open(proof_path))\n",
    "  num_inputs = len(settings['model_input_scales'])\n",
    "  print(\"num_inputs: \", num_inputs)\n",
    "  proof[\"instances\"][0][num_inputs] = ezkl.float_to_vecu64(1.0, output_scale[0])\n",
    "  json.dump(proof, open(proof_path, 'w'))\n",
    "\n",
    "  print(\"prf instances: \", proof['instances'])\n",
    "\n",
    "  print(\"proof boolean: \", ezkl.vecu64_to_float(proof['instances'][0][num_inputs], output_scale[0]))\n",
    "  for i in range(num_inputs+1, len(proof['instances'][0])):\n",
    "    print(\"proof result\",i-num_inputs,\":\", ezkl.vecu64_to_float(proof['instances'][0][i], output_scale[1]))\n",
    "\n",
    "\n",
    "  res = ezkl.verify(\n",
    "        proof_path,\n",
    "        settings_path,\n",
    "        vk_path,\n",
    "        srs_path,\n",
    "    )\n",
    "\n",
    "  assert res == True\n",
    "  print(\"verified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init path\n",
    "os.makedirs(os.path.dirname('generated/'), exist_ok=True)\n",
    "verifier_model_path = os.path.join('generated/verifier.onnx')\n",
    "prover_model_path = os.path.join('generated/prover.onnx')\n",
    "verifier_compiled_model_path = os.path.join('generated/verifier.compiled')\n",
    "prover_compiled_model_path = os.path.join('generated/prover.compiled')\n",
    "pk_path = os.path.join('generated/test.pk')\n",
    "vk_path = os.path.join('generated/test.vk')\n",
    "proof_path = os.path.join('generated/test.pf')\n",
    "settings_path = os.path.join('generated/settings.json')\n",
    "srs_path = os.path.join('generated/kzg.srs')\n",
    "witness_path = os.path.join('generated/witness.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=======================  ZK-STATS FLOW ======================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg fit:  [1.98835287 3.14238058 0.06413647]\n"
     ]
    }
   ],
   "source": [
    "x1_vals_path = os.path.join('x1_vals.json')\n",
    "x2_vals_path = os.path.join('x2_vals.json')\n",
    "dummy_x1_vals_path = os.path.join('generated/dummy_x1_vals.json')\n",
    "dummy_x2_vals_path = os.path.join('generated/dummy_x2_vals.json')\n",
    "\n",
    "x1_vals= np.array(json.loads(open(x1_vals_path, \"r\").read())['input_data'][0])\n",
    "dummy_x1_vals = np.random.uniform(min(x1_vals), max(x1_vals), len(x1_vals))\n",
    "json.dump({\"input_data\":[dummy_x1_vals.tolist()]}, open(dummy_x1_vals_path, 'w'))\n",
    "\n",
    "x2_vals= np.array(json.loads(open(x2_vals_path, \"r\").read())['input_data'][0])\n",
    "dummy_x2_vals = np.random.uniform(min(x2_vals), max(x2_vals), len(x2_vals))\n",
    "json.dump({\"input_data\":[dummy_x2_vals.tolist()]}, open(dummy_x2_vals_path, 'w'))\n",
    "\n",
    "\n",
    "y_vals_path = os.path.join('y_vals.json')\n",
    "dummy_y_vals_path = os.path.join('generated/dummy_y_vals.json')\n",
    "\n",
    "y_vals= np.array(json.loads(open(y_vals_path, \"r\").read())['input_data'][0])\n",
    "dummy_y_vals = np.random.uniform(min(y_vals), max(y_vals), len(y_vals))\n",
    "json.dump({\"input_data\":[dummy_y_vals.tolist()]}, open(dummy_y_vals_path, 'w'))\n",
    "\n",
    "\n",
    "def stacked_x(*args):\n",
    "    result = np.column_stack((*args, np.ones_like(args[0])))\n",
    "    return result\n",
    "\n",
    "x_one = stacked_x(x1_vals, x2_vals)\n",
    "dummy_x_one = stacked_x(dummy_x1_vals, dummy_x2_vals)\n",
    "\n",
    "w_vals = np.matmul(np.matmul(np.linalg.inv(np.matmul(x_one.transpose(), x_one)), x_one.transpose()), y_vals)\n",
    "dummy_w_vals = np.matmul(np.matmul(np.linalg.inv(np.matmul(dummy_x_one.transpose(), dummy_x_one)), dummy_x_one.transpose()), dummy_y_vals)\n",
    "\n",
    "print(\"reg fit: \", w_vals)\n",
    "w_tensor = torch.reshape(torch.tensor(w_vals), (1,3,1))\n",
    "dummy_w_tensor = torch.reshape(torch.tensor(dummy_w_vals), (1,3,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Generate & Calibrate Setting ====\n",
      "scale:  [3]\n",
      "setting:  {\"run_args\":{\"tolerance\":{\"val\":0.0,\"scale\":1.0},\"input_scale\":3,\"param_scale\":3,\"scale_rebase_multiplier\":10,\"lookup_range\":[-13942,977004],\"logrows\":20,\"num_inner_cols\":1,\"variables\":[[\"batch_size\",1]],\"input_visibility\":{\"Hashed\":{\"hash_is_public\":true,\"outlets\":[]}},\"output_visibility\":\"Public\",\"param_visibility\":\"Private\"},\"num_rows\":11808,\"total_assignments\":784,\"total_const_size\":4,\"model_instance_shapes\":[[1],[1,3,1]],\"model_output_scales\":[0,3],\"model_input_scales\":[3,3,3],\"module_sizes\":{\"kzg\":[],\"poseidon\":[11808,[3]],\"elgamal\":[0,[0]]},\"required_lookups\":[\"Abs\",{\"Div\":{\"denom\":100.0}},{\"GreaterThan\":{\"a\":0.0}}],\"check_mode\":\"UNSAFE\",\"version\":\"5.0.8\",\"num_blinding_factors\":null}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== setting up ezkl ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time setup: 88.79235982894897 seconds\n"
     ]
    }
   ],
   "source": [
    "# Verifier/ data consumer side:\n",
    "class verifier_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(verifier_model, self).__init__()\n",
    "        self.w = nn.Parameter(data = dummy_w_tensor, requires_grad = False)\n",
    "\n",
    "    def forward(self, *args):\n",
    "        # infer Y from the last parameter\n",
    "        Y = args[-1]\n",
    "        X_one = torch.cat((*args[:-1], torch.ones_like(args[0][:, :, -1:])), dim=2)\n",
    "        X_T = torch.transpose(X_one, 1, 2)\n",
    "        # some expression of tolerance to error in the inference\n",
    "        return (\n",
    "            torch.sum(torch.abs(X_T @ X_one @ self.w.to('cpu') - X_T @ Y)) < 0.01 * torch.sum(X_T @ Y),\n",
    "            self.w.to('cpu')\n",
    "        )\n",
    "verifier_init(verifier_model, verifier_model_path, verifier_compiled_model_path, [dummy_x1_vals_path,dummy_x2_vals_path, dummy_y_vals_path], settings_path, srs_path, pk_path, vk_path,[3], \"resources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Generating Witness ====\n",
      "witness boolean:  1.0\n",
      "witness result 1 : 2.0\n",
      "witness result 2 : 3.125\n",
      "witness result 3 : 0.125\n",
      "==== Generating Proof ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proof:  {'instances': [[[13372645934914757851, 4179548409246906955, 7308753190278705352, 585334253871252673], [14296875065875978922, 10817153402807448554, 16646795345921275234, 1848850777343635446], [11033437535517255964, 15518297366369924990, 13029218448037200835, 1837434524902037587], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287], [13392416068245389228, 14913608834158628949, 9631264589208289646, 2240050767903289935], [18409976096712818556, 4988926951396865304, 17770093507857248247, 884830624746662524], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287]]], 'proof': '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', 'transcript_type': 'EVM'}\n",
      "Time gen prf: 115.71196699142456 seconds\n"
     ]
    }
   ],
   "source": [
    "# Prover/ data owner side\n",
    "theory_output = w_tensor\n",
    "print(\"theory_output: \", theory_output)\n",
    "class prover_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(prover_model, self).__init__()\n",
    "        self.w = nn.Parameter(data = w_tensor, requires_grad = False)\n",
    "\n",
    "    def forward(self, *args):\n",
    "        # infer Y from the last parameter\n",
    "        Y = args[-1]\n",
    "        X_one = torch.cat((*args[:-1], torch.ones_like(args[0][:, :, -1:])), dim=2)\n",
    "        X_T = torch.transpose(X_one, 1, 2)\n",
    "        # some expression of tolerance to error in the inference\n",
    "        return (\n",
    "            torch.sum(torch.abs(X_T @ X_one @ self.w.to('cpu') - X_T @ Y)) < 0.01 * torch.sum(X_T @ Y),\n",
    "            self.w.to('cpu')\n",
    "        )\n",
    "prover_gen(prover_model, [x1_vals_path, x2_vals_path, y_vals_path], witness_path, prover_model_path, prover_compiled_model_path, settings_path, proof_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_inputs:  3\n",
      "prf instances:  [[[13372645934914757851, 4179548409246906955, 7308753190278705352, 585334253871252673], [14296875065875978922, 10817153402807448554, 16646795345921275234, 1848850777343635446], [11033437535517255964, 15518297366369924990, 13029218448037200835, 1837434524902037587], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287], [13392416068245389228, 14913608834158628949, 9631264589208289646, 2240050767903289935], [18409976096712818556, 4988926951396865304, 17770093507857248247, 884830624746662524], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287]]]\n",
      "proof boolean:  1.0\n",
      "proof result 1 : 2.0\n",
      "proof result 2 : 3.125\n",
      "proof result 3 : 0.125\n",
      "verified\n"
     ]
    }
   ],
   "source": [
    "verifier_verify(proof_path, settings_path, vk_path, srs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
