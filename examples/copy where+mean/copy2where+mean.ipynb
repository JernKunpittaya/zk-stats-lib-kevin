{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ezkl==7.0.0 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from -r ../../requirements.txt (line 1)) (7.0.0)\n",
      "Requirement already satisfied: torch in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from -r ../../requirements.txt (line 2)) (2.2.0)\n",
      "Requirement already satisfied: requests in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from -r ../../requirements.txt (line 3)) (2.31.0)\n",
      "Requirement already satisfied: scipy in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from -r ../../requirements.txt (line 4)) (1.12.0)\n",
      "Requirement already satisfied: numpy in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from -r ../../requirements.txt (line 5)) (1.26.3)\n",
      "Requirement already satisfied: matplotlib in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from -r ../../requirements.txt (line 6)) (3.8.2)\n",
      "Requirement already satisfied: statistics in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from -r ../../requirements.txt (line 7)) (1.0.3.5)\n",
      "Requirement already satisfied: onnx in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from -r ../../requirements.txt (line 8)) (1.15.0)\n",
      "Requirement already satisfied: filelock in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from torch->-r ../../requirements.txt (line 2)) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from torch->-r ../../requirements.txt (line 2)) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from torch->-r ../../requirements.txt (line 2)) (2023.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from requests->-r ../../requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from requests->-r ../../requirements.txt (line 3)) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from requests->-r ../../requirements.txt (line 3)) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from requests->-r ../../requirements.txt (line 3)) (2024.2.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: docutils>=0.3 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from statistics->-r ../../requirements.txt (line 7)) (0.20.1)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from onnx->-r ../../requirements.txt (line 8)) (4.25.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->-r ../../requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from jinja2->torch->-r ../../requirements.txt (line 2)) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from sympy->torch->-r ../../requirements.txt (line 2)) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ezkl\n",
    "import torch\n",
    "from torch import nn\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../../zkstats/core.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init path\n",
    "os.makedirs(os.path.dirname('shared/'), exist_ok=True)\n",
    "os.makedirs(os.path.dirname('prover/'), exist_ok=True)\n",
    "verifier_model_path = os.path.join('shared/verifier.onnx')\n",
    "prover_model_path = os.path.join('prover/prover.onnx')\n",
    "verifier_compiled_model_path = os.path.join('shared/verifier.compiled')\n",
    "prover_compiled_model_path = os.path.join('prover/prover.compiled')\n",
    "pk_path = os.path.join('shared/test.pk')\n",
    "vk_path = os.path.join('shared/test.vk')\n",
    "proof_path = os.path.join('shared/test.pf')\n",
    "settings_path = os.path.join('shared/settings.json')\n",
    "srs_path = os.path.join('shared/kzg.srs')\n",
    "witness_path = os.path.join('prover/witness.json')\n",
    "# this is private to prover since it contains actual data\n",
    "sel_data_path = os.path.join('prover/sel_data.json')\n",
    "# this is just dummy random value\n",
    "sel_dummy_data_path = os.path.join('shared/sel_dummy_data.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=======================  ZK-STATS FLOW ======================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join('data.json')\n",
    "dummy_data_path = os.path.join('shared/dummy_data.json')\n",
    "\n",
    "data = np.array(json.loads(open(data_path, \"r\").read())['col_name'])\n",
    "data_tensor = torch.reshape(torch.tensor(data),(1,-1, 1))\n",
    "# remember that our create_dummy creates random numbers in range 1 - 30, so need to make sure this example the filter doesnt\n",
    "# get filter out all data\n",
    "create_dummy(data_path, dummy_data_path)\n",
    "dummy_data = np.array(json.loads(open(dummy_data_path, \"r\").read())['col_name'])\n",
    "dummy_data_tensor = torch.reshape(torch.tensor(dummy_data), (1,-1,1))\n",
    "\n",
    "# # where(element > 20)\n",
    "gt20_dummy_data_tensor = dummy_data_tensor[dummy_data_tensor > 20].reshape(1,-1,1)\n",
    "dummy_theory_output = torch.mean(gt20_dummy_data_tensor)\n",
    "\n",
    "gt20_data_tensor = data_tensor[data_tensor > 20].reshape(1,-1,1)\n",
    "theory_output = torch.mean(gt20_data_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 1])\n",
      "torch.Size([1, 20, 1])\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "print(gt20_data_tensor.size())\n",
    "print(dummy_data_tensor.size())\n",
    "print(data_tensor[0][1][0]<20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = [5]\n",
    "selected_columns = ['col_name']\n",
    "commitment_maps = get_data_commitment_maps(data_path, scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/y9dw12v976ngdmqz4l7wbsnr0000gn/T/ipykernel_8994/1800029062.py:12: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  result = torch.tensor([0]*self.filtered.size()[1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "graph_ == value->owningGraph() INTERNAL ASSERT FAILED at \"/Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/jit/ir/ir.cpp\":1426, please report a bug to PyTorch. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 27\u001b[0m\n\u001b[1;32m     23\u001b[0m         fil_X \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mwhere(\u001b[39mfilter\u001b[39m, X, \u001b[39m0.0\u001b[39m)\n\u001b[1;32m     24\u001b[0m         \u001b[39mreturn\u001b[39;00m (torch\u001b[39m.\u001b[39mabs(torch\u001b[39m.\u001b[39msum(fil_X)\u001b[39m-\u001b[39mnum_fil_X\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mw)\u001b[39m<\u001b[39m\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mabs(\u001b[39m0.01\u001b[39m\u001b[39m*\u001b[39mnum_fil_X\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mw), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mw)\n\u001b[0;32m---> 27\u001b[0m verifier_define_calculation(dummy_data_path, selected_columns,sel_dummy_data_path,verifier_model, verifier_model_path)\n",
      "File \u001b[0;32m~/Desktop/zk-stats-lib/zkstats/core.py:26\u001b[0m, in \u001b[0;36mverifier_define_calculation\u001b[0;34m(dummy_data_path, col_array, dummy_sel_data_path, verifier_model, verifier_model_path)\u001b[0m\n\u001b[1;32m     24\u001b[0m dummy_data_tensor_array \u001b[39m=\u001b[39m _process_data(dummy_data_path, col_array, dummy_sel_data_path)\n\u001b[1;32m     25\u001b[0m \u001b[39m# export onnx file\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m _export_onnx(verifier_model, dummy_data_tensor_array, verifier_model_path)\n",
      "File \u001b[0;32m~/Desktop/zk-stats-lib/zkstats/core.py:257\u001b[0m, in \u001b[0;36m_export_onnx\u001b[0;34m(model, data_tensor_array, model_loc)\u001b[0m\n\u001b[1;32m    254\u001b[0m dynamic_axes[\u001b[39m\"\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m {\u001b[39m0\u001b[39m : \u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m}\n\u001b[1;32m    256\u001b[0m \u001b[39m# Export the model\u001b[39;00m\n\u001b[0;32m--> 257\u001b[0m torch\u001b[39m.\u001b[39;49monnx\u001b[39m.\u001b[39;49mexport(circuit,               \u001b[39m# model being run\u001b[39;49;00m\n\u001b[1;32m    258\u001b[0m                     data_tensor_tuple,                   \u001b[39m# model input (or a tuple for multiple inputs)\u001b[39;49;00m\n\u001b[1;32m    259\u001b[0m                     model_loc,            \u001b[39m# where to save the model (can be a file or file-like object)\u001b[39;49;00m\n\u001b[1;32m    260\u001b[0m                     export_params\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,        \u001b[39m# store the trained parameter weights inside the model file\u001b[39;49;00m\n\u001b[1;32m    261\u001b[0m                     opset_version\u001b[39m=\u001b[39;49m\u001b[39m11\u001b[39;49m,          \u001b[39m# the ONNX version to export the model to\u001b[39;49;00m\n\u001b[1;32m    262\u001b[0m                     do_constant_folding\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,  \u001b[39m# whether to execute constant folding for optimization\u001b[39;49;00m\n\u001b[1;32m    263\u001b[0m                     input_names \u001b[39m=\u001b[39;49m input_names,   \u001b[39m# the model's input names\u001b[39;49;00m\n\u001b[1;32m    264\u001b[0m                     output_names \u001b[39m=\u001b[39;49m [\u001b[39m'\u001b[39;49m\u001b[39moutput\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39m# the model's output names\u001b[39;49;00m\n\u001b[1;32m    265\u001b[0m                     dynamic_axes\u001b[39m=\u001b[39;49mdynamic_axes)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages/torch/onnx/utils.py:516\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39m@_beartype\u001b[39m\u001b[39m.\u001b[39mbeartype\n\u001b[1;32m    190\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexport\u001b[39m(\n\u001b[1;32m    191\u001b[0m     model: Union[torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule, torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mScriptModule, torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mScriptFunction],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m     autograd_inlining: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    209\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Exports a model into ONNX format.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \n\u001b[1;32m    212\u001b[0m \u001b[39m    If ``model`` is not a :class:`torch.jit.ScriptModule` nor a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[39m            All errors are subclasses of :class:`errors.OnnxExporterError`.\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m     _export(\n\u001b[1;32m    517\u001b[0m         model,\n\u001b[1;32m    518\u001b[0m         args,\n\u001b[1;32m    519\u001b[0m         f,\n\u001b[1;32m    520\u001b[0m         export_params,\n\u001b[1;32m    521\u001b[0m         verbose,\n\u001b[1;32m    522\u001b[0m         training,\n\u001b[1;32m    523\u001b[0m         input_names,\n\u001b[1;32m    524\u001b[0m         output_names,\n\u001b[1;32m    525\u001b[0m         operator_export_type\u001b[39m=\u001b[39;49moperator_export_type,\n\u001b[1;32m    526\u001b[0m         opset_version\u001b[39m=\u001b[39;49mopset_version,\n\u001b[1;32m    527\u001b[0m         do_constant_folding\u001b[39m=\u001b[39;49mdo_constant_folding,\n\u001b[1;32m    528\u001b[0m         dynamic_axes\u001b[39m=\u001b[39;49mdynamic_axes,\n\u001b[1;32m    529\u001b[0m         keep_initializers_as_inputs\u001b[39m=\u001b[39;49mkeep_initializers_as_inputs,\n\u001b[1;32m    530\u001b[0m         custom_opsets\u001b[39m=\u001b[39;49mcustom_opsets,\n\u001b[1;32m    531\u001b[0m         export_modules_as_functions\u001b[39m=\u001b[39;49mexport_modules_as_functions,\n\u001b[1;32m    532\u001b[0m         autograd_inlining\u001b[39m=\u001b[39;49mautograd_inlining,\n\u001b[1;32m    533\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages/torch/onnx/utils.py:1613\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m   1610\u001b[0m     dynamic_axes \u001b[39m=\u001b[39m {}\n\u001b[1;32m   1611\u001b[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001b[0;32m-> 1613\u001b[0m graph, params_dict, torch_out \u001b[39m=\u001b[39m _model_to_graph(\n\u001b[1;32m   1614\u001b[0m     model,\n\u001b[1;32m   1615\u001b[0m     args,\n\u001b[1;32m   1616\u001b[0m     verbose,\n\u001b[1;32m   1617\u001b[0m     input_names,\n\u001b[1;32m   1618\u001b[0m     output_names,\n\u001b[1;32m   1619\u001b[0m     operator_export_type,\n\u001b[1;32m   1620\u001b[0m     val_do_constant_folding,\n\u001b[1;32m   1621\u001b[0m     fixed_batch_size\u001b[39m=\u001b[39;49mfixed_batch_size,\n\u001b[1;32m   1622\u001b[0m     training\u001b[39m=\u001b[39;49mtraining,\n\u001b[1;32m   1623\u001b[0m     dynamic_axes\u001b[39m=\u001b[39;49mdynamic_axes,\n\u001b[1;32m   1624\u001b[0m )\n\u001b[1;32m   1626\u001b[0m \u001b[39m# TODO: Don't allocate a in-memory string for the protobuf\u001b[39;00m\n\u001b[1;32m   1627\u001b[0m defer_weight_export \u001b[39m=\u001b[39m (\n\u001b[1;32m   1628\u001b[0m     export_type \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m _exporter_states\u001b[39m.\u001b[39mExportTypes\u001b[39m.\u001b[39mPROTOBUF_FILE\n\u001b[1;32m   1629\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages/torch/onnx/utils.py:1135\u001b[0m, in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m   1132\u001b[0m     args \u001b[39m=\u001b[39m (args,)\n\u001b[1;32m   1134\u001b[0m model \u001b[39m=\u001b[39m _pre_trace_quant_model(model, args)\n\u001b[0;32m-> 1135\u001b[0m graph, params, torch_out, module \u001b[39m=\u001b[39m _create_jit_graph(model, args)\n\u001b[1;32m   1136\u001b[0m params_dict \u001b[39m=\u001b[39m _get_named_param_dict(graph, params)\n\u001b[1;32m   1138\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages/torch/onnx/utils.py:1011\u001b[0m, in \u001b[0;36m_create_jit_graph\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m   1006\u001b[0m     graph \u001b[39m=\u001b[39m _C\u001b[39m.\u001b[39m_propagate_and_assign_input_shapes(\n\u001b[1;32m   1007\u001b[0m         graph, flattened_args, param_count_list, \u001b[39mFalse\u001b[39;00m, \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m     )\n\u001b[1;32m   1009\u001b[0m     \u001b[39mreturn\u001b[39;00m graph, params, torch_out, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1011\u001b[0m graph, torch_out \u001b[39m=\u001b[39m _trace_and_get_graph_from_model(model, args)\n\u001b[1;32m   1012\u001b[0m _C\u001b[39m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[1;32m   1013\u001b[0m state_dict \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39m_unique_state_dict(model)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages/torch/onnx/utils.py:915\u001b[0m, in \u001b[0;36m_trace_and_get_graph_from_model\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    913\u001b[0m prev_autocast_cache_enabled \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mis_autocast_cache_enabled()\n\u001b[1;32m    914\u001b[0m torch\u001b[39m.\u001b[39mset_autocast_cache_enabled(\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 915\u001b[0m trace_graph, torch_out, inputs_states \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49m_get_trace_graph(\n\u001b[1;32m    916\u001b[0m     model,\n\u001b[1;32m    917\u001b[0m     args,\n\u001b[1;32m    918\u001b[0m     strict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    919\u001b[0m     _force_outplace\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    920\u001b[0m     _return_inputs_states\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    921\u001b[0m )\n\u001b[1;32m    922\u001b[0m torch\u001b[39m.\u001b[39mset_autocast_cache_enabled(prev_autocast_cache_enabled)\n\u001b[1;32m    924\u001b[0m warn_on_static_input_change(inputs_states)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages/torch/jit/_trace.py:1296\u001b[0m, in \u001b[0;36m_get_trace_graph\u001b[0;34m(f, args, kwargs, strict, _force_outplace, return_inputs, _return_inputs_states)\u001b[0m\n\u001b[1;32m   1294\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(args, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m   1295\u001b[0m     args \u001b[39m=\u001b[39m (args,)\n\u001b[0;32m-> 1296\u001b[0m outs \u001b[39m=\u001b[39m ONNXTracedModule(\n\u001b[1;32m   1297\u001b[0m     f, strict, _force_outplace, return_inputs, _return_inputs_states\n\u001b[1;32m   1298\u001b[0m )(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1299\u001b[0m \u001b[39mreturn\u001b[39;00m outs\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages/torch/jit/_trace.py:138\u001b[0m, in \u001b[0;36mONNXTracedModule.forward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(out_vars)\n\u001b[0;32m--> 138\u001b[0m graph, out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_create_graph_by_tracing(\n\u001b[1;32m    139\u001b[0m     wrapper,\n\u001b[1;32m    140\u001b[0m     in_vars \u001b[39m+\u001b[39;49m module_state,\n\u001b[1;32m    141\u001b[0m     _create_interpreter_name_lookup_fn(),\n\u001b[1;32m    142\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstrict,\n\u001b[1;32m    143\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_force_outplace,\n\u001b[1;32m    144\u001b[0m )\n\u001b[1;32m    146\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return_inputs:\n\u001b[1;32m    147\u001b[0m     \u001b[39mreturn\u001b[39;00m graph, outs[\u001b[39m0\u001b[39m], ret_inputs[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages/torch/jit/_trace.py:129\u001b[0m, in \u001b[0;36mONNXTracedModule.forward.<locals>.wrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return_inputs_states:\n\u001b[1;32m    128\u001b[0m     inputs_states\u001b[39m.\u001b[39mappend(_unflatten(in_args, in_desc))\n\u001b[0;32m--> 129\u001b[0m outs\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minner(\u001b[39m*\u001b[39;49mtrace_inputs))\n\u001b[1;32m    130\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return_inputs_states:\n\u001b[1;32m    131\u001b[0m     inputs_states[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m (inputs_states[\u001b[39m0\u001b[39m], trace_inputs)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m         recording_scopes \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1500\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1501\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1503\u001b[0m     \u001b[39mif\u001b[39;00m recording_scopes:\n",
      "Cell \u001b[0;32mIn[35], line 13\u001b[0m, in \u001b[0;36mverifier_model.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     11\u001b[0m filtered_index \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     12\u001b[0m result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39m0\u001b[39m]\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfiltered\u001b[39m.\u001b[39msize()[\u001b[39m1\u001b[39m])\n\u001b[0;32m---> 13\u001b[0m \u001b[39mfor\u001b[39;00m x_val \u001b[39min\u001b[39;00m X[\u001b[39m0\u001b[39;49m]:\n\u001b[1;32m     14\u001b[0m     result[filtered_index] \u001b[39m=\u001b[39m x_val[\u001b[39m0\u001b[39m]\u001b[39m==\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfiltered[\u001b[39m0\u001b[39m][filtered_index][\u001b[39m0\u001b[39m]\n\u001b[1;32m     15\u001b[0m     filtered_index \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mwhere(x_val[\u001b[39m0\u001b[39m]\u001b[39m>\u001b[39m\u001b[39m20\u001b[39m, filtered_index\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, filtered_index)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: graph_ == value->owningGraph() INTERNAL ASSERT FAILED at \"/Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/jit/ir/ir.cpp\":1426, please report a bug to PyTorch. "
     ]
    }
   ],
   "source": [
    "# Verifier/ data consumer side: send desired calculation\n",
    "class verifier_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(verifier_model, self).__init__()\n",
    "        # w represents mean in this case\n",
    "        self.w = nn.Parameter(data = dummy_theory_output, requires_grad = False)\n",
    "        self.filtered = nn.Parameter(data = gt20_dummy_data_tensor, requires_grad = False)\n",
    "\n",
    "    def forward(self,X):\n",
    "        arb = X.size()[1]>0\n",
    "        filtered_index = 0\n",
    "        result = torch.tensor([0]*self.filtered.size()[1])\n",
    "        filtered_index = filtered_index+1\n",
    "        # for x_val in X[0]:\n",
    "        #     result[filtered_index] = x_val[0]==self.filtered[0][filtered_index][0]\n",
    "        #     filtered_index = torch.where(x_val[0]>20, filtered_index+1, filtered_index)\n",
    "            \n",
    "        print('final', filtered_index)\n",
    "        bool_output = torch.abs(torch.sum(self.filtered)-self.filtered.size()[1]*(self.w))<=torch.abs(0.01*self.filtered.size()[1]*self.w)\n",
    "        return (torch.logical_and(arb, bool_output), self.w)\n",
    "        # where part\n",
    "        filter = (X>20)\n",
    "        num_fil_X = torch.sum(filter.float())\n",
    "        fil_X = torch.where(filter, X, 0.0)\n",
    "        return (torch.abs(torch.sum(fil_X)-num_fil_X*self.w)<=torch.abs(0.01*num_fil_X*self.w), self.w)\n",
    "\n",
    "\n",
    "verifier_define_calculation(dummy_data_path, selected_columns,sel_dummy_data_path,verifier_model, verifier_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theory_output:  tensor(50.3750, dtype=torch.float64)\n",
      "==== Generate & Calibrate Setting ====\n",
      "scale:  [5]\n",
      "setting:  {\"run_args\":{\"tolerance\":{\"val\":0.0,\"scale\":1.0},\"input_scale\":5,\"param_scale\":5,\"scale_rebase_multiplier\":10,\"lookup_range\":[0,0],\"logrows\":11,\"num_inner_cols\":2,\"variables\":[[\"batch_size\",1]],\"input_visibility\":{\"Hashed\":{\"hash_is_public\":true,\"outlets\":[]}},\"output_visibility\":\"Public\",\"param_visibility\":\"Private\"},\"num_rows\":1312,\"total_assignments\":20,\"total_const_size\":0,\"model_instance_shapes\":[[1],[1]],\"model_output_scales\":[0,5],\"model_input_scales\":[5],\"module_sizes\":{\"kzg\":[],\"poseidon\":[1312,[1]],\"elgamal\":[0,[0]]},\"required_lookups\":[],\"check_mode\":\"UNSAFE\",\"version\":\"7.0.0\",\"num_blinding_factors\":null}\n"
     ]
    }
   ],
   "source": [
    "# prover calculates settings, send to verifier\n",
    "gt30_data_tensor = data_tensor[data_tensor > 20].reshape(1,-1,1)\n",
    "theory_output = torch.mean(gt30_data_tensor)\n",
    "print(\"Theory_output: \", theory_output)\n",
    "class prover_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(prover_model, self).__init__()\n",
    "        # w represents mean in this case\n",
    "        self.w = nn.Parameter(data = theory_output, requires_grad = False)\n",
    "        self.filtered = nn.Parameter(data = gt20_data_tensor, requires_grad = False)\n",
    "\n",
    "    def forward(self,X):\n",
    "        # where part\n",
    "        arb = X.size()[1]>0\n",
    "        filtered_index = 0\n",
    "        result = torch.tensor([0]*self.filtered.size()[1])\n",
    "        for x_val in X[0]:\n",
    "            result[filtered_index] = x_val[0]==self.filtered[0][filtered_index][0]\n",
    "            filtered_index = torch.where(x_val[0]>20, filtered_index+1, filtered_index)\n",
    "        print(filtered_index)\n",
    "        bool_output = torch.abs(torch.sum(self.filtered)-self.filtered.size()[1]*(self.w))<=torch.abs(0.01*self.filtered.size()[1]*self.w)\n",
    "        return (torch.logical_and(arb, bool_output), self.w)\n",
    "        filter = (X>20)\n",
    "        num_fil_X = torch.sum(filter.float())\n",
    "        fil_X = torch.where(filter, X, 0.0)\n",
    "\n",
    "        return (torch.abs(torch.sum(fil_X)-num_fil_X*self.w)<=torch.abs(0.01*num_fil_X*self.w), self.w)\n",
    "\n",
    "\n",
    "prover_gen_settings(data_path, selected_columns, sel_data_path, prover_model,prover_model_path, scales, \"resources\", settings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== setting up ezkl ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n",
      "spawning module 2\n",
      "spawning module 0\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time setup: 0.25963401794433594 seconds\n",
      "=======================================\n",
      "Theory output:  tensor(50.3750, dtype=torch.float64)\n",
      "==== Generating Witness ====\n",
      "witness boolean:  1.0\n",
      "witness result 1 : 50.375\n",
      "==== Generating Proof ====\n",
      "proof:  {'instances': [[[16266678685338052443, 7438397994847379675, 5674719498686815871, 2240658077530776119], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287], [17049824896927915697, 16648112313320311147, 14284844057324796177, 2517225790866338397]]], 'proof': '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', 'transcript_type': 'EVM'}\n",
      "Time gen prf: 0.26849365234375 seconds\n"
     ]
    }
   ],
   "source": [
    "# Here verifier & prover can concurrently call setup since all params are public to get pk.\n",
    "# Here write as verifier function to emphasize that verifier must calculate its own vk to be sure\n",
    "verifier_setup(verifier_model_path, verifier_compiled_model_path, settings_path,vk_path, pk_path )\n",
    "\n",
    "print(\"=======================================\")\n",
    "# Prover generates proof\n",
    "print(\"Theory output: \", theory_output)\n",
    "prover_gen_proof(prover_model_path, sel_data_path, witness_path, prover_compiled_model_path, settings_path, proof_path, pk_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.375"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifier verifies\n",
    "verifier_verify(proof_path, settings_path, vk_path, selected_columns, commitment_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
