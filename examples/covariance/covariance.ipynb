{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ezkl==5.0.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 1)) (5.0.8)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 2)) (2.1.1)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 3)) (2.31.0)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 4)) (1.11.4)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 5)) (1.26.2)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 6)) (3.8.2)\n",
      "Requirement already satisfied: statistics in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 7)) (1.0.3.5)\n",
      "Requirement already satisfied: onnx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 8)) (1.15.0)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (2023.10.0)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.2.1)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (4.8.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (1.12)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.1.2)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.13.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (2023.11.17)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (3.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (10.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (4.45.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (23.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (1.4.5)\n",
      "Requirement already satisfied: docutils>=0.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from statistics->-r ../../requirements.txt (line 7)) (0.20.1)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from onnx->-r ../../requirements.txt (line 8)) (4.25.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.7->matplotlib->-r ../../requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch->-r ../../requirements.txt (line 2)) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy->torch->-r ../../requirements.txt (line 2)) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ezkl\n",
    "import torch\n",
    "from torch import nn\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export model\n",
    "def export_onnx(model, data_tensor_array, model_loc):\n",
    "  circuit = model()\n",
    "\n",
    "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "  # print(device)\n",
    "\n",
    "  circuit.to(device)\n",
    "\n",
    "  # Flips the neural net into inference mode\n",
    "  circuit.eval()\n",
    "  input_names = []\n",
    "  dynamic_axes = {}\n",
    "\n",
    "  data_tensor_tuple = ()\n",
    "  for i in range(len(data_tensor_array)):\n",
    "    data_tensor_tuple += (data_tensor_array[i],)\n",
    "    input_index = \"input\"+str(i+1)\n",
    "    input_names.append(input_index)\n",
    "    dynamic_axes[input_index] = {0 : 'batch_size'}\n",
    "  dynamic_axes[\"output\"] = {0 : 'batch_size'}\n",
    "\n",
    "  # Export the model\n",
    "  torch.onnx.export(circuit,               # model being run\n",
    "                      data_tensor_tuple,                   # model input (or a tuple for multiple inputs)\n",
    "                      model_loc,            # where to save the model (can be a file or file-like object)\n",
    "                      export_params=True,        # store the trained parameter weights inside the model file\n",
    "                      opset_version=11,          # the ONNX version to export the model to\n",
    "                      do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                      input_names = input_names,   # the model's input names\n",
    "                      output_names = ['output'], # the model's output names\n",
    "                      dynamic_axes=dynamic_axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode is either \"accuracy\" or \"resources\"\n",
    "\n",
    "def gen_settings(comb_data_path, onnx_filename, scale, mode, settings_filename):\n",
    "  print(\"==== Generate & Calibrate Setting ====\")\n",
    "  # Set input to be Poseidon Hash, and param of computation graph to be public\n",
    "  # Poseidon is not homomorphic additive, maybe consider Pedersens or Dory commitment.\n",
    "  gip_run_args = ezkl.PyRunArgs()\n",
    "  gip_run_args.input_visibility = \"hashed\"  # matrix and generalized inverse commitments\n",
    "  gip_run_args.output_visibility = \"public\"   # no parameters used\n",
    "  gip_run_args.param_visibility = \"private\" # should be Tensor(True)--> to enforce arbitrary data in w\n",
    "\n",
    " # generate settings\n",
    "  ezkl.gen_settings(onnx_filename, settings_filename, py_run_args=gip_run_args)\n",
    "  if scale ==\"default\":\n",
    "    ezkl.calibrate_settings(\n",
    "    comb_data_path, onnx_filename, settings_filename, mode)\n",
    "  else:\n",
    "    ezkl.calibrate_settings(\n",
    "    comb_data_path, onnx_filename, settings_filename, mode, scales = scale)\n",
    "\n",
    "  assert os.path.exists(settings_filename)\n",
    "  assert os.path.exists(comb_data_path)\n",
    "  assert os.path.exists(onnx_filename)\n",
    "  f_setting = open(settings_filename, \"r\")\n",
    "  print(\"scale: \", scale)\n",
    "  print(\"setting: \", f_setting.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifier_init(verifier_model, verifier_model_path, verifier_compiled_model_path, dummy_data_path_array, settings_path, srs_path, pk_path, vk_path, scale, mode):\n",
    "\n",
    "  # load data from dummy_data_path_array into dummy_data_array\n",
    "  dummy_data_tensor_array = []\n",
    "  comb_dummy_data = []\n",
    "  for path in dummy_data_path_array:\n",
    "    dummy_data = np.array(json.loads(open(path, \"r\").read())[\"input_data\"][0])\n",
    "    # print(\"dumm: \", dummy_data)\n",
    "    dummy_data_tensor_array.append(torch.reshape(torch.tensor(dummy_data), (1, len(dummy_data),1 )))\n",
    "    comb_dummy_data.append(dummy_data.tolist())\n",
    "  # export onnx file\n",
    "  export_onnx(verifier_model,dummy_data_tensor_array, verifier_model_path)\n",
    "\n",
    "  comb_dummy_data_path = os.path.join('generated/comb_dummy_data.json')\n",
    "  # Serialize data into file:\n",
    "  json.dump(dict(input_data = comb_dummy_data), open(comb_dummy_data_path, 'w' ))\n",
    "\n",
    "  # gen + calibrate setting\n",
    "  gen_settings(comb_dummy_data_path, verifier_model_path, scale, mode, settings_path)\n",
    "\n",
    "  # compile circuit\n",
    "  res = ezkl.compile_circuit(verifier_model_path, verifier_compiled_model_path, settings_path)\n",
    "  assert res == True\n",
    "\n",
    "  # srs path\n",
    "  res = ezkl.get_srs(srs_path, settings_path)\n",
    "\n",
    "  # setupt vk, pk param for use..... prover can use same pk or can init their own!\n",
    "  print(\"==== setting up ezkl ====\")\n",
    "  start_time = time.time()\n",
    "  res = ezkl.setup(\n",
    "        verifier_compiled_model_path,\n",
    "        vk_path,\n",
    "        pk_path,\n",
    "        srs_path)\n",
    "  end_time = time.time()\n",
    "  time_setup = end_time -start_time\n",
    "  print(f\"Time setup: {time_setup} seconds\")\n",
    "\n",
    "  assert res == True\n",
    "  assert os.path.isfile(vk_path)\n",
    "  assert os.path.isfile(pk_path)\n",
    "  assert os.path.isfile(settings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prover_gen(prover_model, data_path_array, witness_path, prover_model_path, prover_compiled_model_path, settings_path, proof_path):\n",
    "  # load data from data_path\n",
    "  # data = json.loads(open(data_path, \"r\").read())[\"input_data\"][0]\n",
    "  # data_tensor = torch.reshape(torch.tensor(data), (1, len(data),1 ))\n",
    "\n",
    "\n",
    "  data_tensor_array = []\n",
    "  comb_data = []\n",
    "  for path in data_path_array:\n",
    "    data = np.array(json.loads(open(path, \"r\").read())[\"input_data\"][0])\n",
    "    # print(\"dumm: \", dummy_data)\n",
    "    data_tensor_array.append(torch.reshape(torch.tensor(data), (1, len(data),1 )))\n",
    "    comb_data.append(data.tolist())\n",
    "\n",
    "  # export onnx file\n",
    "  export_onnx(prover_model, data_tensor_array, prover_model_path)\n",
    "\n",
    "  comb_data_path = os.path.join('generated/comb_data.json')\n",
    "  # Serialize data into file:\n",
    "  json.dump(dict(input_data = comb_data), open(comb_data_path, 'w' ))\n",
    "\n",
    "  res = ezkl.compile_circuit(prover_model_path, prover_compiled_model_path, settings_path)\n",
    "  assert res == True\n",
    "  # now generate the witness file\n",
    "  print('==== Generating Witness ====')\n",
    "  witness = ezkl.gen_witness(comb_data_path, prover_compiled_model_path, witness_path)\n",
    "  assert os.path.isfile(witness_path)\n",
    "  # print(witness[\"outputs\"])\n",
    "  settings = json.load(open(settings_path))\n",
    "  output_scale = settings['model_output_scales']\n",
    "  print(\"witness boolean: \", ezkl.vecu64_to_float(witness['outputs'][0][0], output_scale[0]))\n",
    "  for i in range(len(witness['outputs'][1])):\n",
    "    print(\"witness result\", i+1,\":\", ezkl.vecu64_to_float(witness['outputs'][1][i], output_scale[1]))\n",
    "\n",
    "  # GENERATE A PROOF\n",
    "  print(\"==== Generating Proof ====\")\n",
    "  start_time = time.time()\n",
    "  res = ezkl.prove(\n",
    "        witness_path,\n",
    "        prover_compiled_model_path,\n",
    "        pk_path,\n",
    "        proof_path,\n",
    "        srs_path,\n",
    "        \"single\",\n",
    "    )\n",
    "\n",
    "  print(\"proof: \" ,res)\n",
    "  end_time = time.time()\n",
    "  time_gen_prf = end_time -start_time\n",
    "  print(f\"Time gen prf: {time_gen_prf} seconds\")\n",
    "  assert os.path.isfile(proof_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifier_verify(proof_path, settings_path, vk_path, srs_path):\n",
    "  # enforce boolean statement to be true\n",
    "  settings = json.load(open(settings_path))\n",
    "  output_scale = settings['model_output_scales']\n",
    "\n",
    "  proof = json.load(open(proof_path))\n",
    "  num_inputs = len(settings['model_input_scales'])\n",
    "  print(\"num_inputs: \", num_inputs)\n",
    "  proof[\"instances\"][0][num_inputs] = ezkl.float_to_vecu64(1.0, output_scale[0])\n",
    "  json.dump(proof, open(proof_path, 'w'))\n",
    "\n",
    "  print(\"prf instances: \", proof['instances'])\n",
    "\n",
    "  print(\"proof boolean: \", ezkl.vecu64_to_float(proof['instances'][0][num_inputs], output_scale[0]))\n",
    "  for i in range(num_inputs+1, len(proof['instances'][0])):\n",
    "    print(\"proof result\",i-num_inputs,\":\", ezkl.vecu64_to_float(proof['instances'][0][i], output_scale[1]))\n",
    "\n",
    "\n",
    "  res = ezkl.verify(\n",
    "        proof_path,\n",
    "        settings_path,\n",
    "        vk_path,\n",
    "        srs_path,\n",
    "    )\n",
    "\n",
    "  assert res == True\n",
    "  print(\"verified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init path\n",
    "os.makedirs(os.path.dirname('generated/'), exist_ok=True)\n",
    "verifier_model_path = os.path.join('generated/verifier.onnx')\n",
    "prover_model_path = os.path.join('generated/prover.onnx')\n",
    "verifier_compiled_model_path = os.path.join('generated/verifier.compiled')\n",
    "prover_compiled_model_path = os.path.join('generated/prover.compiled')\n",
    "pk_path = os.path.join('generated/test.pk')\n",
    "vk_path = os.path.join('generated/test.vk')\n",
    "proof_path = os.path.join('generated/test.pf')\n",
    "settings_path = os.path.join('generated/settings.json')\n",
    "srs_path = os.path.join('generated/kzg.srs')\n",
    "witness_path = os.path.join('generated/witness.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=======================  ZK-STATS FLOW ======================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cov:  3214.750736446082\n",
      "x mean:  49.5\n",
      "y mean:  227.70285322096493\n"
     ]
    }
   ],
   "source": [
    "x_vals_path = os.path.join('x_vals.json')\n",
    "dummy_x_vals_path = os.path.join('generated/dummy_x_vals.json')\n",
    "x_open = open(x_vals_path, \"r\")\n",
    "x_vals= json.loads(x_open.read())['input_data'][0]\n",
    "dummy_x_vals = np.random.uniform(min(x_vals), max(x_vals), len(x_vals))\n",
    "json.dump({\"input_data\":[dummy_x_vals.tolist()]}, open(dummy_x_vals_path, 'w'))\n",
    "\n",
    "\n",
    "y_vals_path = os.path.join('y_vals.json')\n",
    "dummy_y_vals_path = os.path.join('generated/dummy_y_vals.json')\n",
    "y_open = open(y_vals_path, \"r\")\n",
    "y_vals= json.loads(y_open.read())[\"input_data\"][0]\n",
    "dummy_y_vals = np.random.uniform(min(y_vals), max(y_vals), len(y_vals))\n",
    "json.dump({\"input_data\":[dummy_y_vals.tolist()]}, open(dummy_y_vals_path, 'w'))\n",
    "\n",
    "\n",
    "real_cov = statistics.covariance(x_vals, y_vals)\n",
    "x_mean = statistics.mean(x_vals)\n",
    "y_mean = statistics.mean(y_vals)\n",
    "print(\"cov: \",real_cov )\n",
    "print(\"x mean: \", x_mean)\n",
    "print(\"y mean: \", y_mean)\n",
    "\n",
    "dummy_cov = statistics.covariance(dummy_x_vals, dummy_y_vals)\n",
    "dummy_x_mean = statistics.mean(dummy_x_vals)\n",
    "dummy_y_mean = statistics.mean(dummy_y_vals)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/onnx/symbolic_opset9.py:2174: FutureWarning: 'torch.onnx.symbolic_opset9._cast_Bool' is deprecated in version 2.0 and will be removed in the future. Please Avoid using this function and create a Cast node instead.\n",
      "  return fn(g, to_cast_func(g, input, False), to_cast_func(g, other, False))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Generate & Calibrate Setting ====\n",
      "scale:  [0]\n",
      "setting:  {\"run_args\":{\"tolerance\":{\"val\":0.0,\"scale\":1.0},\"input_scale\":0,\"param_scale\":0,\"scale_rebase_multiplier\":10,\"lookup_range\":[-4,65276],\"logrows\":16,\"num_inner_cols\":1,\"variables\":[[\"batch_size\",1]],\"input_visibility\":{\"Hashed\":{\"hash_is_public\":true,\"outlets\":[]}},\"output_visibility\":\"Public\",\"param_visibility\":\"Private\"},\"num_rows\":13120,\"total_assignments\":824,\"total_const_size\":2,\"model_instance_shapes\":[[1],[1]],\"model_output_scales\":[0,0],\"model_input_scales\":[0,0],\"module_sizes\":{\"kzg\":[],\"poseidon\":[13120,[2]],\"elgamal\":[0,[0]]},\"required_lookups\":[\"Abs\",{\"Div\":{\"denom\":100.0}},{\"GreaterThan\":{\"a\":0.0}}],\"check_mode\":\"UNSAFE\",\"version\":\"5.0.8\",\"num_blinding_factors\":null}\n",
      "==== setting up ezkl ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n",
      "spawning module 2\n",
      "spawning module 0\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time setup: 5.766196966171265 seconds\n"
     ]
    }
   ],
   "source": [
    "# Verifier/ data consumer side:\n",
    "class verifier_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(verifier_model, self).__init__()\n",
    "        self.cov = nn.Parameter(data = torch.tensor(dummy_cov), requires_grad = False)\n",
    "        self.x_mean = nn.Parameter(data = torch.tensor(dummy_x_mean), requires_grad = False)\n",
    "        self.y_mean = nn.Parameter(data = torch.tensor(dummy_y_mean), requires_grad = False)\n",
    "    def forward(self,X,Y):\n",
    "        # some expression of tolerance to error in the inference\n",
    "        # print(\"x size: \", X.size()[1])\n",
    "        #  need to enforce same length, not yet\n",
    "        return (torch.logical_and(torch.logical_and(torch.abs(torch.sum(X)-X.size()[1]*(self.x_mean))<0.01*torch.sum(X), torch.abs(torch.sum(Y)-Y.size()[1]*(self.y_mean))<0.01*torch.sum(Y)), torch.abs(torch.sum((X-self.x_mean)*(Y-self.y_mean))-(X.size()[1]-1)*(self.cov))<0.01*(X.size()[1]-1)*(self.cov)), self.cov)\n",
    "\n",
    "verifier_init(verifier_model, verifier_model_path, verifier_compiled_model_path, [dummy_x_vals_path, dummy_y_vals_path], settings_path, srs_path, pk_path, vk_path,[0], \"resources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Generating Witness ====\n",
      "witness boolean:  1.0\n",
      "witness result 1 : 3215.0\n",
      "==== Generating Proof ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proof:  {'instances': [[[14955570959218682635, 4667139652385906200, 12836539004462631467, 1774684518626433649], [2636517083442646612, 5059672846326347070, 4705835036930416229, 3312472395716484608], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287], [5743885005642251665, 3430503978676436355, 7149667244725939006, 2902673458086333540]]], 'proof': '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', 'transcript_type': 'EVM'}\n",
      "Time gen prf: 6.980463743209839 seconds\n"
     ]
    }
   ],
   "source": [
    "# Prover/ data owner side\n",
    "theory_output = torch.tensor(real_cov)\n",
    "print(\"theory output: \", theory_output)\n",
    "class prover_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(prover_model, self).__init__()\n",
    "        self.cov = nn.Parameter(data = torch.tensor(real_cov), requires_grad = False)\n",
    "        self.x_mean = nn.Parameter(data = torch.tensor(x_mean), requires_grad = False)\n",
    "        self.y_mean = nn.Parameter(data = torch.tensor(y_mean), requires_grad = False)\n",
    "    def forward(self,X,Y):\n",
    "        # some expression of tolerance to error in the inference\n",
    "        # print(\"x size: \", X.size()[1])\n",
    "        #  need to enforce same length\n",
    "        return (torch.logical_and(torch.logical_and(torch.abs(torch.sum(X)-X.size()[1]*(self.x_mean))<0.01*torch.sum(X), torch.abs(torch.sum(Y)-Y.size()[1]*(self.y_mean))<0.01*torch.sum(Y)), torch.abs(torch.sum((X-self.x_mean)*(Y-self.y_mean))-(X.size()[1]-1)*(self.cov))<0.01*(X.size()[1]-1)*(self.cov)), self.cov)\n",
    "\n",
    "prover_gen(prover_model, [x_vals_path, y_vals_path], witness_path, prover_model_path, prover_compiled_model_path, settings_path, proof_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_inputs:  2\n",
      "prf instances:  [[[14955570959218682635, 4667139652385906200, 12836539004462631467, 1774684518626433649], [2636517083442646612, 5059672846326347070, 4705835036930416229, 3312472395716484608], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287], [5743885005642251665, 3430503978676436355, 7149667244725939006, 2902673458086333540]]]\n",
      "proof boolean:  1.0\n",
      "proof result 1 : 3215.0\n",
      "verified\n"
     ]
    }
   ],
   "source": [
    "# Verifier verifies\n",
    "verifier_verify(proof_path, settings_path, vk_path, srs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
