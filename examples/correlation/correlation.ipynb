{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ezkl==7.0.0 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from -r ../../requirements.txt (line 1)) (7.0.0)\n",
      "Requirement already satisfied: torch in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from -r ../../requirements.txt (line 2)) (2.2.0)\n",
      "Requirement already satisfied: requests in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from -r ../../requirements.txt (line 3)) (2.31.0)\n",
      "Requirement already satisfied: scipy in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from -r ../../requirements.txt (line 4)) (1.12.0)\n",
      "Requirement already satisfied: numpy in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from -r ../../requirements.txt (line 5)) (1.26.3)\n",
      "Requirement already satisfied: matplotlib in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from -r ../../requirements.txt (line 6)) (3.8.2)\n",
      "Requirement already satisfied: statistics in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from -r ../../requirements.txt (line 7)) (1.0.3.5)\n",
      "Requirement already satisfied: onnx in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from -r ../../requirements.txt (line 8)) (1.15.0)\n",
      "Requirement already satisfied: filelock in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from torch->-r ../../requirements.txt (line 2)) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from torch->-r ../../requirements.txt (line 2)) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from torch->-r ../../requirements.txt (line 2)) (2023.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from requests->-r ../../requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from requests->-r ../../requirements.txt (line 3)) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from requests->-r ../../requirements.txt (line 3)) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from requests->-r ../../requirements.txt (line 3)) (2024.2.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: docutils>=0.3 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from statistics->-r ../../requirements.txt (line 7)) (0.20.1)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from onnx->-r ../../requirements.txt (line 8)) (4.25.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->-r ../../requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from jinja2->torch->-r ../../requirements.txt (line 2)) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages (from sympy->torch->-r ../../requirements.txt (line 2)) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r ../../requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Currently, the circuit is too huge, we would do it by requesting covariance and stdev and just calculate it on verifier side instead! Other circuits in this example can run well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ezkl\n",
    "import torch\n",
    "from torch import nn\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../../zkstats/core.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init path\n",
    "os.makedirs(os.path.dirname('shared/'), exist_ok=True)\n",
    "os.makedirs(os.path.dirname('prover/'), exist_ok=True)\n",
    "verifier_model_path = os.path.join('shared/verifier.onnx')\n",
    "prover_model_path = os.path.join('prover/prover.onnx')\n",
    "verifier_compiled_model_path = os.path.join('shared/verifier.compiled')\n",
    "prover_compiled_model_path = os.path.join('prover/prover.compiled')\n",
    "pk_path = os.path.join('shared/test.pk')\n",
    "vk_path = os.path.join('shared/test.vk')\n",
    "proof_path = os.path.join('shared/test.pf')\n",
    "settings_path = os.path.join('shared/settings.json')\n",
    "srs_path = os.path.join('shared/kzg.srs')\n",
    "witness_path = os.path.join('prover/witness.json')\n",
    "# this is private to prover since it contains actual data\n",
    "sel_data_path = os.path.join('prover/sel_data.json')\n",
    "# this is just dummy random value\n",
    "sel_dummy_data_path = os.path.join('shared/sel_dummy_data.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=======================  ZK-STATS FLOW ======================="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is not necessary. In fact, a person can just request cov(x,y), std(x), and std(y). Then just compute correlation on his own as well, but here we show that the code is composable enough to do all at once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr:  tensor(0.5182)\n",
      "check:  tensor(0.5182, dtype=torch.float64)\n",
      "x mean:  tensor(2.5000, dtype=torch.float64)\n",
      "y mean:  tensor(21.6667)\n",
      "dummy corr:  tensor(0.2342)\n",
      "dummy x mean:  tensor(15.5000)\n",
      "dummy y mean:  tensor(13.2500)\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join('data.json')\n",
    "dummy_data_path = os.path.join('shared/dummy_data.json')\n",
    "\n",
    "data = json.loads(open(data_path, \"r\").read())\n",
    "x_vals = data['x']\n",
    "y_vals = data['y']\n",
    "x_vals_tensor = torch.reshape(torch.tensor(x_vals, dtype = torch.float64),(1,-1, 1))\n",
    "y_vals_tensor = torch.reshape(torch.tensor(y_vals),(1,-1, 1))\n",
    "\n",
    "\n",
    "create_dummy(data_path, dummy_data_path)\n",
    "dummy_data = json.loads(open(dummy_data_path, \"r\").read())\n",
    "dummy_x_vals = dummy_data['x']\n",
    "dummy_y_vals = dummy_data['y']\n",
    "dummy_x_vals_tensor = torch.reshape(torch.tensor(dummy_x_vals),(1,-1, 1))\n",
    "dummy_y_vals_tensor = torch.reshape(torch.tensor(dummy_y_vals),(1,-1, 1))\n",
    "\n",
    "real_corr = torch.tensor(statistics.correlation(x_vals, y_vals))\n",
    "real_cov = torch.tensor(statistics.covariance(x_vals, y_vals))\n",
    "x_mean = torch.mean(x_vals_tensor)\n",
    "y_mean = torch.mean(y_vals_tensor)\n",
    "x_std = torch.sqrt(torch.var(x_vals_tensor, correction = 1))\n",
    "y_std = torch.sqrt(torch.var(y_vals_tensor, correction = 1))\n",
    "\n",
    "print(\"corr: \",real_corr )\n",
    "print(\"check: \", real_cov/(x_std*y_std))\n",
    "print(\"x mean: \", x_mean)\n",
    "print(\"y mean: \", y_mean)\n",
    "\n",
    "dummy_corr = torch.tensor(statistics.correlation(dummy_x_vals, dummy_y_vals))\n",
    "dummy_cov = torch.tensor(statistics.covariance(dummy_x_vals, dummy_y_vals))\n",
    "dummy_x_mean = torch.mean(dummy_x_vals_tensor)\n",
    "dummy_y_mean = torch.mean(dummy_y_vals_tensor)\n",
    "dummy_x_std = torch.sqrt(torch.var(dummy_x_vals_tensor, correction = 1))\n",
    "dummy_y_std = torch.sqrt(torch.var(dummy_y_vals_tensor, correction = 1))\n",
    "print(\"dummy corr: \",dummy_corr )\n",
    "print(\"dummy x mean: \", dummy_x_mean)\n",
    "print(\"dummy y mean: \", dummy_y_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = [3]\n",
    "selected_columns = ['x', 'y']\n",
    "commitment_maps = get_data_commitment_maps(data_path, scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance(X, Y, cov, x_mean, y_mean):\n",
    "    x_mean_cons = torch.abs(torch.sum(X)-X.size()[1]*(x_mean))<=torch.abs(0.01*X.size()[1]*(x_mean))\n",
    "    y_mean_cons = torch.abs(torch.sum(Y)-Y.size()[1]*(y_mean))<=torch.abs(0.01*Y.size()[1]*(y_mean))\n",
    "    return (torch.logical_and(torch.logical_and(x_mean_cons,y_mean_cons), torch.abs(torch.sum((X-x_mean)*(Y-y_mean))-(X.size()[1]-1)*(cov))<0.01*(X.size()[1]-1)*(cov)), cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stdev(X, x_std, x_mean):\n",
    "    x_mean_cons = torch.abs(torch.sum(X)-X.size()[1]*(x_mean))<=torch.abs(0.01*X.size()[1]*x_mean)\n",
    "    return (torch.logical_and(torch.abs(torch.sum((X-x_mean)*(X-x_mean))-x_std*x_std*(X.size()[1]-1))<=torch.abs(0.02*x_std*x_std*(X.size()[1]-1)),x_mean_cons),x_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jernkun/Library/Caches/pypoetry/virtualenvs/zkstats-OJpceffF-py3.11/lib/python3.11/site-packages/torch/onnx/symbolic_opset9.py:2174: FutureWarning: 'torch.onnx.symbolic_opset9._cast_Bool' is deprecated in version 2.0 and will be removed in the future. Please Avoid using this function and create a Cast node instead.\n",
      "  return fn(g, to_cast_func(g, input, False), to_cast_func(g, other, False))\n"
     ]
    }
   ],
   "source": [
    "# precise float number is hard, so we calculate 100*correlation instead.\n",
    "# Verifier/ data consumer side:\n",
    "class verifier_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(verifier_model, self).__init__()\n",
    "        self.corr = nn.Parameter(data = dummy_corr, requires_grad = False)\n",
    "        self.cov = nn.Parameter(data = dummy_cov, requires_grad = False)\n",
    "        self.x_mean = nn.Parameter(data = dummy_x_mean, requires_grad = False)\n",
    "        self.y_mean = nn.Parameter(data = dummy_y_mean, requires_grad = False)\n",
    "        self.x_std = nn.Parameter(data = dummy_x_std, requires_grad = False)\n",
    "        self.y_std = nn.Parameter(data = dummy_y_std, requires_grad = False)\n",
    "    def forward(self, *x):\n",
    "        X, Y = x\n",
    "        #  need to enforce same length, not yet\n",
    "        bool1, cov = covariance(X,Y, self.cov, self.x_mean, self.y_mean)\n",
    "        bool2, x_std = stdev(X, self.x_std, self.x_mean)\n",
    "        bool3, y_std = stdev(Y, self.y_std, self.y_mean)\n",
    "        bool4 = torch.abs(cov - self.corr*x_std*y_std)<=0.01*cov\n",
    "        return (torch.logical_and(torch.logical_and(bool1, bool2),torch.logical_and(bool3, bool4)), self.corr )\n",
    "\n",
    "verifier_define_calculation(dummy_data_path, selected_columns,sel_dummy_data_path,verifier_model, verifier_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theory output:  tensor(0.5182)\n",
      "==== Generate & Calibrate Setting ====\n",
      "scale:  [3]\n",
      "setting:  {\"run_args\":{\"tolerance\":{\"val\":0.0,\"scale\":1.0},\"input_scale\":3,\"param_scale\":3,\"scale_rebase_multiplier\":10,\"lookup_range\":[-3086,86],\"logrows\":12,\"num_inner_cols\":2,\"variables\":[[\"batch_size\",1]],\"input_visibility\":{\"Hashed\":{\"hash_is_public\":true,\"outlets\":[]}},\"output_visibility\":\"Public\",\"param_visibility\":\"Private\"},\"num_rows\":2624,\"total_assignments\":123,\"total_const_size\":16,\"model_instance_shapes\":[[1],[1]],\"model_output_scales\":[0,3],\"model_input_scales\":[3,3],\"module_sizes\":{\"kzg\":[],\"poseidon\":[2624,[2]],\"elgamal\":[0,[0]]},\"required_lookups\":[\"Abs\",{\"GreaterThan\":{\"a\":0.0}}],\"check_mode\":\"UNSAFE\",\"version\":\"7.0.0\",\"num_blinding_factors\":null}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/y9dw12v976ngdmqz4l7wbsnr0000gn/T/ipykernel_87897/280034176.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  theory_output = torch.tensor(real_corr)\n"
     ]
    }
   ],
   "source": [
    "# Prover/ data owner side\n",
    "theory_output = torch.tensor(real_corr)\n",
    "print(\"theory output: \", theory_output)\n",
    "class prover_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(prover_model, self).__init__()\n",
    "        self.corr = nn.Parameter(data = real_corr, requires_grad = False)\n",
    "        self.cov = nn.Parameter(data = real_cov, requires_grad = False)\n",
    "        self.x_mean = nn.Parameter(data = x_mean, requires_grad = False)\n",
    "        self.y_mean = nn.Parameter(data = y_mean, requires_grad = False)\n",
    "        self.x_std = nn.Parameter(data = x_std, requires_grad = False)\n",
    "        self.y_std = nn.Parameter(data = y_std, requires_grad = False)\n",
    "    def forward(self, *x):\n",
    "        X, Y = x\n",
    "        #  need to enforce same length, not yet\n",
    "        bool1, cov = covariance(X,Y, self.cov, self.x_mean, self.y_mean)\n",
    "        bool2, x_std = stdev(X, self.x_std, self.x_mean)\n",
    "        bool3, y_std = stdev(Y, self.y_std, self.y_mean)\n",
    "        bool4 = torch.abs(cov - self.corr*x_std*y_std)<=0.01*cov\n",
    "        return (torch.logical_and(torch.logical_and(bool1, bool2),torch.logical_and(bool3, bool4)), self.corr )\n",
    "\n",
    "prover_gen_settings(data_path, selected_columns, sel_data_path, prover_model,prover_model_path, scales, \"resources\", settings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== setting up ezkl ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n",
      "spawning module 2\n",
      "spawning module 0\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time setup: 0.5547151565551758 seconds\n",
      "=======================================\n",
      "Theory output:  tensor(0.5182)\n",
      "==== Generating Witness ====\n",
      "witness boolean:  1.0\n",
      "witness result 1 : 0.5\n",
      "==== Generating Proof ====\n",
      "proof:  {'instances': [[[7878865789954254792, 13676651756402193216, 14598220794878025105, 2053479320262803094], [957313277933440172, 8558673717091004388, 16115511877586365498, 2713079561337169730], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287], [7959790035488735211, 12951774245394433045, 16242874202584236123, 560012691975822483]]], 'proof': '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', 'transcript_type': 'EVM'}\n",
      "Time gen prf: 0.7244601249694824 seconds\n"
     ]
    }
   ],
   "source": [
    "# Here verifier & prover can concurrently call setup since all params are public to get pk.\n",
    "# Here write as verifier function to emphasize that verifier must calculate its own vk to be sure\n",
    "verifier_setup(verifier_model_path, verifier_compiled_model_path, settings_path,vk_path, pk_path )\n",
    "\n",
    "print(\"=======================================\")\n",
    "# Prover generates proof\n",
    "print(\"Theory output: \", theory_output)\n",
    "prover_gen_proof(prover_model_path, sel_data_path, witness_path, prover_compiled_model_path, settings_path, proof_path, pk_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifier verifies\n",
    "verifier_verify(proof_path, settings_path, vk_path, selected_columns, commitment_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
