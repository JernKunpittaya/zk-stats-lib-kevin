{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ezkl==5.0.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 1)) (5.0.8)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 2)) (2.1.1)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 3)) (2.31.0)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 4)) (1.11.4)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 5)) (1.26.2)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 6)) (3.8.2)\n",
      "Requirement already satisfied: statistics in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 7)) (1.0.3.5)\n",
      "Requirement already satisfied: onnx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 8)) (1.15.0)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (2023.10.0)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.2.1)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (4.8.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (1.12)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.1.2)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.13.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (2023.11.17)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (3.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (10.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (4.45.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (23.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (1.4.5)\n",
      "Requirement already satisfied: docutils>=0.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from statistics->-r ../../requirements.txt (line 7)) (0.20.1)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from onnx->-r ../../requirements.txt (line 8)) (4.25.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.7->matplotlib->-r ../../requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch->-r ../../requirements.txt (line 2)) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy->torch->-r ../../requirements.txt (line 2)) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r ../../requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Currently, the circuit is too huge, we would do it by requesting covariance and stdev and just calculate it on verifier side instead! Other circuits in this example can run well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ezkl\n",
    "import torch\n",
    "from torch import nn\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../../zkstats/core.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init path\n",
    "os.makedirs(os.path.dirname('shared/'), exist_ok=True)\n",
    "os.makedirs(os.path.dirname('prover/'), exist_ok=True)\n",
    "verifier_model_path = os.path.join('shared/verifier.onnx')\n",
    "prover_model_path = os.path.join('prover/prover.onnx')\n",
    "verifier_compiled_model_path = os.path.join('shared/verifier.compiled')\n",
    "prover_compiled_model_path = os.path.join('prover/prover.compiled')\n",
    "pk_path = os.path.join('shared/test.pk')\n",
    "vk_path = os.path.join('shared/test.vk')\n",
    "proof_path = os.path.join('shared/test.pf')\n",
    "settings_path = os.path.join('shared/settings.json')\n",
    "srs_path = os.path.join('shared/kzg.srs')\n",
    "witness_path = os.path.join('prover/witness.json')\n",
    "# this is private to prover since it contains actual data\n",
    "comb_data_path = os.path.join('prover/comb_data.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=======================  ZK-STATS FLOW ======================="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, this circuit is too huge, we would do it by requesting covariance and stdev and just calculate it on verifier side instead!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr:  0.8928769029553791\n",
      "x mean:  49.5\n",
      "y mean:  227.703\n",
      "dummy corr:  0.15901453422288986\n",
      "dummy x mean:  46.72829076325691\n",
      "dummy y mean:  231.04013454924026\n"
     ]
    }
   ],
   "source": [
    "x_vals_path = os.path.join('x_vals.json')\n",
    "dummy_x_vals_path = os.path.join('shared/dummy_x_vals.json')\n",
    "x_open = open(x_vals_path, \"r\")\n",
    "x_vals= json.loads(x_open.read())['input_data'][0]\n",
    "dummy_x_vals = np.random.uniform(min(x_vals), max(x_vals), len(x_vals))\n",
    "json.dump({\"input_data\":[dummy_x_vals.tolist()]}, open(dummy_x_vals_path, 'w'))\n",
    "\n",
    "\n",
    "y_vals_path = os.path.join('y_vals.json')\n",
    "dummy_y_vals_path = os.path.join('shared/dummy_y_vals.json')\n",
    "y_open = open(y_vals_path, \"r\")\n",
    "y_vals= json.loads(y_open.read())[\"input_data\"][0]\n",
    "dummy_y_vals = np.random.uniform(min(y_vals), max(y_vals), len(y_vals))\n",
    "json.dump({\"input_data\":[dummy_y_vals.tolist()]}, open(dummy_y_vals_path, 'w'))\n",
    "\n",
    "\n",
    "real_corr = statistics.correlation(x_vals, y_vals)\n",
    "x_mean = statistics.mean(x_vals)\n",
    "y_mean = statistics.mean(y_vals)\n",
    "x_var = np.sum((np.array(x_vals)-x_mean)**2)\n",
    "y_var = np.sum((np.array(y_vals)-y_mean)**2)\n",
    "print(\"corr: \",real_corr )\n",
    "print(\"x mean: \", x_mean)\n",
    "print(\"y mean: \", y_mean)\n",
    "\n",
    "dummy_corr = statistics.correlation(dummy_x_vals, dummy_y_vals)\n",
    "dummy_x_mean = statistics.mean(dummy_x_vals)\n",
    "dummy_y_mean = statistics.mean(dummy_y_vals)\n",
    "dummy_x_var = np.sum((dummy_x_vals-dummy_x_mean)**2)\n",
    "dummy_y_var = np.sum((dummy_y_vals-dummy_y_mean)**2)\n",
    "print(\"dummy corr: \",dummy_corr )\n",
    "print(\"dummy x mean: \", dummy_x_mean)\n",
    "print(\"dummy y mean: \", dummy_y_mean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE:\n",
    "IGnore this file, we already have way to calculate covariance and stdev. So better just calculate those values and then derive correlation from them, instead of fitting this whole thing into one circuit, unnecessarily big."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/onnx/symbolic_opset9.py:2174: FutureWarning: 'torch.onnx.symbolic_opset9._cast_Bool' is deprecated in version 2.0 and will be removed in the future. Please Avoid using this function and create a Cast node instead.\n",
      "  return fn(g, to_cast_func(g, input, False), to_cast_func(g, other, False))\n"
     ]
    }
   ],
   "source": [
    "# precise float number is hard, so we calculate 100*correlation instead.\n",
    "# Verifier/ data consumer side:\n",
    "class verifier_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(verifier_model, self).__init__()\n",
    "        self.corr = nn.Parameter(data = torch.tensor(dummy_corr*100), requires_grad = False)\n",
    "        self.x_mean = nn.Parameter(data = torch.tensor(dummy_x_mean), requires_grad = False)\n",
    "        self.y_mean = nn.Parameter(data = torch.tensor(dummy_y_mean), requires_grad = False)\n",
    "        self.x_var = nn.Parameter(data = torch.tensor(dummy_x_var), requires_grad = False)\n",
    "        self.y_var = nn.Parameter(data = torch.tensor(dummy_y_var), requires_grad = False)\n",
    "    def forward(self,X,Y):\n",
    "        #  need to enforce same length, not yet\n",
    "        x_mean_cons = torch.abs(torch.sum(X)-X.size()[1]*(self.x_mean))<0.01*X.size()[1]*(self.x_mean)\n",
    "        y_mean_cons = torch.abs(torch.sum(Y)-Y.size()[1]*(self.y_mean))<0.01*Y.size()[1]*(self.y_mean)\n",
    "        x_var_cons = torch.abs(torch.sum((X-self.x_mean)*(X-self.x_mean))-self.x_var*(X.size()[1]-1))<0.01*self.x_var*(X.size()[1]-1)\n",
    "        y_var_cons = torch.abs(torch.sum((Y-self.y_mean)*(Y-self.y_mean))-self.y_var*(Y.size()[1]-1))<0.01*self.y_var*(Y.size()[1]-1)\n",
    "        corr_cons = torch.abs(torch.sum((X-self.x_mean)*(Y-self.y_mean))-(torch.sqrt(self.x_var)*torch.sqrt(self.y_var)*torch.div(self.corr, 100)))<0.01*(torch.sqrt(self.x_var)*torch.sqrt(self.y_var)*torch.div(self.corr, 100))\n",
    "\n",
    "        # return (torch.logical_and(corr_cons, torch.logical_and(torch.logical_and(x_mean_cons, y_mean_cons), torch.logical_and(x_var_cons, y_var_cons))), self.corr)\n",
    "        # return (torch.logical_and(corr_cons, torch.logical_and(x_mean_cons, y_mean_cons)), self.corr)\n",
    "        # return (torch.logical_and(torch.logical_and(x_var_cons,corr_cons), torch.logical_and(x_mean_cons, y_mean_cons)), self.corr)\n",
    "        # return (torch.logical_and(x_var_cons,torch.logical_and(corr_cons, torch.logical_and(x_mean_cons, y_mean_cons))), self.corr)\n",
    "        return (torch.logical_and(x_var_cons, corr_cons), self.corr)\n",
    "verifier_define_calculation(verifier_model, verifier_model_path, [dummy_x_vals_path, dummy_y_vals_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theory output:  tensor(0.8929)\n",
      "==== Generate & Calibrate Setting ====\n",
      "scale:  [0]\n",
      "setting:  {\"run_args\":{\"tolerance\":{\"val\":0.0,\"scale\":1.0},\"input_scale\":0,\"param_scale\":0,\"scale_rebase_multiplier\":10,\"lookup_range\":[-16331650,6246],\"logrows\":24,\"num_inner_cols\":1,\"variables\":[[\"batch_size\",1]],\"input_visibility\":{\"Hashed\":{\"hash_is_public\":true,\"outlets\":[]}},\"output_visibility\":\"Public\",\"param_visibility\":\"Private\"},\"num_rows\":13120,\"total_assignments\":1011,\"total_const_size\":0,\"model_instance_shapes\":[[1],[1]],\"model_output_scales\":[0,0],\"model_input_scales\":[0,0],\"module_sizes\":{\"kzg\":[],\"poseidon\":[13120,[2]],\"elgamal\":[0,[0]]},\"required_lookups\":[\"Abs\",{\"GreaterThan\":{\"a\":0.0}}],\"check_mode\":\"UNSAFE\",\"version\":\"5.0.8\",\"num_blinding_factors\":null}\n"
     ]
    }
   ],
   "source": [
    "# Prover/ data owner side\n",
    "theory_output = torch.tensor(real_corr)\n",
    "print(\"theory output: \", theory_output)\n",
    "class prover_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(prover_model, self).__init__()\n",
    "        self.corr = nn.Parameter(data = torch.tensor(real_corr*100), requires_grad = False)\n",
    "        self.x_mean = nn.Parameter(data = torch.tensor(x_mean), requires_grad = False)\n",
    "        self.y_mean = nn.Parameter(data = torch.tensor(y_mean), requires_grad = False)\n",
    "        self.x_var = nn.Parameter(data = torch.tensor(x_var), requires_grad = False)\n",
    "        self.y_var = nn.Parameter(data = torch.tensor(y_var), requires_grad = False)\n",
    "    def forward(self,X,Y):\n",
    "        #  need to enforce same length, not yet\n",
    "        x_mean_cons = torch.abs(torch.sum(X)-X.size()[1]*(self.x_mean))<0.01*X.size()[1]*(self.x_mean)\n",
    "        y_mean_cons = torch.abs(torch.sum(Y)-Y.size()[1]*(self.y_mean))<0.01*Y.size()[1]*(self.y_mean)\n",
    "        x_var_cons = torch.abs(torch.sum((X-self.x_mean)*(X-self.x_mean))-self.x_var*(X.size()[1]-1))<0.01*self.x_var*(X.size()[1]-1)\n",
    "        y_var_cons = torch.abs(torch.sum((Y-self.y_mean)*(Y-self.y_mean))-self.y_var*(Y.size()[1]-1))<0.01*self.y_var*(Y.size()[1]-1)\n",
    "        corr_cons = torch.abs(torch.sum((X-self.x_mean)*(Y-self.y_mean))-(torch.sqrt(self.x_var)*torch.sqrt(self.y_var)*torch.div(self.corr, 100)))<0.01*(torch.sqrt(self.x_var)*torch.sqrt(self.y_var)*torch.div(self.corr, 100))\n",
    "\n",
    "        # return (torch.logical_and(corr_cons, torch.logical_and(torch.logical_and(x_mean_cons, y_mean_cons), torch.logical_and(x_var_cons, y_var_cons))), self.corr)\n",
    "        # return (torch.logical_and(corr_cons, torch.logical_and(x_mean_cons, y_mean_cons)), self.corr)\n",
    "        # return (torch.logical_and(torch.logical_and(corr_cons, x_var_cons), torch.logical_and(x_mean_cons, y_mean_cons)), self.corr)\n",
    "        # return (torch.logical_and(x_var_cons,torch.logical_and(corr_cons, torch.logical_and(x_mean_cons, y_mean_cons))), self.corr)\n",
    "        return (torch.logical_and(x_var_cons, corr_cons), self.corr)\n",
    "prover_gen_settings([x_vals_path, y_vals_path], comb_data_path, prover_model,prover_model_path, [0], \"resources\", settings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here verifier & prover can concurrently call setup since all params are public to get pk.\n",
    "# Here write as verifier function to emphasize that verifier must calculate its own vk to be sure\n",
    "verifier_setup(verifier_model_path, verifier_compiled_model_path, settings_path, srs_path,vk_path, pk_path )\n",
    "\n",
    "print(\"=======================================\")\n",
    "# Prover generates proof\n",
    "print(\"Theory output: \", theory_output)\n",
    "prover_gen_proof(prover_model_path, comb_data_path, witness_path, prover_compiled_model_path, settings_path, proof_path, pk_path, srs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_inputs:  2\n",
      "prf instances:  [[[14955570959218682635, 4667139652385906200, 12836539004462631467, 1774684518626433649], [4224417983558473805, 851357164555783563, 5363851773531956453, 1448631618362554917], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287], [6856486776492523050, 3509301300289033549, 11286023888431465720, 2871037162753880935]]]\n",
      "proof boolean:  1.0\n",
      "proof result 1 : 89.0\n",
      "verified\n"
     ]
    }
   ],
   "source": [
    "# Verifier verifies\n",
    "verifier_verify(proof_path, settings_path, vk_path, srs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
