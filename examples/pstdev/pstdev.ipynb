{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ezkl==5.0.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 1)) (5.0.8)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 2)) (2.1.1)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 3)) (2.31.0)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 4)) (1.11.4)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 5)) (1.26.2)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 6)) (3.8.2)\n",
      "Requirement already satisfied: statistics in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 7)) (1.0.3.5)\n",
      "Requirement already satisfied: onnx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 8)) (1.15.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.13.1)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.2.1)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (2023.10.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (1.12)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (4.8.0)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.1.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (3.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (1.4.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (4.45.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (3.1.1)\n",
      "Requirement already satisfied: docutils>=0.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from statistics->-r ../../requirements.txt (line 7)) (0.20.1)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from onnx->-r ../../requirements.txt (line 8)) (4.25.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.7->matplotlib->-r ../../requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch->-r ../../requirements.txt (line 2)) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy->torch->-r ../../requirements.txt (line 2)) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ezkl\n",
    "import torch\n",
    "from torch import nn\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export model\n",
    "def export_onnx(model, data_tensor_array, model_loc):\n",
    "  circuit = model()\n",
    "\n",
    "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "  # print(device)\n",
    "\n",
    "  circuit.to(device)\n",
    "\n",
    "  # Flips the neural net into inference mode\n",
    "  circuit.eval()\n",
    "  input_names = []\n",
    "  dynamic_axes = {}\n",
    "\n",
    "  data_tensor_tuple = ()\n",
    "  for i in range(len(data_tensor_array)):\n",
    "    data_tensor_tuple += (data_tensor_array[i],)\n",
    "    input_index = \"input\"+str(i+1)\n",
    "    input_names.append(input_index)\n",
    "    dynamic_axes[input_index] = {0 : 'batch_size'}\n",
    "  dynamic_axes[\"output\"] = {0 : 'batch_size'}\n",
    "\n",
    "  # Export the model\n",
    "  torch.onnx.export(circuit,               # model being run\n",
    "                      data_tensor_tuple,                   # model input (or a tuple for multiple inputs)\n",
    "                      model_loc,            # where to save the model (can be a file or file-like object)\n",
    "                      export_params=True,        # store the trained parameter weights inside the model file\n",
    "                      opset_version=11,          # the ONNX version to export the model to\n",
    "                      do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                      input_names = input_names,   # the model's input names\n",
    "                      output_names = ['output'], # the model's output names\n",
    "                      dynamic_axes=dynamic_axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode is either \"accuracy\" or \"resources\"\n",
    "\n",
    "def gen_settings(comb_data_path, onnx_filename, scale, mode, settings_filename):\n",
    "  print(\"==== Generate & Calibrate Setting ====\")\n",
    "  # Set input to be Poseidon Hash, and param of computation graph to be public\n",
    "  # Poseidon is not homomorphic additive, maybe consider Pedersens or Dory commitment.\n",
    "  gip_run_args = ezkl.PyRunArgs()\n",
    "  gip_run_args.input_visibility = \"hashed\"  # matrix and generalized inverse commitments\n",
    "  gip_run_args.output_visibility = \"public\"   # no parameters used\n",
    "  gip_run_args.param_visibility = \"private\" # should be Tensor(True)--> to enforce arbitrary data in w\n",
    "\n",
    " # generate settings\n",
    "  ezkl.gen_settings(onnx_filename, settings_filename, py_run_args=gip_run_args)\n",
    "  if scale ==\"default\":\n",
    "    ezkl.calibrate_settings(\n",
    "    comb_data_path, onnx_filename, settings_filename, mode)\n",
    "  else:\n",
    "    ezkl.calibrate_settings(\n",
    "    comb_data_path, onnx_filename, settings_filename, mode, scales = scale)\n",
    "\n",
    "  assert os.path.exists(settings_filename)\n",
    "  assert os.path.exists(comb_data_path)\n",
    "  assert os.path.exists(onnx_filename)\n",
    "  f_setting = open(settings_filename, \"r\")\n",
    "  print(\"scale: \", scale)\n",
    "  print(\"setting: \", f_setting.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifier_init(verifier_model, verifier_model_path, verifier_compiled_model_path, dummy_data_path_array, settings_path, srs_path, pk_path, vk_path, scale, mode):\n",
    "\n",
    "  # load data from dummy_data_path_array into dummy_data_array\n",
    "  dummy_data_tensor_array = []\n",
    "  comb_dummy_data = []\n",
    "  for path in dummy_data_path_array:\n",
    "    dummy_data = np.array(json.loads(open(path, \"r\").read())[\"input_data\"][0])\n",
    "    # print(\"dumm: \", dummy_data)\n",
    "    dummy_data_tensor_array.append(torch.reshape(torch.tensor(dummy_data), (1, len(dummy_data),1 )))\n",
    "    comb_dummy_data.append(dummy_data.tolist())\n",
    "  # export onnx file\n",
    "  export_onnx(verifier_model,dummy_data_tensor_array, verifier_model_path)\n",
    "\n",
    "  comb_dummy_data_path = os.path.join('generated/comb_dummy_data.json')\n",
    "  # Serialize data into file:\n",
    "  json.dump(dict(input_data = comb_dummy_data), open(comb_dummy_data_path, 'w' ))\n",
    "\n",
    "  # gen + calibrate setting\n",
    "  gen_settings(comb_dummy_data_path, verifier_model_path, scale, mode, settings_path)\n",
    "\n",
    "  # compile circuit\n",
    "  res = ezkl.compile_circuit(verifier_model_path, verifier_compiled_model_path, settings_path)\n",
    "  assert res == True\n",
    "\n",
    "  # srs path\n",
    "  res = ezkl.get_srs(srs_path, settings_path)\n",
    "\n",
    "  # setupt vk, pk param for use..... prover can use same pk or can init their own!\n",
    "  print(\"==== setting up ezkl ====\")\n",
    "  start_time = time.time()\n",
    "  res = ezkl.setup(\n",
    "        verifier_compiled_model_path,\n",
    "        vk_path,\n",
    "        pk_path,\n",
    "        srs_path)\n",
    "  end_time = time.time()\n",
    "  time_setup = end_time -start_time\n",
    "  print(f\"Time setup: {time_setup} seconds\")\n",
    "\n",
    "  assert res == True\n",
    "  assert os.path.isfile(vk_path)\n",
    "  assert os.path.isfile(pk_path)\n",
    "  assert os.path.isfile(settings_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prover_gen(prover_model, data_path_array, witness_path, prover_model_path, prover_compiled_model_path, settings_path, proof_path):\n",
    "  # load data from data_path\n",
    "  # data = json.loads(open(data_path, \"r\").read())[\"input_data\"][0]\n",
    "  # data_tensor = torch.reshape(torch.tensor(data), (1, len(data),1 ))\n",
    "\n",
    "\n",
    "  data_tensor_array = []\n",
    "  comb_data = []\n",
    "  for path in data_path_array:\n",
    "    data = np.array(json.loads(open(path, \"r\").read())[\"input_data\"][0])\n",
    "    # print(\"dumm: \", dummy_data)\n",
    "    data_tensor_array.append(torch.reshape(torch.tensor(data), (1, len(data),1 )))\n",
    "    comb_data.append(data.tolist())\n",
    "\n",
    "  # export onnx file\n",
    "  export_onnx(prover_model, data_tensor_array, prover_model_path)\n",
    "\n",
    "  comb_data_path = os.path.join('generated/comb_data.json')\n",
    "  # Serialize data into file:\n",
    "  json.dump(dict(input_data = comb_data), open(comb_data_path, 'w' ))\n",
    "\n",
    "  res = ezkl.compile_circuit(prover_model_path, prover_compiled_model_path, settings_path)\n",
    "  assert res == True\n",
    "  # now generate the witness file\n",
    "  print('==== Generating Witness ====')\n",
    "  witness = ezkl.gen_witness(comb_data_path, prover_compiled_model_path, witness_path)\n",
    "  assert os.path.isfile(witness_path)\n",
    "  # print(witness[\"outputs\"])\n",
    "  settings = json.load(open(settings_path))\n",
    "  output_scale = settings['model_output_scales']\n",
    "  print(\"witness boolean: \", ezkl.vecu64_to_float(witness['outputs'][0][0], output_scale[0]))\n",
    "  for i in range(len(witness['outputs'][1])):\n",
    "    print(\"witness result\", i+1,\":\", ezkl.vecu64_to_float(witness['outputs'][1][i], output_scale[1]))\n",
    "\n",
    "  # GENERATE A PROOF\n",
    "  print(\"==== Generating Proof ====\")\n",
    "  start_time = time.time()\n",
    "  res = ezkl.prove(\n",
    "        witness_path,\n",
    "        prover_compiled_model_path,\n",
    "        pk_path,\n",
    "        proof_path,\n",
    "        srs_path,\n",
    "        \"single\",\n",
    "    )\n",
    "\n",
    "  print(\"proof: \" ,res)\n",
    "  end_time = time.time()\n",
    "  time_gen_prf = end_time -start_time\n",
    "  print(f\"Time gen prf: {time_gen_prf} seconds\")\n",
    "  assert os.path.isfile(proof_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifier_verify(proof_path, settings_path, vk_path, srs_path):\n",
    "  # enforce boolean statement to be true\n",
    "  settings = json.load(open(settings_path))\n",
    "  output_scale = settings['model_output_scales']\n",
    "\n",
    "  proof = json.load(open(proof_path))\n",
    "  num_inputs = len(settings['model_input_scales'])\n",
    "  print(\"num_inputs: \", num_inputs)\n",
    "  proof[\"instances\"][0][num_inputs] = ezkl.float_to_vecu64(1.0, output_scale[0])\n",
    "  json.dump(proof, open(proof_path, 'w'))\n",
    "\n",
    "  print(\"prf instances: \", proof['instances'])\n",
    "\n",
    "  print(\"proof boolean: \", ezkl.vecu64_to_float(proof['instances'][0][num_inputs], output_scale[0]))\n",
    "  for i in range(num_inputs+1, len(proof['instances'][0])):\n",
    "    print(\"proof result\",i-num_inputs,\":\", ezkl.vecu64_to_float(proof['instances'][0][i], output_scale[1]))\n",
    "\n",
    "\n",
    "  res = ezkl.verify(\n",
    "        proof_path,\n",
    "        settings_path,\n",
    "        vk_path,\n",
    "        srs_path,\n",
    "    )\n",
    "\n",
    "  assert res == True\n",
    "  print(\"verified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init path\n",
    "os.makedirs(os.path.dirname('generated/'), exist_ok=True)\n",
    "verifier_model_path = os.path.join('generated/verifier.onnx')\n",
    "prover_model_path = os.path.join('generated/prover.onnx')\n",
    "verifier_compiled_model_path = os.path.join('generated/verifier.compiled')\n",
    "prover_compiled_model_path = os.path.join('generated/prover.compiled')\n",
    "pk_path = os.path.join('generated/test.pk')\n",
    "vk_path = os.path.join('generated/test.vk')\n",
    "proof_path = os.path.join('generated/test.pf')\n",
    "settings_path = os.path.join('generated/settings.json')\n",
    "srs_path = os.path.join('generated/kzg.srs')\n",
    "witness_path = os.path.join('generated/witness.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=======================  ZK-STATS FLOW ======================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join('data.json')\n",
    "dummy_data_path = os.path.join('generated/dummy_data.json')\n",
    "\n",
    "f_raw_input = open(data_path, \"r\")\n",
    "data = json.loads(f_raw_input.read())[\"input_data\"][0]\n",
    "data_tensor = torch.reshape(torch.tensor(data),(1, len(data), 1))\n",
    "\n",
    "#  dummy data for data consumer: make the bound approx same as real data\n",
    "dummy_data = np.random.uniform(min(data), max(data), len(data))\n",
    "json.dump({\"input_data\":[dummy_data.tolist()]}, open(dummy_data_path, 'w'))\n",
    "\n",
    "dummy_data_tensor = torch.reshape(torch.tensor(dummy_data), (1, len(dummy_data),1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_theory_output = torch.sqrt(torch.var(dummy_data_tensor, correction = 0))\n",
    "dummy_data_mean = torch.mean(dummy_data_tensor)\n",
    "# print(dummy_theory_output)\n",
    "# print(torch.sum(torch.pow(dummy_data_tensor-torch.mean(dummy_data_tensor), 2))/(dummy_data_tensor.size()[1]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/onnx/symbolic_opset9.py:2174: FutureWarning: 'torch.onnx.symbolic_opset9._cast_Bool' is deprecated in version 2.0 and will be removed in the future. Please Avoid using this function and create a Cast node instead.\n",
      "  return fn(g, to_cast_func(g, input, False), to_cast_func(g, other, False))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Generate & Calibrate Setting ====\n",
      "scale:  [0]\n",
      "setting:  {\"run_args\":{\"tolerance\":{\"val\":0.0,\"scale\":1.0},\"input_scale\":0,\"param_scale\":0,\"scale_rebase_multiplier\":10,\"lookup_range\":[0,37882],\"logrows\":16,\"num_inner_cols\":1,\"variables\":[[\"batch_size\",1]],\"input_visibility\":{\"Hashed\":{\"hash_is_public\":true,\"outlets\":[]}},\"output_visibility\":\"Public\",\"param_visibility\":\"Private\"},\"num_rows\":14432,\"total_assignments\":1515,\"total_const_size\":1,\"model_instance_shapes\":[[1],[1]],\"model_output_scales\":[0,0],\"model_input_scales\":[0],\"module_sizes\":{\"kzg\":[],\"poseidon\":[14432,[1]],\"elgamal\":[0,[0]]},\"required_lookups\":[\"Abs\",{\"Div\":{\"denom\":100.0}},{\"GreaterThan\":{\"a\":0.0}}],\"check_mode\":\"UNSAFE\",\"version\":\"5.0.8\",\"num_blinding_factors\":null}\n",
      "==== setting up ezkl ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n",
      "spawning module 2\n",
      "spawning module 0\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time setup: 5.24577784538269 seconds\n"
     ]
    }
   ],
   "source": [
    "# Verifier/ data consumer side:\n",
    "class verifier_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(verifier_model, self).__init__()\n",
    "        # w represents mean in this case\n",
    "        self.w = nn.Parameter(data = dummy_theory_output, requires_grad = False)\n",
    "        self.data_mean = nn.Parameter(data = dummy_data_mean, requires_grad = False)\n",
    "\n",
    "    def forward(self,X):\n",
    "        # some expression of tolerance to error in the inference\n",
    "        return (torch.logical_and(torch.abs(torch.sum((X-self.data_mean)*(X-self.data_mean))-self.w*self.w*X.size()[1])<0.01*self.w*self.w*X.size()[1],torch.abs(torch.sum(X)-X.size()[1]*(self.data_mean))<0.01*torch.sum(X) ),self.w)\n",
    "\n",
    "verifier_init(verifier_model, verifier_model_path, verifier_compiled_model_path, [dummy_data_path], settings_path, srs_path, pk_path, vk_path,[0], \"resources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theory output:  tensor(14.5557)\n",
      "==== Generating Witness ====\n",
      "witness boolean:  1.0\n",
      "witness result 1 : 15.0\n",
      "==== Generating Proof ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proof:  {'instances': [[[10512373747352303962, 11798585516934984832, 13421675179368312123, 2200257403316998104], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287], [956231351009279921, 10951436676983309100, 2250248050743556928, 1228298028208591648]]], 'proof': '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', 'transcript_type': 'EVM'}\n",
      "Time gen prf: 6.400813102722168 seconds\n"
     ]
    }
   ],
   "source": [
    "# Prover/ data owner side\n",
    "theory_output = torch.sqrt(torch.var(data_tensor, correction = 0))\n",
    "data_mean = torch.mean(data_tensor)\n",
    "print(\"theory output: \", theory_output)\n",
    "class prover_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(prover_model, self).__init__()\n",
    "        # w represents mean in this case\n",
    "        self.w = nn.Parameter(data = theory_output, requires_grad = False)\n",
    "        self.data_mean = nn.Parameter(data = data_mean, requires_grad = False)\n",
    "    def forward(self,X):\n",
    "        # some expression of tolerance to error in the inference\n",
    "       return (torch.logical_and(torch.abs(torch.sum((X-self.data_mean)*(X-self.data_mean))-self.w*self.w*X.size()[1])<0.01*self.w*self.w*X.size()[1],torch.abs(torch.sum(X)-X.size()[1]*(self.data_mean))<0.01*torch.sum(X)),self.w)\n",
    "prover_gen(prover_model, [data_path], witness_path, prover_model_path, prover_compiled_model_path, settings_path, proof_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_inputs:  1\n",
      "prf instances:  [[[10512373747352303962, 11798585516934984832, 13421675179368312123, 2200257403316998104], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287], [956231351009279921, 10951436676983309100, 2250248050743556928, 1228298028208591648]]]\n",
      "proof boolean:  1.0\n",
      "proof result 1 : 15.0\n",
      "verified\n"
     ]
    }
   ],
   "source": [
    "# Verifier verifies\n",
    "verifier_verify(proof_path, settings_path, vk_path, srs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
