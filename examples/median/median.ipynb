{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ezkl==5.0.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 1)) (5.0.8)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 2)) (2.1.1)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 3)) (2.31.0)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 4)) (1.11.4)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 5)) (1.26.2)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 6)) (3.8.2)\n",
      "Requirement already satisfied: statistics in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 7)) (1.0.3.5)\n",
      "Requirement already satisfied: onnx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 8)) (1.15.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.13.1)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.2.1)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (2023.10.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (1.12)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (4.8.0)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.1.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (3.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (1.4.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (4.45.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (3.1.1)\n",
      "Requirement already satisfied: docutils>=0.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from statistics->-r ../../requirements.txt (line 7)) (0.20.1)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from onnx->-r ../../requirements.txt (line 8)) (4.25.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.7->matplotlib->-r ../../requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch->-r ../../requirements.txt (line 2)) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy->torch->-r ../../requirements.txt (line 2)) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ezkl\n",
    "import torch\n",
    "from torch import nn\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../../core.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init path\n",
    "os.makedirs(os.path.dirname('shared/'), exist_ok=True)\n",
    "os.makedirs(os.path.dirname('prover/'), exist_ok=True)\n",
    "verifier_model_path = os.path.join('shared/verifier.onnx')\n",
    "prover_model_path = os.path.join('prover/prover.onnx')\n",
    "verifier_compiled_model_path = os.path.join('shared/verifier.compiled')\n",
    "prover_compiled_model_path = os.path.join('prover/prover.compiled')\n",
    "pk_path = os.path.join('shared/test.pk')\n",
    "vk_path = os.path.join('shared/test.vk')\n",
    "proof_path = os.path.join('shared/test.pf')\n",
    "settings_path = os.path.join('shared/settings.json')\n",
    "srs_path = os.path.join('shared/kzg.srs')\n",
    "witness_path = os.path.join('prover/witness.json')\n",
    "# this is private to prover since it contains actual data\n",
    "comb_data_path = os.path.join('prover/comb_data.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=======================  ZK-STATS FLOW ======================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join('data.json')\n",
    "dummy_data_path = os.path.join('shared/dummy_data.json')\n",
    "\n",
    "f_raw_input = open(data_path, \"r\")\n",
    "data = json.loads(f_raw_input.read())[\"input_data\"][0]\n",
    "data_tensor = torch.reshape(torch.tensor(data),(1, len(data), 1))\n",
    "\n",
    "#  dummy data for data consumer: make the bound approx same as real data\n",
    "dummy_data = np.round(np.random.uniform(min(data), max(data), len(data)),2)\n",
    "json.dump({\"input_data\":[dummy_data.tolist()]}, open(dummy_data_path, 'w'))\n",
    "\n",
    "dummy_data_tensor = torch.reshape(torch.tensor(dummy_data), (1, len(dummy_data),1 ))\n",
    "dummy_theory_output = torch.tensor(np.median(dummy_data))\n",
    "# print(int(len(dummy_data)/2))\n",
    "dummy_lower_to_median = torch.tensor(np.sort(dummy_data)[int(len(dummy_data)/2)-1])\n",
    "dummy_upper_to_median = torch.tensor(np.sort(dummy_data)[int(len(dummy_data)/2)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sort:  53.62\n",
      "sort:  53.63\n",
      "median:  tensor(53.6250, dtype=torch.float64)\n",
      "lower:  tensor(53.6200, dtype=torch.float64)\n",
      "upper:  tensor(53.6300, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# print(\"dummy data:\", dummy_data)\n",
    "print(\"sort: \", np.sort(dummy_data)[149])\n",
    "print(\"sort: \", np.sort(dummy_data)[150])\n",
    "print(\"median: \", dummy_theory_output)\n",
    "print(\"lower: \", dummy_lower_to_median)\n",
    "print(\"upper: \", dummy_upper_to_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy output:  tensor(53.6250, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/y9dw12v976ngdmqz4l7wbsnr0000gn/T/ipykernel_27165/3985421908.py:20: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if(len%2==0):\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/onnx/symbolic_opset9.py:2174: FutureWarning: 'torch.onnx.symbolic_opset9._cast_Bool' is deprecated in version 2.0 and will be removed in the future. Please Avoid using this function and create a Cast node instead.\n",
      "  return fn(g, to_cast_func(g, input, False), to_cast_func(g, other, False))\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/onnx/utils.py:1686: UserWarning: The exported ONNX model failed ONNX shape inference. The model will not be executable by the ONNX Runtime. If this is unintended and you believe there is a bug, please report an issue at https://github.com/pytorch/pytorch/issues. Error reported by strict ONNX shape inference: [ShapeInferenceError] (op_type:Add, node name: /Add_1): A typestr: T, has unsupported type: tensor(bool) (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/jit/serialization/export.cpp:1421.)\n",
      "  _C._check_onnx_proto(proto)\n"
     ]
    }
   ],
   "source": [
    "print(\"dummy output: \", dummy_theory_output)\n",
    "# Verifier/ data consumer side: send desired calculation\n",
    "class verifier_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(verifier_model, self).__init__()\n",
    "        # w represents mean in this case\n",
    "        self.w = nn.Parameter(data = dummy_theory_output, requires_grad = False)\n",
    "        self.lower = nn.Parameter(data = dummy_lower_to_median, requires_grad = False)\n",
    "        self.upper = nn.Parameter(data = dummy_upper_to_median, requires_grad = False)\n",
    "    def forward(self,X):\n",
    "        # some expression of tolerance to error in the inference\n",
    "        count_less = torch.sum((X < self.w).double())\n",
    "        count_equal = torch.sum((X == self.w).double())\n",
    "        len = X.size()[1]\n",
    "        half_len = torch.div(len, 2)\n",
    "\n",
    "        # doesnt support mod if not in conditional\n",
    "       \n",
    "        # For count_equal > 0\n",
    "        if(len%2==0):\n",
    "            is_odd = 0\n",
    "        else:\n",
    "            is_odd = 1\n",
    "        less_cons = count_less<half_len+is_odd\n",
    "        more_cons = count_less+count_equal>half_len\n",
    "\n",
    "        # For count_equal == 0\n",
    "        lower_exist = torch.sum((X == self.lower).double())>0\n",
    "        lower_cons = torch.sum((X>self.lower).double())==half_len\n",
    "        upper_exist = torch.sum((X == self.upper).double())>0\n",
    "        upper_cons = torch.sum((X<self.upper).double())==half_len\n",
    "        bound = count_less==half_len\n",
    "        bound_avg = self.lower+self.upper == bound*2\n",
    "\n",
    "        median_in_cons = torch.logical_and(less_cons, more_cons)\n",
    "        median_out_cons = torch.logical_and(torch.logical_and(bound, bound_avg), torch.logical_and(torch.logical_and(lower_cons, upper_cons), torch.logical_and(lower_exist, upper_exist)))\n",
    "        return (median_in_cons*(count_equal!=0)+median_out_cons*(count_equal ==0), self.w)\n",
    "\n",
    "\n",
    "    \n",
    "verifier_define_calculation(verifier_model, verifier_model_path, [dummy_data_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theory_output:  tensor(49., dtype=torch.float64)\n",
      "==== Generate & Calibrate Setting ====\n",
      "scale:  [0]\n",
      "setting:  {\"run_args\":{\"tolerance\":{\"val\":0.0,\"scale\":1.0},\"input_scale\":0,\"param_scale\":0,\"scale_rebase_multiplier\":10,\"lookup_range\":[-78,196],\"logrows\":14,\"num_inner_cols\":1,\"variables\":[[\"batch_size\",1]],\"input_visibility\":{\"Hashed\":{\"hash_is_public\":true,\"outlets\":[]}},\"output_visibility\":\"Public\",\"param_visibility\":\"Private\"},\"num_rows\":14432,\"total_assignments\":7540,\"total_const_size\":4,\"model_instance_shapes\":[[1],[1]],\"model_output_scales\":[0,0],\"model_input_scales\":[0],\"module_sizes\":{\"kzg\":[],\"poseidon\":[14432,[1]],\"elgamal\":[0,[0]]},\"required_lookups\":[{\"GreaterThan\":{\"a\":0.0}},\"KroneckerDelta\"],\"check_mode\":\"UNSAFE\",\"version\":\"5.0.8\",\"num_blinding_factors\":null}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/y9dw12v976ngdmqz4l7wbsnr0000gn/T/ipykernel_27165/1250105436.py:24: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if(len%2==0):\n"
     ]
    }
   ],
   "source": [
    "# prover calculates settings, send to verifier\n",
    "\n",
    "theory_output = torch.tensor(np.median(data))\n",
    "lower_to_median = torch.tensor(np.sort(data)[int(len(data)/2)-1])\n",
    "upper_to_median = torch.tensor(np.sort(data)[int(len(data)/2)])\n",
    "print(\"Theory_output: \", theory_output)\n",
    "class prover_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(prover_model, self).__init__()\n",
    "        # w represents mean in this case\n",
    "        self.w = nn.Parameter(data = theory_output, requires_grad = False)\n",
    "        self.lower = nn.Parameter(data = lower_to_median, requires_grad = False)\n",
    "        self.upper = nn.Parameter(data = upper_to_median, requires_grad = False)\n",
    "    def forward(self,X):\n",
    "        # some expression of tolerance to error in the inference\n",
    "        count_less = torch.sum((X < self.w).double())\n",
    "        count_equal = torch.sum((X == self.w).double())\n",
    "        len = X.size()[1]\n",
    "        half_len = torch.div(len, 2)\n",
    "\n",
    "        # doesnt support mod if not in conditional\n",
    "\n",
    "        # For count_equal > 0\n",
    "        if(len%2==0):\n",
    "            is_odd = 0\n",
    "        else:\n",
    "            is_odd = 1\n",
    "        less_cons = count_less<half_len+is_odd\n",
    "        more_cons = count_less+count_equal>half_len\n",
    "\n",
    "        # For count_equal == 0\n",
    "        lower_exist = torch.sum((X == self.lower).double())>0\n",
    "        lower_cons = torch.sum((X>self.lower).double())==half_len\n",
    "        upper_exist = torch.sum((X == self.upper).double())>0\n",
    "        upper_cons = torch.sum((X<self.upper).double())==half_len\n",
    "        bound = count_less==half_len\n",
    "        bound_avg = self.lower+self.upper == bound*2\n",
    "\n",
    "        median_in_cons = torch.logical_and(less_cons, more_cons)\n",
    "        median_out_cons = torch.logical_and(torch.logical_and(bound, bound_avg), torch.logical_and(torch.logical_and(lower_cons, upper_cons), torch.logical_and(lower_exist, upper_exist)))\n",
    "        return (median_in_cons*(count_equal!=0)+median_out_cons*(count_equal ==0), self.w)\n",
    "   \n",
    "prover_gen_settings([data_path], comb_data_path, prover_model,prover_model_path, [0], \"resources\", settings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== setting up ezkl ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n",
      "spawning module 2\n",
      "spawning module 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time setup: 1.362818956375122 seconds\n",
      "=======================================\n",
      "Theory output:  tensor(49., dtype=torch.float64)\n",
      "==== Generating Witness ====\n",
      "witness boolean:  1.0\n",
      "witness result 1 : 49.0\n",
      "==== Generating Proof ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proof:  {'instances': [[[10512373747352303962, 11798585516934984832, 13421675179368312123, 2200257403316998104], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287], [5937023402479976189, 6015681745618410760, 9712426403540212160, 757908509798626762]]], 'proof': '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', 'transcript_type': 'EVM'}\n",
      "Time gen prf: 1.984236717224121 seconds\n"
     ]
    }
   ],
   "source": [
    "# Here verifier & prover can concurrently call setup since all params are public to get pk. \n",
    "# Here write as verifier function to emphasize that verifier must calculate its own vk to be sure\n",
    "verifier_setup(verifier_model_path, verifier_compiled_model_path, settings_path, srs_path,vk_path, pk_path )\n",
    "\n",
    "print(\"=======================================\")\n",
    "# Prover generates proof\n",
    "print(\"Theory output: \", theory_output)\n",
    "prover_gen_proof(prover_model_path, comb_data_path, witness_path, prover_compiled_model_path, settings_path, proof_path, pk_path, srs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_inputs:  1\n",
      "prf instances:  [[[10512373747352303962, 11798585516934984832, 13421675179368312123, 2200257403316998104], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287], [5937023402479976189, 6015681745618410760, 9712426403540212160, 757908509798626762]]]\n",
      "proof boolean:  1.0\n",
      "proof result 1 : 49.0\n",
      "verified\n"
     ]
    }
   ],
   "source": [
    "# Verifier verifies\n",
    "verifier_verify(proof_path, settings_path, vk_path, srs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
