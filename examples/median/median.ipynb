{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ezkl==5.0.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 1)) (5.0.8)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 2)) (2.1.1)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 3)) (2.31.0)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 4)) (1.11.4)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 5)) (1.26.2)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 6)) (3.8.2)\n",
      "Requirement already satisfied: statistics in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 7)) (1.0.3.5)\n",
      "Requirement already satisfied: onnx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 8)) (1.15.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.13.1)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.2.1)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (2023.10.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (1.12)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (4.8.0)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.1.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (3.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (1.4.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (4.45.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (3.1.1)\n",
      "Requirement already satisfied: docutils>=0.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from statistics->-r ../../requirements.txt (line 7)) (0.20.1)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from onnx->-r ../../requirements.txt (line 8)) (4.25.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.7->matplotlib->-r ../../requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch->-r ../../requirements.txt (line 2)) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy->torch->-r ../../requirements.txt (line 2)) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ezkl\n",
    "import torch\n",
    "from torch import nn\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../../core.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init path\n",
    "os.makedirs(os.path.dirname('shared/'), exist_ok=True)\n",
    "os.makedirs(os.path.dirname('prover/'), exist_ok=True)\n",
    "verifier_model_path = os.path.join('shared/verifier.onnx')\n",
    "prover_model_path = os.path.join('prover/prover.onnx')\n",
    "verifier_compiled_model_path = os.path.join('shared/verifier.compiled')\n",
    "prover_compiled_model_path = os.path.join('prover/prover.compiled')\n",
    "pk_path = os.path.join('shared/test.pk')\n",
    "vk_path = os.path.join('shared/test.vk')\n",
    "proof_path = os.path.join('shared/test.pf')\n",
    "settings_path = os.path.join('shared/settings.json')\n",
    "srs_path = os.path.join('shared/kzg.srs')\n",
    "witness_path = os.path.join('prover/witness.json')\n",
    "# this is private to prover since it contains actual data\n",
    "comb_data_path = os.path.join('prover/comb_data.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=======================  ZK-STATS FLOW ======================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join('data.json')\n",
    "dummy_data_path = os.path.join('shared/dummy_data.json')\n",
    "\n",
    "f_raw_input = open(data_path, \"r\")\n",
    "data = json.loads(f_raw_input.read())[\"input_data\"][0]\n",
    "data_tensor = torch.reshape(torch.tensor(data),(1, len(data), 1))\n",
    "\n",
    "#  dummy data for data consumer: make the bound approx same as real data\n",
    "dummy_data = np.round(np.random.uniform(min(data), max(data), len(data)),2)\n",
    "json.dump({\"input_data\":[dummy_data.tolist()]}, open(dummy_data_path, 'w'))\n",
    "\n",
    "dummy_data_tensor = torch.reshape(torch.tensor(dummy_data), (1, len(dummy_data),1 ))\n",
    "dummy_theory_output = torch.tensor(np.median(dummy_data))\n",
    "# print(int(len(dummy_data)/2))\n",
    "dummy_lower_to_median = torch.tensor(np.sort(dummy_data)[int(len(dummy_data)/2)-1])\n",
    "dummy_upper_to_median = torch.tensor(np.sort(dummy_data)[int(len(dummy_data)/2)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy output:  tensor(8.9400, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/y9dw12v976ngdmqz4l7wbsnr0000gn/T/ipykernel_55637/2612144315.py:20: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if(len%2==0):\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/onnx/symbolic_opset9.py:2174: FutureWarning: 'torch.onnx.symbolic_opset9._cast_Bool' is deprecated in version 2.0 and will be removed in the future. Please Avoid using this function and create a Cast node instead.\n",
      "  return fn(g, to_cast_func(g, input, False), to_cast_func(g, other, False))\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/onnx/utils.py:1686: UserWarning: The exported ONNX model failed ONNX shape inference. The model will not be executable by the ONNX Runtime. If this is unintended and you believe there is a bug, please report an issue at https://github.com/pytorch/pytorch/issues. Error reported by strict ONNX shape inference: [ShapeInferenceError] (op_type:Add, node name: /Add_1): A typestr: T, has unsupported type: tensor(bool) (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/jit/serialization/export.cpp:1421.)\n",
      "  _C._check_onnx_proto(proto)\n"
     ]
    }
   ],
   "source": [
    "print(\"dummy output: \", dummy_theory_output)\n",
    "# Verifier/ data consumer side: send desired calculation\n",
    "class verifier_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(verifier_model, self).__init__()\n",
    "        # w represents mean in this case\n",
    "        self.w = nn.Parameter(data = dummy_theory_output, requires_grad = False)\n",
    "        self.lower = nn.Parameter(data = dummy_lower_to_median, requires_grad = False)\n",
    "        self.upper = nn.Parameter(data = dummy_upper_to_median, requires_grad = False)\n",
    "    def forward(self,X):\n",
    "        count_less = torch.sum((X < self.w).double())\n",
    "        count_equal = torch.sum((torch.abs(X-self.w)<=torch.abs(0.01*self.w)).double())\n",
    "        len = X.size()[1]\n",
    "        half_len = torch.floor(torch.div(len, 2))\n",
    "\n",
    "        # doesnt support mod if not in conditional\n",
    "       \n",
    "        # For count_equal > 0\n",
    "        if(len%2==0):\n",
    "            is_odd = 0\n",
    "        else:\n",
    "            is_odd = 1\n",
    "        less_cons = count_less<half_len+is_odd\n",
    "        more_cons = count_less+count_equal>half_len\n",
    "\n",
    "\n",
    "        # For count_equal == 0\n",
    "        lower_exist = torch.sum((torch.abs(X-self.lower)<=torch.abs(0.01*self.lower)).double())>0\n",
    "        lower_cons = torch.sum((X>self.lower).double())==half_len\n",
    "        upper_exist = torch.sum((torch.abs(X-self.upper)<=torch.abs(0.01*self.upper)).double())>0\n",
    "        upper_cons = torch.sum((X<self.upper).double())==half_len\n",
    "        bound = count_less==half_len\n",
    "        # 0.02 since 2*0.01\n",
    "        bound_avg = (torch.abs(self.lower+self.upper-2*self.w)<=torch.abs(0.02*self.w))\n",
    "\n",
    "        median_in_cons = torch.logical_and(less_cons, more_cons)\n",
    "        median_out_cons = torch.logical_and(torch.logical_and(bound, bound_avg), torch.logical_and(torch.logical_and(lower_cons, upper_cons), torch.logical_and(lower_exist, upper_exist)))\n",
    "        \n",
    "        return (median_in_cons*(count_equal!=0)+median_out_cons*(count_equal ==0), self.w)\n",
    "\n",
    "    \n",
    "verifier_define_calculation(verifier_model, verifier_model_path, [dummy_data_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theory_output:  tensor(4.6500, dtype=torch.float64)\n",
      "lower:  tensor(4.1000, dtype=torch.float64)\n",
      "upper:  tensor(5.2000, dtype=torch.float64)\n",
      "==== Generate & Calibrate Setting ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/y9dw12v976ngdmqz4l7wbsnr0000gn/T/ipykernel_55637/513316771.py:26: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if(len%2==0):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale:  default\n",
      "setting:  {\"run_args\":{\"tolerance\":{\"val\":0.0,\"scale\":1.0},\"input_scale\":5,\"param_scale\":5,\"scale_rebase_multiplier\":10,\"lookup_range\":[-790,826],\"logrows\":11,\"num_inner_cols\":1,\"variables\":[[\"batch_size\",1]],\"input_visibility\":{\"Hashed\":{\"hash_is_public\":true,\"outlets\":[]}},\"output_visibility\":\"Public\",\"param_visibility\":\"Private\"},\"num_rows\":1312,\"total_assignments\":287,\"total_const_size\":55,\"model_instance_shapes\":[[1],[1]],\"model_output_scales\":[0,5],\"model_input_scales\":[5],\"module_sizes\":{\"kzg\":[],\"poseidon\":[1312,[1]],\"elgamal\":[0,[0]]},\"required_lookups\":[\"Abs\",{\"GreaterThan\":{\"a\":0.0}},\"KroneckerDelta\"],\"check_mode\":\"UNSAFE\",\"version\":\"5.0.8\",\"num_blinding_factors\":null}\n"
     ]
    }
   ],
   "source": [
    "# prover calculates settings, send to verifier\n",
    "\n",
    "theory_output = torch.tensor(np.median(data))\n",
    "lower_to_median = torch.tensor(np.sort(data)[int(len(data)/2)-1])\n",
    "upper_to_median = torch.tensor(np.sort(data)[int(len(data)/2)])\n",
    "print(\"Theory_output: \", theory_output)\n",
    "print(\"lower: \", lower_to_median)\n",
    "print(\"upper: \", upper_to_median)\n",
    "class prover_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(prover_model, self).__init__()\n",
    "        # w represents mean in this case\n",
    "        self.w = nn.Parameter(data = theory_output, requires_grad = False)\n",
    "        self.lower = nn.Parameter(data = lower_to_median, requires_grad = False)\n",
    "        self.upper = nn.Parameter(data = upper_to_median, requires_grad = False)\n",
    "    def forward(self,X):\n",
    "        count_less = torch.sum((X < self.w).double())\n",
    "        count_equal = torch.sum((torch.abs(X-self.w)<=torch.abs(0.01*self.w)).double())\n",
    "        len = X.size()[1]\n",
    "        half_len = torch.floor(torch.div(len, 2))\n",
    "\n",
    "        # doesnt support mod if not in conditional\n",
    "       \n",
    "        # For count_equal > 0\n",
    "        if(len%2==0):\n",
    "            is_odd = 0\n",
    "        else:\n",
    "            is_odd = 1\n",
    "        less_cons = count_less<half_len+is_odd\n",
    "        more_cons = count_less+count_equal>half_len\n",
    "\n",
    "\n",
    "        # For count_equal == 0\n",
    "        lower_exist = torch.sum((torch.abs(X-self.lower)<=torch.abs(0.01*self.lower)).double())>0\n",
    "        lower_cons = torch.sum((X>self.lower).double())==half_len\n",
    "        upper_exist = torch.sum((torch.abs(X-self.upper)<=torch.abs(0.01*self.upper)).double())>0\n",
    "        upper_cons = torch.sum((X<self.upper).double())==half_len\n",
    "        bound = count_less==half_len\n",
    "        # 0.02 since 2*0.01\n",
    "        bound_avg = (torch.abs(self.lower+self.upper-2*self.w)<=torch.abs(0.02*self.w))\n",
    "\n",
    "        median_in_cons = torch.logical_and(less_cons, more_cons)\n",
    "        median_out_cons = torch.logical_and(torch.logical_and(bound, bound_avg), torch.logical_and(torch.logical_and(lower_cons, upper_cons), torch.logical_and(lower_exist, upper_exist)))\n",
    "        \n",
    "        return (median_in_cons*(count_equal!=0)+median_out_cons*(count_equal ==0), self.w)\n",
    "\n",
    " \n",
    "\n",
    "prover_gen_settings([data_path], comb_data_path, prover_model,prover_model_path, \"default\", \"resources\", settings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== setting up ezkl ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 2\n",
      "spawning module 0\n",
      "spawning module 2\n",
      "spawning module 0\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time setup: 0.3114502429962158 seconds\n",
      "=======================================\n",
      "Theory output:  tensor(4.6500, dtype=torch.float64)\n",
      "==== Generating Witness ====\n",
      "witness boolean:  1.0\n",
      "witness result 1 : 4.65625\n",
      "==== Generating Proof ====\n",
      "proof:  {'instances': [[[15776967246226738966, 14470885921245171519, 5947983710744493689, 2326010236508186386], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287], [898490808456445164, 4627731094189474011, 12171376262565855552, 810232741982306196]]], 'proof': '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', 'transcript_type': 'EVM'}\n",
      "Time gen prf: 0.3601400852203369 seconds\n"
     ]
    }
   ],
   "source": [
    "# Here verifier & prover can concurrently call setup since all params are public to get pk. \n",
    "# Here write as verifier function to emphasize that verifier must calculate its own vk to be sure\n",
    "verifier_setup(verifier_model_path, verifier_compiled_model_path, settings_path, srs_path,vk_path, pk_path )\n",
    "\n",
    "print(\"=======================================\")\n",
    "# Prover generates proof\n",
    "print(\"Theory output: \", theory_output)\n",
    "prover_gen_proof(prover_model_path, comb_data_path, witness_path, prover_compiled_model_path, settings_path, proof_path, pk_path, srs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_inputs:  1\n",
      "prf instances:  [[[15776967246226738966, 14470885921245171519, 5947983710744493689, 2326010236508186386], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287], [898490808456445164, 4627731094189474011, 12171376262565855552, 810232741982306196]]]\n",
      "proof boolean:  1.0\n",
      "proof result 1 : 4.65625\n",
      "verified\n"
     ]
    }
   ],
   "source": [
    "# Verifier verifies\n",
    "verifier_verify(proof_path, settings_path, vk_path, srs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
