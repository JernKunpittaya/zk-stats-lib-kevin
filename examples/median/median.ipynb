{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ezkl==7.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 1)) (7.0.0)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 2)) (2.1.1)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 3)) (2.31.0)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 4)) (1.11.4)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 5)) (1.26.2)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 6)) (3.8.2)\n",
      "Requirement already satisfied: statistics in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 7)) (1.0.3.5)\n",
      "Requirement already satisfied: onnx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 8)) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (4.8.0)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.2.1)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (1.12)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (2023.10.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.13.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.1.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (2023.11.17)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (3.1.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (4.45.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (10.1.0)\n",
      "Requirement already satisfied: docutils>=0.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from statistics->-r ../../requirements.txt (line 7)) (0.20.1)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from onnx->-r ../../requirements.txt (line 8)) (4.25.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.7->matplotlib->-r ../../requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch->-r ../../requirements.txt (line 2)) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy->torch->-r ../../requirements.txt (line 2)) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ezkl\n",
    "import torch\n",
    "from torch import nn\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../../zkstats/core.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init path\n",
    "os.makedirs(os.path.dirname('shared/'), exist_ok=True)\n",
    "os.makedirs(os.path.dirname('prover/'), exist_ok=True)\n",
    "verifier_model_path = os.path.join('shared/verifier.onnx')\n",
    "prover_model_path = os.path.join('prover/prover.onnx')\n",
    "verifier_compiled_model_path = os.path.join('shared/verifier.compiled')\n",
    "prover_compiled_model_path = os.path.join('prover/prover.compiled')\n",
    "pk_path = os.path.join('shared/test.pk')\n",
    "vk_path = os.path.join('shared/test.vk')\n",
    "proof_path = os.path.join('shared/test.pf')\n",
    "settings_path = os.path.join('shared/settings.json')\n",
    "srs_path = os.path.join('shared/kzg.srs')\n",
    "witness_path = os.path.join('prover/witness.json')\n",
    "# this is private to prover since it contains actual data\n",
    "comb_data_path = os.path.join('prover/comb_data.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=======================  ZK-STATS FLOW ======================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join('data.json')\n",
    "dummy_data_path = os.path.join('shared/dummy_data.json')\n",
    "\n",
    "f_raw_input = open(data_path, \"r\")\n",
    "data = json.loads(f_raw_input.read())[\"input_data\"][0]\n",
    "data_tensor = torch.reshape(torch.tensor(data),(1, len(data), 1))\n",
    "\n",
    "dummy_data = np.round(np.random.uniform(1,10,len(data)),1)\n",
    "json.dump({\"input_data\":[dummy_data.tolist()]}, open(dummy_data_path, 'w'))\n",
    "\n",
    "dummy_data_tensor = torch.reshape(torch.tensor(dummy_data), (1, len(dummy_data),1 ))\n",
    "dummy_theory_output = torch.tensor(np.median(dummy_data))\n",
    "# print(int(len(dummy_data)/2))\n",
    "dummy_lower_to_median = torch.tensor(np.sort(dummy_data)[int(len(dummy_data)/2)-1])\n",
    "dummy_upper_to_median = torch.tensor(np.sort(dummy_data)[int(len(dummy_data)/2)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy output:  tensor(5.6000, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(\"dummy output: \", dummy_theory_output)\n",
    "# Verifier/ data consumer side: send desired calculation\n",
    "class verifier_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(verifier_model, self).__init__()\n",
    "        # w represents mean in this case\n",
    "        self.w = nn.Parameter(data = dummy_theory_output, requires_grad = False)\n",
    "        self.lower = nn.Parameter(data = dummy_lower_to_median, requires_grad = False)\n",
    "        self.upper = nn.Parameter(data = dummy_upper_to_median, requires_grad = False)\n",
    "    def forward(self,X):\n",
    "        # since within 1%, we regard as same value\n",
    "        count_less = torch.sum((X < 0.99*self.w).double())\n",
    "        count_equal = torch.sum((torch.abs(X-self.w)<=torch.abs(0.01*self.w)).double())\n",
    "        len = X.size()[1]\n",
    "        half_len = torch.floor(torch.div(len, 2))\n",
    "        \n",
    "        # not support modulo yet\n",
    "        less_cons = count_less<half_len+2*(len/2 - torch.floor(len/2))\n",
    "        more_cons = count_less+count_equal>half_len\n",
    "\n",
    "        # For count_equal == 0\n",
    "        lower_exist = torch.sum((torch.abs(X-self.lower)<=torch.abs(0.01*self.lower)).double())>0\n",
    "        lower_cons = torch.sum((X>1.01*self.lower).double())==half_len\n",
    "        upper_exist = torch.sum((torch.abs(X-self.upper)<=torch.abs(0.01*self.upper)).double())>0\n",
    "        upper_cons = torch.sum((X<0.99*self.upper).double())==half_len\n",
    "        bound = count_less==half_len\n",
    "        # 0.02 since 2*0.01\n",
    "        bound_avg = (torch.abs(self.lower+self.upper-2*self.w)<=torch.abs(0.02*self.w))\n",
    "\n",
    "        median_in_cons = torch.logical_and(less_cons, more_cons)\n",
    "        median_out_cons = torch.logical_and(torch.logical_and(bound, bound_avg), torch.logical_and(torch.logical_and(lower_cons, upper_cons), torch.logical_and(lower_exist, upper_exist)))\n",
    "        \n",
    "        return(torch.where(count_equal==0, median_out_cons, median_in_cons), self.w)\n",
    "\n",
    "    \n",
    "verifier_define_calculation(verifier_model, verifier_model_path, [dummy_data_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theory_output:  tensor(49.5500, dtype=torch.float64)\n",
      "lower:  tensor(49.3000, dtype=torch.float64)\n",
      "upper:  tensor(49.8000, dtype=torch.float64)\n",
      "==== Generate & Calibrate Setting ====\n",
      "scale:  default\n",
      "setting:  {\"run_args\":{\"tolerance\":{\"val\":0.0,\"scale\":1.0},\"input_scale\":8,\"param_scale\":8,\"scale_rebase_multiplier\":10,\"lookup_range\":[-25112,24986],\"logrows\":16,\"num_inner_cols\":2,\"variables\":[[\"batch_size\",1]],\"input_visibility\":{\"Hashed\":{\"hash_is_public\":true,\"outlets\":[]}},\"output_visibility\":\"Public\",\"param_visibility\":\"Private\"},\"num_rows\":14432,\"total_assignments\":12046,\"total_const_size\":1816,\"model_instance_shapes\":[[1],[1]],\"model_output_scales\":[0,8],\"model_input_scales\":[8],\"module_sizes\":{\"kzg\":[],\"poseidon\":[14432,[1]],\"elgamal\":[0,[0]]},\"required_lookups\":[\"Abs\",{\"GreaterThan\":{\"a\":0.0}},\"KroneckerDelta\"],\"check_mode\":\"UNSAFE\",\"version\":\"7.0.0\",\"num_blinding_factors\":null}\n"
     ]
    }
   ],
   "source": [
    "# prover calculates settings, send to verifier\n",
    "\n",
    "theory_output = torch.tensor(np.median(data))\n",
    "lower_to_median = torch.tensor(np.sort(data)[int(len(data)/2)-1])\n",
    "upper_to_median = torch.tensor(np.sort(data)[int(len(data)/2)])\n",
    "print(\"Theory_output: \", theory_output)\n",
    "print(\"lower: \", lower_to_median)\n",
    "print(\"upper: \", upper_to_median)\n",
    "class prover_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(prover_model, self).__init__()\n",
    "        # w represents mean in this case\n",
    "        self.w = nn.Parameter(data = theory_output, requires_grad = False)\n",
    "        self.lower = nn.Parameter(data = lower_to_median, requires_grad = False)\n",
    "        self.upper = nn.Parameter(data = upper_to_median, requires_grad = False)\n",
    "    def forward(self,X):\n",
    "        # since within 1%, we regard as same value\n",
    "        count_less = torch.sum((X < 0.99*self.w).double())\n",
    "        count_equal = torch.sum((torch.abs(X-self.w)<=torch.abs(0.01*self.w)).double())\n",
    "        len = X.size()[1]\n",
    "        half_len = torch.floor(torch.div(len, 2))\n",
    "        \n",
    "        # not support modulo yet\n",
    "        less_cons = count_less<half_len+2*(len/2 - torch.floor(len/2))\n",
    "        more_cons = count_less+count_equal>half_len\n",
    "\n",
    "        # For count_equal == 0\n",
    "        lower_exist = torch.sum((torch.abs(X-self.lower)<=torch.abs(0.01*self.lower)).double())>0\n",
    "        lower_cons = torch.sum((X>1.01*self.lower).double())==half_len\n",
    "        upper_exist = torch.sum((torch.abs(X-self.upper)<=torch.abs(0.01*self.upper)).double())>0\n",
    "        upper_cons = torch.sum((X<0.99*self.upper).double())==half_len\n",
    "        bound = count_less==half_len\n",
    "        # 0.02 since 2*0.01\n",
    "        bound_avg = (torch.abs(self.lower+self.upper-2*self.w)<=torch.abs(0.02*self.w))\n",
    "\n",
    "        median_in_cons = torch.logical_and(less_cons, more_cons)\n",
    "        median_out_cons = torch.logical_and(torch.logical_and(bound, bound_avg), torch.logical_and(torch.logical_and(lower_cons, upper_cons), torch.logical_and(lower_exist, upper_exist)))\n",
    "        \n",
    "        return(torch.where(count_equal==0, median_out_cons, median_in_cons), self.w)\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "prover_gen_settings([data_path], comb_data_path, prover_model,prover_model_path, \"default\", \"resources\", settings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== setting up ezkl ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time setup: 6.663752794265747 seconds\n",
      "=======================================\n",
      "Theory output:  tensor(49.5500, dtype=torch.float64)\n",
      "!@# compiled_model exists? True\n",
      "!@# compiled_model exists? True\n",
      "==== Generating Witness ====\n",
      "witness boolean:  1.0\n",
      "witness result 1 : 49.55078125\n",
      "==== Generating Proof ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proof:  {'instances': [[[3042937791208075219, 8157070662846698822, 3804781648660056856, 172406108020799675], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287], [18341455175509539295, 12796101019039945164, 1607286914885633240, 1929881192315725821]]], 'proof': '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', 'transcript_type': 'EVM'}\n",
      "Time gen prf: 9.588904857635498 seconds\n"
     ]
    }
   ],
   "source": [
    "# Here verifier & prover can concurrently call setup since all params are public to get pk. \n",
    "# Here write as verifier function to emphasize that verifier must calculate its own vk to be sure\n",
    "verifier_setup(verifier_model_path, verifier_compiled_model_path, settings_path,vk_path, pk_path )\n",
    "\n",
    "print(\"=======================================\")\n",
    "# Prover generates proof\n",
    "print(\"Theory output: \", theory_output)\n",
    "prover_gen_proof(prover_model_path, comb_data_path, witness_path, prover_compiled_model_path, settings_path, proof_path, pk_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_inputs:  1\n",
      "prf instances:  [[[3042937791208075219, 8157070662846698822, 3804781648660056856, 172406108020799675], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287], [18341455175509539295, 12796101019039945164, 1607286914885633240, 1929881192315725821]]]\n",
      "proof boolean:  1.0\n",
      "proof result 1 : 49.55078125\n",
      "verified\n"
     ]
    }
   ],
   "source": [
    "# Verifier verifies\n",
    "verifier_verify(proof_path, settings_path, vk_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
