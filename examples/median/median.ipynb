{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ezkl==5.0.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 1)) (5.0.8)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 2)) (2.1.1)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 3)) (2.31.0)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 4)) (1.11.4)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 5)) (1.26.2)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 6)) (3.8.2)\n",
      "Requirement already satisfied: statistics in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 7)) (1.0.3.5)\n",
      "Requirement already satisfied: onnx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 8)) (1.15.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.13.1)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.2.1)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (2023.10.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (1.12)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (4.8.0)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.1.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (3.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (1.4.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (4.45.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (3.1.1)\n",
      "Requirement already satisfied: docutils>=0.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from statistics->-r ../../requirements.txt (line 7)) (0.20.1)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from onnx->-r ../../requirements.txt (line 8)) (4.25.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.7->matplotlib->-r ../../requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch->-r ../../requirements.txt (line 2)) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy->torch->-r ../../requirements.txt (line 2)) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ezkl\n",
    "import torch\n",
    "from torch import nn\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../../zkstats/core.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init path\n",
    "os.makedirs(os.path.dirname('shared/'), exist_ok=True)\n",
    "os.makedirs(os.path.dirname('prover/'), exist_ok=True)\n",
    "verifier_model_path = os.path.join('shared/verifier.onnx')\n",
    "prover_model_path = os.path.join('prover/prover.onnx')\n",
    "verifier_compiled_model_path = os.path.join('shared/verifier.compiled')\n",
    "prover_compiled_model_path = os.path.join('prover/prover.compiled')\n",
    "pk_path = os.path.join('shared/test.pk')\n",
    "vk_path = os.path.join('shared/test.vk')\n",
    "proof_path = os.path.join('shared/test.pf')\n",
    "settings_path = os.path.join('shared/settings.json')\n",
    "srs_path = os.path.join('shared/kzg.srs')\n",
    "witness_path = os.path.join('prover/witness.json')\n",
    "# this is private to prover since it contains actual data\n",
    "comb_data_path = os.path.join('prover/comb_data.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=======================  ZK-STATS FLOW ======================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join('data.json')\n",
    "dummy_data_path = os.path.join('shared/dummy_data.json')\n",
    "\n",
    "f_raw_input = open(data_path, \"r\")\n",
    "data = json.loads(f_raw_input.read())[\"input_data\"][0]\n",
    "data_tensor = torch.reshape(torch.tensor(data),(1, len(data), 1))\n",
    "\n",
    "#  dummy data for data consumer: make the bound approx same as real data\n",
    "dummy_data = np.round(np.random.uniform(min(data), max(data), len(data)),2)\n",
    "json.dump({\"input_data\":[dummy_data.tolist()]}, open(dummy_data_path, 'w'))\n",
    "\n",
    "dummy_data_tensor = torch.reshape(torch.tensor(dummy_data), (1, len(dummy_data),1 ))\n",
    "dummy_theory_output = torch.tensor(np.median(dummy_data))\n",
    "# print(int(len(dummy_data)/2))\n",
    "dummy_lower_to_median = torch.tensor(np.sort(dummy_data)[int(len(dummy_data)/2)-1])\n",
    "dummy_upper_to_median = torch.tensor(np.sort(dummy_data)[int(len(dummy_data)/2)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy output:  tensor(10.6600, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/y9dw12v976ngdmqz4l7wbsnr0000gn/T/ipykernel_33271/3330003512.py:20: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if(len%2==0):\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/onnx/symbolic_opset9.py:2174: FutureWarning: 'torch.onnx.symbolic_opset9._cast_Bool' is deprecated in version 2.0 and will be removed in the future. Please Avoid using this function and create a Cast node instead.\n",
      "  return fn(g, to_cast_func(g, input, False), to_cast_func(g, other, False))\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/onnx/utils.py:1686: UserWarning: The exported ONNX model failed ONNX shape inference. The model will not be executable by the ONNX Runtime. If this is unintended and you believe there is a bug, please report an issue at https://github.com/pytorch/pytorch/issues. Error reported by strict ONNX shape inference: [ShapeInferenceError] (op_type:Add, node name: /Add_1): A typestr: T, has unsupported type: tensor(bool) (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/jit/serialization/export.cpp:1421.)\n",
      "  _C._check_onnx_proto(proto)\n"
     ]
    }
   ],
   "source": [
    "print(\"dummy output: \", dummy_theory_output)\n",
    "# Verifier/ data consumer side: send desired calculation\n",
    "class verifier_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(verifier_model, self).__init__()\n",
    "        # w represents mean in this case\n",
    "        self.w = nn.Parameter(data = dummy_theory_output, requires_grad = False)\n",
    "        self.lower = nn.Parameter(data = dummy_lower_to_median, requires_grad = False)\n",
    "        self.upper = nn.Parameter(data = dummy_upper_to_median, requires_grad = False)\n",
    "    def forward(self,X):\n",
    "        # some expression of tolerance to error in the inference\n",
    "        count_less = torch.sum((X < self.w).double())\n",
    "        count_equal = torch.sum((torch.abs(X-self.w)<0.01*self.w).double())\n",
    "        len = X.size()[1]\n",
    "        half_len = torch.floor(torch.div(len, 2))\n",
    "\n",
    "        # doesnt support mod if not in conditional\n",
    "       \n",
    "        # For count_equal > 0\n",
    "        if(len%2==0):\n",
    "            is_odd = 0\n",
    "        else:\n",
    "            is_odd = 1\n",
    "        less_cons = count_less<half_len+is_odd\n",
    "        more_cons = count_less+count_equal>half_len\n",
    "\n",
    "\n",
    "        # For count_equal == 0\n",
    "        lower_exist = torch.sum((torch.abs(X-self.lower)<0.01*self.lower).double())>0\n",
    "        lower_cons = torch.sum((X>self.lower).double())==half_len\n",
    "        upper_exist = torch.sum((torch.abs(X-self.upper)<0.01*self.upper).double())>0\n",
    "        upper_cons = torch.sum((X<self.upper).double())==half_len\n",
    "        bound = count_less==half_len\n",
    "        bound_avg = (torch.abs(self.lower+self.upper-2*self.w)<0.02*self.w)\n",
    "\n",
    "        median_in_cons = torch.logical_and(less_cons, more_cons)\n",
    "        median_out_cons = torch.logical_and(torch.logical_and(bound, bound_avg), torch.logical_and(torch.logical_and(lower_cons, upper_cons), torch.logical_and(lower_exist, upper_exist)))\n",
    "        \n",
    "        return (median_in_cons*(count_equal!=0)+median_out_cons*(count_equal ==0), self.w)\n",
    "\n",
    "    \n",
    "verifier_define_calculation(verifier_model, verifier_model_path, [dummy_data_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theory_output:  tensor(4.6500, dtype=torch.float64)\n",
      "lower:  tensor(4.1000, dtype=torch.float64)\n",
      "upper:  tensor(5.2000, dtype=torch.float64)\n",
      "half len:  tensor(3.)\n",
      "count+:  tensor(3., dtype=torch.float64)\n",
      "result:  tensor(True)\n",
      "==== Generate & Calibrate Setting ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/y9dw12v976ngdmqz4l7wbsnr0000gn/T/ipykernel_33271/36507449.py:27: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if(len%2==0):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale:  default\n",
      "setting:  {\"run_args\":{\"tolerance\":{\"val\":0.0,\"scale\":1.0},\"input_scale\":5,\"param_scale\":5,\"scale_rebase_multiplier\":10,\"lookup_range\":[-824,826],\"logrows\":11,\"num_inner_cols\":1,\"variables\":[[\"batch_size\",1]],\"input_visibility\":{\"Hashed\":{\"hash_is_public\":true,\"outlets\":[]}},\"output_visibility\":\"Public\",\"param_visibility\":\"Private\"},\"num_rows\":1312,\"total_assignments\":230,\"total_const_size\":13,\"model_instance_shapes\":[[1],[1]],\"model_output_scales\":[0,5],\"model_input_scales\":[5],\"module_sizes\":{\"kzg\":[],\"poseidon\":[1312,[1]],\"elgamal\":[0,[0]]},\"required_lookups\":[\"Abs\",{\"GreaterThan\":{\"a\":0.0}},\"KroneckerDelta\"],\"check_mode\":\"UNSAFE\",\"version\":\"5.0.8\",\"num_blinding_factors\":null}\n"
     ]
    }
   ],
   "source": [
    "# prover calculates settings, send to verifier\n",
    "\n",
    "theory_output = torch.tensor(np.median(data))\n",
    "lower_to_median = torch.tensor(np.sort(data)[int(len(data)/2)-1])\n",
    "upper_to_median = torch.tensor(np.sort(data)[int(len(data)/2)])\n",
    "print(\"Theory_output: \", theory_output)\n",
    "print(\"lower: \", lower_to_median)\n",
    "print(\"upper: \", upper_to_median)\n",
    "class prover_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(prover_model, self).__init__()\n",
    "        # w represents mean in this case\n",
    "        self.w = nn.Parameter(data = theory_output, requires_grad = False)\n",
    "        self.lower = nn.Parameter(data = lower_to_median, requires_grad = False)\n",
    "        self.upper = nn.Parameter(data = upper_to_median, requires_grad = False)\n",
    "    def forward(self,X):\n",
    "        # some expression of tolerance to error in the inference\n",
    "        count_less = torch.sum((X < self.w).double())\n",
    "        count_equal = torch.sum((torch.abs(X-self.w)<0.01*self.w).double())\n",
    "\n",
    "        len = X.size()[1]\n",
    "        half_len = torch.floor(torch.div(len, 2))\n",
    "\n",
    "        # doesnt support mod if not in conditional\n",
    "\n",
    "        # For count_equal > 0\n",
    "        if(len%2==0):\n",
    "            is_odd = 0\n",
    "        else:\n",
    "            is_odd = 1\n",
    "        less_cons = count_less<half_len+is_odd\n",
    "        more_cons = count_less+count_equal>half_len\n",
    "        print(\"half len: \", half_len)\n",
    "        print(\"count+: \", count_equal+count_less)\n",
    "\n",
    "        # For count_equal == 0\n",
    "        lower_exist = torch.sum((torch.abs(X-self.lower)<0.01*self.lower).double())>0\n",
    "        lower_cons = torch.sum((X>self.lower).double())==half_len\n",
    "        upper_exist = torch.sum((torch.abs(X-self.upper)<0.01*self.lower).double())>0\n",
    "        upper_cons = torch.sum((X<self.upper).double())==half_len\n",
    "        bound = count_less==half_len\n",
    "        bound_avg = (torch.abs(self.lower+self.upper-2*self.w)<0.02*self.w)\n",
    "\n",
    "        median_in_cons = torch.logical_and(less_cons, more_cons)\n",
    "        median_out_cons = torch.logical_and(torch.logical_and(bound, bound_avg), torch.logical_and(torch.logical_and(lower_cons, upper_cons), torch.logical_and(lower_exist, upper_exist)))\n",
    "\n",
    "        print(\"result: \",median_in_cons*(count_equal!=0)+median_out_cons*(count_equal ==0) )\n",
    "        return (median_in_cons*(count_equal!=0)+median_out_cons*(count_equal ==0), self.w)\n",
    "\n",
    "\n",
    "prover_gen_settings([data_path], comb_data_path, prover_model,prover_model_path, \"default\", \"resources\", settings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== setting up ezkl ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n",
      "spawning module 2\n",
      "spawning module 0\n",
      "spawning module 2\n",
      "spawning module 0\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time setup: 0.3002300262451172 seconds\n",
      "=======================================\n",
      "Theory output:  tensor(4.6500, dtype=torch.float64)\n",
      "==== Generating Witness ====\n",
      "witness boolean:  1.0\n",
      "witness result 1 : 4.65625\n",
      "==== Generating Proof ====\n",
      "proof:  {'instances': [[[15776967246226738966, 14470885921245171519, 5947983710744493689, 2326010236508186386], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287], [898490808456445164, 4627731094189474011, 12171376262565855552, 810232741982306196]]], 'proof': '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', 'transcript_type': 'EVM'}\n",
      "Time gen prf: 0.3559250831604004 seconds\n"
     ]
    }
   ],
   "source": [
    "# Here verifier & prover can concurrently call setup since all params are public to get pk. \n",
    "# Here write as verifier function to emphasize that verifier must calculate its own vk to be sure\n",
    "verifier_setup(verifier_model_path, verifier_compiled_model_path, settings_path, srs_path,vk_path, pk_path )\n",
    "\n",
    "print(\"=======================================\")\n",
    "# Prover generates proof\n",
    "print(\"Theory output: \", theory_output)\n",
    "prover_gen_proof(prover_model_path, comb_data_path, witness_path, prover_compiled_model_path, settings_path, proof_path, pk_path, srs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_inputs:  1\n",
      "prf instances:  [[[15776967246226738966, 14470885921245171519, 5947983710744493689, 2326010236508186386], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287], [898490808456445164, 4627731094189474011, 12171376262565855552, 810232741982306196]]]\n",
      "proof boolean:  1.0\n",
      "proof result 1 : 4.65625\n",
      "verified\n"
     ]
    }
   ],
   "source": [
    "# Verifier verifies\n",
    "verifier_verify(proof_path, settings_path, vk_path, srs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
