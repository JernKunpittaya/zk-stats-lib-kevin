{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ezkl==7.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 1)) (7.0.0)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 2)) (2.1.1)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 3)) (2.31.0)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 4)) (1.11.4)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 5)) (1.26.2)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 6)) (3.8.2)\n",
      "Requirement already satisfied: statistics in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 7)) (1.0.3.5)\n",
      "Requirement already satisfied: onnx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 8)) (1.15.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (1.12)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (4.8.0)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (2023.10.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (2023.11.17)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (3.6)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (4.45.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (3.1.1)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (10.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: docutils>=0.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from statistics->-r ../../requirements.txt (line 7)) (0.20.1)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from onnx->-r ../../requirements.txt (line 8)) (4.25.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.7->matplotlib->-r ../../requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch->-r ../../requirements.txt (line 2)) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy->torch->-r ../../requirements.txt (line 2)) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ezkl\n",
    "import torch\n",
    "from torch import nn\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../../zkstats/core.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init path\n",
    "os.makedirs(os.path.dirname('shared/'), exist_ok=True)\n",
    "os.makedirs(os.path.dirname('prover/'), exist_ok=True)\n",
    "verifier_model_path = os.path.join('shared/verifier.onnx')\n",
    "prover_model_path = os.path.join('prover/prover.onnx')\n",
    "verifier_compiled_model_path = os.path.join('shared/verifier.compiled')\n",
    "prover_compiled_model_path = os.path.join('prover/prover.compiled')\n",
    "pk_path = os.path.join('shared/test.pk')\n",
    "vk_path = os.path.join('shared/test.vk')\n",
    "proof_path = os.path.join('shared/test.pf')\n",
    "settings_path = os.path.join('shared/settings.json')\n",
    "srs_path = os.path.join('shared/kzg.srs')\n",
    "witness_path = os.path.join('prover/witness.json')\n",
    "# this is private to prover since it contains actual data\n",
    "comb_data_path = os.path.join('prover/comb_data.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=======================  ZK-STATS FLOW ======================="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, Given data1, data2, what if a person requests mean(median(data1), median(data2)). We show that the code is composable enough to do so. However, a person can just request median(data1), and median(data2). Then just compute mean on his own as well "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median1:  tensor(5.6500, dtype=torch.float64)\n",
      "median2:  tensor(5.5500, dtype=torch.float64)\n",
      "theory mean output:  tensor(5.6000, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "data_path1 = os.path.join('data1.json')\n",
    "data_path2 = os.path.join('data2.json')\n",
    "dummy_data_path1 = os.path.join('shared/dummy_data1.json')\n",
    "dummy_data_path2 = os.path.join('shared/dummy_data2.json')\n",
    "\n",
    "f_raw_input1 = open(data_path1, \"r\")\n",
    "data1 = json.loads(f_raw_input1.read())[\"input_data\"][0]\n",
    "data_tensor1 = torch.reshape(torch.tensor(data1),(1, len(data1), 1))\n",
    "f_raw_input2 = open(data_path2, \"r\")\n",
    "data2 = json.loads(f_raw_input2.read())[\"input_data\"][0]\n",
    "data_tensor2 = torch.reshape(torch.tensor(data2),(1, len(data2), 1))\n",
    "\n",
    "dummy_data1 = np.round(np.random.uniform(1,10,len(data1)),1)\n",
    "json.dump({\"input_data\":[dummy_data1.tolist()]}, open(dummy_data_path1, 'w'))\n",
    "dummy_data2 = np.round(np.random.uniform(1,10,len(data2)),1)\n",
    "json.dump({\"input_data\":[dummy_data2.tolist()]}, open(dummy_data_path2, 'w'))\n",
    "\n",
    "\n",
    "dummy_theory_output_median1 = torch.tensor(np.median(dummy_data1))\n",
    "dummy_lower_to_median1 = torch.tensor(np.sort(dummy_data1)[int(len(dummy_data1)/2)-1])\n",
    "dummy_upper_to_median1 = torch.tensor(np.sort(dummy_data1)[int(len(dummy_data1)/2)])\n",
    "\n",
    "dummy_theory_output_median2 = torch.tensor(np.median(dummy_data2))\n",
    "dummy_lower_to_median2 = torch.tensor(np.sort(dummy_data2)[int(len(dummy_data2)/2)-1])\n",
    "dummy_upper_to_median2 = torch.tensor(np.sort(dummy_data2)[int(len(dummy_data2)/2)])\n",
    "\n",
    "print('median1: ', dummy_theory_output_median1)\n",
    "print('median2: ', dummy_theory_output_median2)\n",
    "dummy_theory_output_mean = torch.mean(torch.tensor([dummy_theory_output_median1, dummy_theory_output_median2]))\n",
    "print(\"theory mean output: \", dummy_theory_output_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median(X, median, lower, upper):\n",
    "    # since within 1%, we regard as same value\n",
    "    count_less = torch.sum((X < 0.99*median).double())\n",
    "    count_equal = torch.sum((torch.abs(X-median)<=torch.abs(0.01*median)).double())\n",
    "    len = X.size()[1]\n",
    "    half_len = torch.floor(torch.div(len, 2))\n",
    "        \n",
    "    # not support modulo yet\n",
    "    less_cons = count_less<half_len+2*(len/2 - torch.floor(len/2))\n",
    "    more_cons = count_less+count_equal>half_len\n",
    "\n",
    "    # For count_equal == 0\n",
    "    lower_exist = torch.sum((torch.abs(X-lower)<=torch.abs(0.01*lower)).double())>0\n",
    "    lower_cons = torch.sum((X>1.01*lower).double())==half_len\n",
    "    upper_exist = torch.sum((torch.abs(X-upper)<=torch.abs(0.01*upper)).double())>0\n",
    "    upper_cons = torch.sum((X<0.99*upper).double())==half_len\n",
    "    bound = count_less==half_len\n",
    "    # 0.02 since 2*0.01\n",
    "    bound_avg = (torch.abs(lower+upper-2*median)<=torch.abs(0.02*median))\n",
    "\n",
    "    median_in_cons = torch.logical_and(less_cons, more_cons)\n",
    "    median_out_cons = torch.logical_and(torch.logical_and(bound, bound_avg), torch.logical_and(torch.logical_and(lower_cons, upper_cons), torch.logical_and(lower_exist, upper_exist)))\n",
    "        \n",
    "    return(torch.where(count_equal==0, median_out_cons, median_in_cons), median)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(X, mean):\n",
    "    return (torch.abs(torch.sum(X)-X.size()[1]*(mean))<=torch.abs(0.01*X.size()[1]*mean), mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy output:  tensor(5.6000, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/y9dw12v976ngdmqz4l7wbsnr0000gn/T/ipykernel_11872/478696835.py:17: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  bool3, output_mean = mean(torch.tensor([median1, median2]).reshape(1,-1,1), self.mean)\n",
      "/var/folders/89/y9dw12v976ngdmqz4l7wbsnr0000gn/T/ipykernel_11872/478696835.py:17: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  bool3, output_mean = mean(torch.tensor([median1, median2]).reshape(1,-1,1), self.mean)\n"
     ]
    }
   ],
   "source": [
    "print(\"dummy output: \", dummy_theory_output_mean)\n",
    "# Verifier/ data consumer side: send desired calculation\n",
    "class verifier_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(verifier_model, self).__init__()\n",
    "        # w represents mean in this case\n",
    "        self.median1 = nn.Parameter(data = dummy_theory_output_median1, requires_grad = False)\n",
    "        self.lower1 = nn.Parameter(data = dummy_lower_to_median1, requires_grad = False)\n",
    "        self.upper1 = nn.Parameter(data = dummy_upper_to_median1, requires_grad = False)\n",
    "        self.median2 = nn.Parameter(data = dummy_theory_output_median2, requires_grad = False)\n",
    "        self.lower2 = nn.Parameter(data = dummy_lower_to_median2, requires_grad = False)\n",
    "        self.upper2 = nn.Parameter(data = dummy_upper_to_median2, requires_grad = False)\n",
    "        self.mean = nn.Parameter(data = dummy_theory_output_mean, requires_grad = False)\n",
    "    def forward(self,X1, X2):\n",
    "        bool1, median1 = median(X1, self.median1, self.lower1, self.upper1)\n",
    "        bool2, median2 = median(X2, self.median2, self.lower2, self.upper2)\n",
    "        bool3, output_mean = mean(torch.tensor([median1, median2]).reshape(1,-1,1), self.mean)\n",
    "        return (torch.logical_and(torch.logical_and(bool1, bool2),bool3), output_mean )\n",
    "\n",
    "    \n",
    "verifier_define_calculation(verifier_model, verifier_model_path, [dummy_data_path1, dummy_data_path2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median1:  tensor(49.5500, dtype=torch.float64)\n",
      "median2:  tensor(49.1500, dtype=torch.float64)\n",
      "theory mean output:  tensor(49.3500, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/y9dw12v976ngdmqz4l7wbsnr0000gn/T/ipykernel_11872/3763826393.py:30: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  bool3, output_mean = mean(torch.tensor([median1, median2]).reshape(1,-1,1), self.mean)\n",
      "/var/folders/89/y9dw12v976ngdmqz4l7wbsnr0000gn/T/ipykernel_11872/3763826393.py:30: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  bool3, output_mean = mean(torch.tensor([median1, median2]).reshape(1,-1,1), self.mean)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Generate & Calibrate Setting ====\n",
      "scale:  default\n",
      "setting:  {\"run_args\":{\"tolerance\":{\"val\":0.0,\"scale\":1.0},\"input_scale\":8,\"param_scale\":8,\"scale_rebase_multiplier\":10,\"lookup_range\":[-25518,25754],\"logrows\":16,\"num_inner_cols\":2,\"variables\":[[\"batch_size\",1]],\"input_visibility\":{\"Hashed\":{\"hash_is_public\":true,\"outlets\":[]}},\"output_visibility\":\"Public\",\"param_visibility\":\"Private\"},\"num_rows\":20992,\"total_assignments\":16092,\"total_const_size\":2432,\"model_instance_shapes\":[[1],[1]],\"model_output_scales\":[0,8],\"model_input_scales\":[8,8],\"module_sizes\":{\"kzg\":[],\"poseidon\":[20992,[2]],\"elgamal\":[0,[0]]},\"required_lookups\":[\"Abs\",{\"GreaterThan\":{\"a\":0.0}},\"KroneckerDelta\"],\"check_mode\":\"UNSAFE\",\"version\":\"7.0.0\",\"num_blinding_factors\":null}\n"
     ]
    }
   ],
   "source": [
    "# prover calculates settings, send to verifier\n",
    "\n",
    "theory_output_median1 = torch.tensor(np.median(data1))\n",
    "lower_to_median1 = torch.tensor(np.sort(data1)[int(len(data1)/2)-1])\n",
    "upper_to_median1 = torch.tensor(np.sort(data1)[int(len(data1)/2)])\n",
    "\n",
    "theory_output_median2 = torch.tensor(np.median(data2))\n",
    "lower_to_median2 = torch.tensor(np.sort(data2)[int(len(data2)/2)-1])\n",
    "upper_to_median2 = torch.tensor(np.sort(data2)[int(len(data2)/2)])\n",
    "\n",
    "print('median1: ', theory_output_median1)\n",
    "print('median2: ', theory_output_median2)\n",
    "theory_output_mean = torch.mean(torch.tensor([theory_output_median1, theory_output_median2]))\n",
    "print(\"theory mean output: \", theory_output_mean)\n",
    "\n",
    "class prover_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(prover_model, self).__init__()\n",
    "        # w represents mean in this case\n",
    "        self.median1 = nn.Parameter(data = theory_output_median1, requires_grad = False)\n",
    "        self.lower1 = nn.Parameter(data = lower_to_median1, requires_grad = False)\n",
    "        self.upper1 = nn.Parameter(data = upper_to_median1, requires_grad = False)\n",
    "        self.median2 = nn.Parameter(data = theory_output_median2, requires_grad = False)\n",
    "        self.lower2 = nn.Parameter(data = lower_to_median2, requires_grad = False)\n",
    "        self.upper2 = nn.Parameter(data = upper_to_median2, requires_grad = False)\n",
    "        self.mean = nn.Parameter(data = theory_output_mean, requires_grad = False)\n",
    "    def forward(self,X1, X2):\n",
    "        bool1, median1 = median(X1, self.median1, self.lower1, self.upper1)\n",
    "        bool2, median2 = median(X2, self.median2, self.lower2, self.upper2)\n",
    "        bool3, output_mean = mean(torch.tensor([median1, median2]).reshape(1,-1,1), self.mean)\n",
    "        return (torch.logical_and(torch.logical_and(bool1, bool2),bool3), output_mean )\n",
    "\n",
    " \n",
    "\n",
    "prover_gen_settings([data_path1, data_path2], comb_data_path, prover_model,prover_model_path, \"default\", \"resources\", settings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== setting up ezkl ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time setup: 8.246044874191284 seconds\n",
      "=======================================\n",
      "Theory output:  tensor(49.3500, dtype=torch.float64)\n",
      "!@# compiled_model exists? True\n",
      "!@# compiled_model exists? True\n",
      "==== Generating Witness ====\n",
      "witness boolean:  1.0\n",
      "witness result 1 : 49.3515625\n",
      "==== Generating Proof ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proof:  {'instances': [[[3042937791208075219, 8157070662846698822, 3804781648660056856, 172406108020799675], [15295097400487804665, 12861486368330479023, 3350118022201779210, 343142782800691716], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287], [10870267098303494893, 1752989342377741058, 8860763459400202009, 2635465469930673149]]], 'proof': '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', 'transcript_type': 'EVM'}\n",
      "Time gen prf: 10.191311120986938 seconds\n"
     ]
    }
   ],
   "source": [
    "# Here verifier & prover can concurrently call setup since all params are public to get pk. \n",
    "# Here write as verifier function to emphasize that verifier must calculate its own vk to be sure\n",
    "verifier_setup(verifier_model_path, verifier_compiled_model_path, settings_path,vk_path, pk_path )\n",
    "\n",
    "print(\"=======================================\")\n",
    "# Prover generates proof\n",
    "print(\"Theory output: \", theory_output_mean)\n",
    "prover_gen_proof(prover_model_path, comb_data_path, witness_path, prover_compiled_model_path, settings_path, proof_path, pk_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_inputs:  2\n",
      "prf instances:  [[[3042937791208075219, 8157070662846698822, 3804781648660056856, 172406108020799675], [15295097400487804665, 12861486368330479023, 3350118022201779210, 343142782800691716], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287], [10870267098303494893, 1752989342377741058, 8860763459400202009, 2635465469930673149]]]\n",
      "proof boolean:  1.0\n",
      "proof result 1 : 49.3515625\n",
      "verified\n"
     ]
    }
   ],
   "source": [
    "# Verifier verifies\n",
    "verifier_verify(proof_path, settings_path, vk_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
