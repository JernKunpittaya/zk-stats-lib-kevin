{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ezkl==5.0.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 1)) (5.0.8)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 2)) (2.1.1)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 3)) (2.31.0)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 4)) (1.11.4)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 5)) (1.26.2)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 6)) (3.8.2)\n",
      "Requirement already satisfied: statistics in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 7)) (1.0.3.5)\n",
      "Requirement already satisfied: onnx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 8)) (1.15.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.13.1)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.2.1)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (2023.10.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (1.12)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (4.8.0)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.1.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (3.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (1.4.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (4.45.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (3.1.1)\n",
      "Requirement already satisfied: docutils>=0.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from statistics->-r ../../requirements.txt (line 7)) (0.20.1)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from onnx->-r ../../requirements.txt (line 8)) (4.25.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.7->matplotlib->-r ../../requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch->-r ../../requirements.txt (line 2)) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy->torch->-r ../../requirements.txt (line 2)) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ezkl\n",
    "import torch\n",
    "from torch import nn\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export model\n",
    "def export_onnx(model, data_tensor_array, model_loc):\n",
    "  circuit = model()\n",
    "\n",
    "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "  # print(device)\n",
    "\n",
    "  circuit.to(device)\n",
    "\n",
    "  # Flips the neural net into inference mode\n",
    "  circuit.eval()\n",
    "  input_names = []\n",
    "  dynamic_axes = {}\n",
    "\n",
    "  data_tensor_tuple = ()\n",
    "  for i in range(len(data_tensor_array)):\n",
    "    data_tensor_tuple += (data_tensor_array[i],)\n",
    "    input_index = \"input\"+str(i+1)\n",
    "    input_names.append(input_index)\n",
    "    dynamic_axes[input_index] = {0 : 'batch_size'}\n",
    "  dynamic_axes[\"output\"] = {0 : 'batch_size'}\n",
    "\n",
    "  # Export the model\n",
    "  torch.onnx.export(circuit,               # model being run\n",
    "                      data_tensor_tuple,                   # model input (or a tuple for multiple inputs)\n",
    "                      model_loc,            # where to save the model (can be a file or file-like object)\n",
    "                      export_params=True,        # store the trained parameter weights inside the model file\n",
    "                      opset_version=11,          # the ONNX version to export the model to\n",
    "                      do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                      input_names = input_names,   # the model's input names\n",
    "                      output_names = ['output'], # the model's output names\n",
    "                      dynamic_axes=dynamic_axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode is either \"accuracy\" or \"resources\"\n",
    "\n",
    "def gen_settings(comb_data_path, onnx_filename, scale, mode, settings_filename):\n",
    "  print(\"==== Generate & Calibrate Setting ====\")\n",
    "  # Set input to be Poseidon Hash, and param of computation graph to be public\n",
    "  # Poseidon is not homomorphic additive, maybe consider Pedersens or Dory commitment.\n",
    "  gip_run_args = ezkl.PyRunArgs()\n",
    "  gip_run_args.input_visibility = \"hashed\"  # matrix and generalized inverse commitments\n",
    "  gip_run_args.output_visibility = \"public\"   # no parameters used\n",
    "  gip_run_args.param_visibility = \"private\" # should be Tensor(True)--> to enforce arbitrary data in w\n",
    "\n",
    " # generate settings\n",
    "  ezkl.gen_settings(onnx_filename, settings_filename, py_run_args=gip_run_args)\n",
    "  if scale ==\"default\":\n",
    "    ezkl.calibrate_settings(\n",
    "    comb_data_path, onnx_filename, settings_filename, mode)\n",
    "  else:\n",
    "    ezkl.calibrate_settings(\n",
    "    comb_data_path, onnx_filename, settings_filename, mode, scales = scale)\n",
    "\n",
    "  assert os.path.exists(settings_filename)\n",
    "  assert os.path.exists(comb_data_path)\n",
    "  assert os.path.exists(onnx_filename)\n",
    "  f_setting = open(settings_filename, \"r\")\n",
    "  print(\"scale: \", scale)\n",
    "  print(\"setting: \", f_setting.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifier_init(verifier_model, verifier_model_path, verifier_compiled_model_path, dummy_data_path_array, settings_path, srs_path, pk_path, vk_path, scale, mode):\n",
    "\n",
    "  # load data from dummy_data_path_array into dummy_data_array\n",
    "  dummy_data_tensor_array = []\n",
    "  comb_dummy_data = []\n",
    "  for path in dummy_data_path_array:\n",
    "    dummy_data = np.array(json.loads(open(path, \"r\").read())[\"input_data\"][0])\n",
    "    # print(\"dumm: \", dummy_data)\n",
    "    dummy_data_tensor_array.append(torch.reshape(torch.tensor(dummy_data), (1, len(dummy_data),1 )))\n",
    "    comb_dummy_data.append(dummy_data.tolist())\n",
    "  # export onnx file\n",
    "  export_onnx(verifier_model,dummy_data_tensor_array, verifier_model_path)\n",
    "\n",
    "  comb_dummy_data_path = os.path.join('generated/comb_dummy_data.json')\n",
    "  # Serialize data into file:\n",
    "  json.dump(dict(input_data = comb_dummy_data), open(comb_dummy_data_path, 'w' ))\n",
    "\n",
    "  # gen + calibrate setting\n",
    "  gen_settings(comb_dummy_data_path, verifier_model_path, scale, mode, settings_path)\n",
    "\n",
    "  # compile circuit\n",
    "  res = ezkl.compile_circuit(verifier_model_path, verifier_compiled_model_path, settings_path)\n",
    "  assert res == True\n",
    "\n",
    "  # srs path\n",
    "  res = ezkl.get_srs(srs_path, settings_path)\n",
    "\n",
    "  # setupt vk, pk param for use..... prover can use same pk or can init their own!\n",
    "  print(\"==== setting up ezkl ====\")\n",
    "  start_time = time.time()\n",
    "  res = ezkl.setup(\n",
    "        verifier_compiled_model_path,\n",
    "        vk_path,\n",
    "        pk_path,\n",
    "        srs_path)\n",
    "  end_time = time.time()\n",
    "  time_setup = end_time -start_time\n",
    "  print(f\"Time setup: {time_setup} seconds\")\n",
    "\n",
    "  assert res == True\n",
    "  assert os.path.isfile(vk_path)\n",
    "  assert os.path.isfile(pk_path)\n",
    "  assert os.path.isfile(settings_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prover_gen(prover_model, data_path_array, witness_path, prover_model_path, prover_compiled_model_path, settings_path, proof_path):\n",
    "  # load data from data_path\n",
    "  # data = json.loads(open(data_path, \"r\").read())[\"input_data\"][0]\n",
    "  # data_tensor = torch.reshape(torch.tensor(data), (1, len(data),1 ))\n",
    "\n",
    "\n",
    "  data_tensor_array = []\n",
    "  comb_data = []\n",
    "  for path in data_path_array:\n",
    "    data = np.array(json.loads(open(path, \"r\").read())[\"input_data\"][0])\n",
    "    # print(\"dumm: \", dummy_data)\n",
    "    data_tensor_array.append(torch.reshape(torch.tensor(data), (1, len(data),1 )))\n",
    "    comb_data.append(data.tolist())\n",
    "\n",
    "  # export onnx file\n",
    "  export_onnx(prover_model, data_tensor_array, prover_model_path)\n",
    "\n",
    "  comb_data_path = os.path.join('generated/comb_data.json')\n",
    "  # Serialize data into file:\n",
    "  json.dump(dict(input_data = comb_data), open(comb_data_path, 'w' ))\n",
    "\n",
    "  res = ezkl.compile_circuit(prover_model_path, prover_compiled_model_path, settings_path)\n",
    "  assert res == True\n",
    "  # now generate the witness file\n",
    "  print('==== Generating Witness ====')\n",
    "  witness = ezkl.gen_witness(comb_data_path, prover_compiled_model_path, witness_path)\n",
    "  assert os.path.isfile(witness_path)\n",
    "  # print(witness[\"outputs\"])\n",
    "  settings = json.load(open(settings_path))\n",
    "  output_scale = settings['model_output_scales']\n",
    "  print(\"witness boolean: \", ezkl.vecu64_to_float(witness['outputs'][0][0], output_scale[0]))\n",
    "  for i in range(len(witness['outputs'][1])):\n",
    "    print(\"witness result\", i+1,\":\", ezkl.vecu64_to_float(witness['outputs'][1][i], output_scale[1]))\n",
    "\n",
    "  # GENERATE A PROOF\n",
    "  print(\"==== Generating Proof ====\")\n",
    "  start_time = time.time()\n",
    "  res = ezkl.prove(\n",
    "        witness_path,\n",
    "        prover_compiled_model_path,\n",
    "        pk_path,\n",
    "        proof_path,\n",
    "        srs_path,\n",
    "        \"single\",\n",
    "    )\n",
    "\n",
    "  print(\"proof: \" ,res)\n",
    "  end_time = time.time()\n",
    "  time_gen_prf = end_time -start_time\n",
    "  print(f\"Time gen prf: {time_gen_prf} seconds\")\n",
    "  assert os.path.isfile(proof_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifier_verify(proof_path, settings_path, vk_path, srs_path):\n",
    "  # enforce boolean statement to be true\n",
    "  settings = json.load(open(settings_path))\n",
    "  output_scale = settings['model_output_scales']\n",
    "\n",
    "  proof = json.load(open(proof_path))\n",
    "  num_inputs = len(settings['model_input_scales'])\n",
    "  print(\"num_inputs: \", num_inputs)\n",
    "  proof[\"instances\"][0][num_inputs] = ezkl.float_to_vecu64(1.0, output_scale[0])\n",
    "  json.dump(proof, open(proof_path, 'w'))\n",
    "\n",
    "  print(\"prf instances: \", proof['instances'])\n",
    "\n",
    "  print(\"proof boolean: \", ezkl.vecu64_to_float(proof['instances'][0][num_inputs], output_scale[0]))\n",
    "  for i in range(num_inputs+1, len(proof['instances'][0])):\n",
    "    print(\"proof result\",i-num_inputs,\":\", ezkl.vecu64_to_float(proof['instances'][0][i], output_scale[1]))\n",
    "\n",
    "\n",
    "  res = ezkl.verify(\n",
    "        proof_path,\n",
    "        settings_path,\n",
    "        vk_path,\n",
    "        srs_path,\n",
    "    )\n",
    "\n",
    "  assert res == True\n",
    "  print(\"verified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init path\n",
    "os.makedirs(os.path.dirname('generated/'), exist_ok=True)\n",
    "verifier_model_path = os.path.join('generated/verifier.onnx')\n",
    "prover_model_path = os.path.join('generated/prover.onnx')\n",
    "verifier_compiled_model_path = os.path.join('generated/verifier.compiled')\n",
    "prover_compiled_model_path = os.path.join('generated/prover.compiled')\n",
    "pk_path = os.path.join('generated/test.pk')\n",
    "vk_path = os.path.join('generated/test.vk')\n",
    "proof_path = os.path.join('generated/test.pf')\n",
    "settings_path = os.path.join('generated/settings.json')\n",
    "srs_path = os.path.join('generated/kzg.srs')\n",
    "witness_path = os.path.join('generated/witness.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=======================  ZK-STATS FLOW ======================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join('data.json')\n",
    "dummy_data_path = os.path.join('generated/dummy_data.json')\n",
    "\n",
    "f_raw_input = open(data_path, \"r\")\n",
    "data = json.loads(f_raw_input.read())[\"input_data\"][0]\n",
    "data_tensor = torch.reshape(torch.tensor(data),(1, len(data), 1))\n",
    "\n",
    "#  dummy data for data consumer: make the bound approx same as real data\n",
    "dummy_data = np.random.uniform(min(data), max(data), len(data))\n",
    "json.dump({\"input_data\":[dummy_data.tolist()]}, open(dummy_data_path, 'w'))\n",
    "\n",
    "dummy_data_tensor = torch.reshape(torch.tensor(dummy_data), (1, len(dummy_data),1 ))\n",
    "dummy_theory_output = torch.exp(torch.mean(torch.log(dummy_data_tensor)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(46.1673, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(dummy_theory_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x size:  tensor(300)\n",
      "==== Generate & Calibrate Setting ====\n",
      "scale:  [0]\n",
      "setting:  {\"run_args\":{\"tolerance\":{\"val\":0.0,\"scale\":1.0},\"input_scale\":0,\"param_scale\":0,\"scale_rebase_multiplier\":10,\"lookup_range\":[-36,174],\"logrows\":14,\"num_inner_cols\":1,\"variables\":[[\"batch_size\",1]],\"input_visibility\":{\"Hashed\":{\"hash_is_public\":true,\"outlets\":[]}},\"output_visibility\":\"Public\",\"param_visibility\":\"Private\"},\"num_rows\":14432,\"total_assignments\":906,\"total_const_size\":0,\"model_instance_shapes\":[[1],[1]],\"model_output_scales\":[0,0],\"model_input_scales\":[0],\"module_sizes\":{\"kzg\":[],\"poseidon\":[14432,[1]],\"elgamal\":[0,[0]]},\"required_lookups\":[\"Abs\",{\"Ln\":{\"scale\":1.0}},{\"GreaterThan\":{\"a\":0.0}}],\"check_mode\":\"UNSAFE\",\"version\":\"5.0.8\",\"num_blinding_factors\":null}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== setting up ezkl ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time setup: 1.4332208633422852 seconds\n"
     ]
    }
   ],
   "source": [
    "# Verifier/ data consumer side:\n",
    "class verifier_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(verifier_model, self).__init__()\n",
    "        # w represents mean in this case\n",
    "        self.w = nn.Parameter(data = dummy_theory_output, requires_grad = False)\n",
    "\n",
    "    def forward(self,X):\n",
    "        # some expression of tolerance to error in the inference\n",
    "        return (torch.abs((torch.log(self.w)*X.size()[1])-torch.sum(torch.log(X)))<0.01*(torch.log(self.w)*X.size()[1]), self.w)\n",
    "\n",
    "verifier_init(verifier_model, verifier_model_path, verifier_compiled_model_path, [dummy_data_path], settings_path, srs_path, pk_path, vk_path,[0], \"resources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Generating Witness ====\n",
      "witness boolean:  1.0\n",
      "witness result 1 : 50.0\n",
      "==== Generating Proof ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proof:  {'instances': [[[10512373747352303962, 11798585516934984832, 13421675179368312123, 2200257403316998104], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287], [18373208119716085496, 9977853902793730609, 17093442942004944878, 1769661249493325049]]], 'proof': '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', 'transcript_type': 'EVM'}\n",
      "Time gen prf: 2.129973888397217 seconds\n"
     ]
    }
   ],
   "source": [
    "# Prover/ data owner side\n",
    "theory_output = torch.mean(data_tensor)\n",
    "class prover_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(prover_model, self).__init__()\n",
    "        # w represents mean in this case\n",
    "        self.w = nn.Parameter(data = theory_output, requires_grad = False)\n",
    "\n",
    "    def forward(self,X):\n",
    "        # some expression of tolerance to error in the inference\n",
    "        return (torch.abs((torch.log(self.w)*X.size()[1])-torch.sum(torch.log(X)))<0.01*(torch.log(self.w)*X.size()[1]), self.w)\n",
    "prover_gen(prover_model, [data_path], witness_path, prover_model_path, prover_compiled_model_path, settings_path, proof_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_inputs:  1\n",
      "prf instances:  [[[10512373747352303962, 11798585516934984832, 13421675179368312123, 2200257403316998104], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287], [18373208119716085496, 9977853902793730609, 17093442942004944878, 1769661249493325049]]]\n",
      "proof boolean:  1.0\n",
      "proof result 1 : 50.0\n",
      "verified\n",
      "theory mean:  tensor(49.9700)\n"
     ]
    }
   ],
   "source": [
    "# Verifier verifies\n",
    "verifier_verify(proof_path, settings_path, vk_path, srs_path)\n",
    "print(\"theory mean: \", theory_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
