{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ezkl==5.0.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 1)) (5.0.8)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 2)) (2.1.1)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 3)) (2.31.0)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 4)) (1.11.4)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 5)) (1.26.2)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 6)) (3.8.2)\n",
      "Requirement already satisfied: statistics in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 7)) (1.0.3.5)\n",
      "Requirement already satisfied: onnx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 8)) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (4.8.0)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.1.2)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (1.12)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.13.1)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (2023.10.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (4.45.1)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (10.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (1.4.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (3.1.1)\n",
      "Requirement already satisfied: docutils>=0.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from statistics->-r ../../requirements.txt (line 7)) (0.20.1)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from onnx->-r ../../requirements.txt (line 8)) (4.25.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.7->matplotlib->-r ../../requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch->-r ../../requirements.txt (line 2)) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy->torch->-r ../../requirements.txt (line 2)) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ezkl\n",
    "import torch\n",
    "from torch import nn\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../../core.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init path\n",
    "os.makedirs(os.path.dirname('shared/'), exist_ok=True)\n",
    "os.makedirs(os.path.dirname('prover/'), exist_ok=True)\n",
    "verifier_model_path = os.path.join('shared/verifier.onnx')\n",
    "prover_model_path = os.path.join('prover/prover.onnx')\n",
    "verifier_compiled_model_path = os.path.join('shared/verifier.compiled')\n",
    "prover_compiled_model_path = os.path.join('prover/prover.compiled')\n",
    "pk_path = os.path.join('shared/test.pk')\n",
    "vk_path = os.path.join('shared/test.vk')\n",
    "proof_path = os.path.join('shared/test.pf')\n",
    "settings_path = os.path.join('shared/settings.json')\n",
    "srs_path = os.path.join('shared/kzg.srs')\n",
    "witness_path = os.path.join('prover/witness.json')\n",
    "# this is private to prover since it contains actual data\n",
    "comb_data_path = os.path.join('prover/comb_data.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=======================  ZK-STATS FLOW ======================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_vals_path = os.path.join('x1_vals.json')\n",
    "x2_vals_path = os.path.join('x2_vals.json')\n",
    "dummy_x1_vals_path = os.path.join('shared/dummy_x1_vals.json')\n",
    "dummy_x2_vals_path = os.path.join('shared/dummy_x2_vals.json')\n",
    "\n",
    "x1_vals= np.array(json.loads(open(x1_vals_path, \"r\").read())['input_data'][0])\n",
    "dummy_x1_vals = np.random.uniform(min(x1_vals), max(x1_vals), len(x1_vals))\n",
    "json.dump({\"input_data\":[dummy_x1_vals.tolist()]}, open(dummy_x1_vals_path, 'w'))\n",
    "\n",
    "x2_vals= np.array(json.loads(open(x2_vals_path, \"r\").read())['input_data'][0])\n",
    "dummy_x2_vals = np.random.uniform(min(x2_vals), max(x2_vals), len(x2_vals))\n",
    "json.dump({\"input_data\":[dummy_x2_vals.tolist()]}, open(dummy_x2_vals_path, 'w'))\n",
    "\n",
    "\n",
    "y_vals_path = os.path.join('y_vals.json')\n",
    "dummy_y_vals_path = os.path.join('shared/dummy_y_vals.json')\n",
    "\n",
    "y_vals= np.array(json.loads(open(y_vals_path, \"r\").read())['input_data'][0])\n",
    "dummy_y_vals = np.random.uniform(min(y_vals), max(y_vals), len(y_vals))\n",
    "json.dump({\"input_data\":[dummy_y_vals.tolist()]}, open(dummy_y_vals_path, 'w'))\n",
    "\n",
    "\n",
    "def stacked_x(*args):\n",
    "    result = np.column_stack((*args, np.ones_like(args[0])))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lennn:  27\n",
      "reg fit:  [1.98835287 3.14238058 0.06413647]\n",
      "lt 20 reg fit:  [ 2.12311694  3.43333008 -1.03203902]\n",
      "w tensor:  tensor([[[1.9884],\n",
      "         [3.1424],\n",
      "         [0.0641]]], dtype=torch.float64)\n",
      "w lt20 tensor:  tensor([[[ 2.1231],\n",
      "         [ 3.4333],\n",
      "         [-1.0320]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# where y value > 20.0\n",
    "lt20_y_vals = y_vals[y_vals<20.0]\n",
    "lt20_y_vals_tensor = torch.tensor(lt20_y_vals).reshape(1,-1,1)\n",
    "new_size = torch.tensor(lt20_y_vals_tensor.size()[1])\n",
    "\n",
    "lt20_dummy_y_vals = dummy_y_vals[dummy_y_vals<20.0]\n",
    "print(\"lennn: \", len(lt20_dummy_y_vals))\n",
    "lt20_dummy_y_vals_tensor = torch.tensor(lt20_dummy_y_vals).reshape(1,-1,1)\n",
    "new_dummy_size = torch.tensor(lt20_dummy_y_vals_tensor.size()[1])\n",
    "\n",
    "x_one = stacked_x(x1_vals, x2_vals)\n",
    "lt20_x_one = stacked_x(x1_vals[y_vals<20.0], x2_vals[y_vals<20.0])\n",
    "lt20_x_one_tensor = torch.tensor(lt20_x_one).reshape(1, len(lt20_x_one), -1)\n",
    "\n",
    "\n",
    "dummy_x_one = stacked_x(dummy_x1_vals, dummy_x2_vals)\n",
    "lt20_dummy_x_one = stacked_x(dummy_x1_vals[dummy_y_vals<20.0], dummy_x2_vals[dummy_y_vals<20.0])\n",
    "lt20_dummy_x_one_tensor = torch.tensor(lt20_dummy_x_one).reshape(1, len(lt20_dummy_x_one), -1)\n",
    "\n",
    "w_vals = np.matmul(np.matmul(np.linalg.inv(np.matmul(x_one.transpose(), x_one)), x_one.transpose()), y_vals)\n",
    "lt20_w_vals = np.matmul(np.matmul(np.linalg.inv(np.matmul(lt20_x_one.transpose(), lt20_x_one)), lt20_x_one.transpose()), lt20_y_vals)\n",
    "dummy_w_vals = np.matmul(np.matmul(np.linalg.inv(np.matmul(dummy_x_one.transpose(), dummy_x_one)), dummy_x_one.transpose()), dummy_y_vals)\n",
    "lt20_dummy_w_vals = np.matmul(np.matmul(np.linalg.inv(np.matmul(lt20_dummy_x_one.transpose(), lt20_dummy_x_one)), lt20_dummy_x_one.transpose()), lt20_dummy_y_vals)\n",
    "\n",
    "\n",
    "print(\"reg fit: \", w_vals)\n",
    "print(\"lt 20 reg fit: \", lt20_w_vals)\n",
    "\n",
    "w_tensor = torch.tensor(w_vals).reshape(1,-1,1)\n",
    "print(\"w tensor: \", w_tensor)\n",
    "lt20_w_tensor = torch.tensor(lt20_w_vals).reshape(1,-1,1)\n",
    "print(\"w lt20 tensor: \", lt20_w_tensor)\n",
    "# lt20_x1_vals_tensor = x1_vals[y_vals<20.0].reshape(1,-1,1)\n",
    "# lt20_x2_vals_tensor = x2_vals[y_vals<20.0].reshape(1,-1,1)\n",
    "\n",
    "dummy_w_tensor = torch.tensor(dummy_w_vals).reshape(1,-1,1)\n",
    "lt20_dummy_w_tensor = torch.tensor(lt20_dummy_w_vals).reshape(1,-1,1)\n",
    "# lt20_dummy_x1_vals_tensor = dummy_x1_vals[y_vals<20.0].reshape(1,-1,1)\n",
    "# lt20_dummy_x2_vals_tensor = dummy_x2_vals[y_vals<20.0].reshape(1,-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bool result:  tensor(True)\n",
      "value:  tensor(1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/y9dw12v976ngdmqz4l7wbsnr0000gn/T/ipykernel_53260/1290388594.py:39: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if (torch.sum(torch.abs(X_where_T @ X_one_where @ self.w - X_where_T @ Y_where)) < 0.01 * torch.sum(X_where_T @ Y_where)):\n",
      "/var/folders/89/y9dw12v976ngdmqz4l7wbsnr0000gn/T/ipykernel_53260/1290388594.py:40: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  value = torch.tensor(1)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/onnx/utils.py:1686: UserWarning: The exported ONNX model failed ONNX shape inference. The model will not be executable by the ONNX Runtime. If this is unintended and you believe there is a bug, please report an issue at https://github.com/pytorch/pytorch/issues. Error reported by strict ONNX shape inference: [ShapeInferenceError] (op_type:ConstantOfShape, node name: /ConstantOfShape): input typestr: T1, has unsupported type: tensor(float) (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/jit/serialization/export.cpp:1421.)\n",
      "  _C._check_onnx_proto(proto)\n"
     ]
    }
   ],
   "source": [
    "# Verifier/ data consumer side:\n",
    "# Want to calculate regression of y over \n",
    "class verifier_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(verifier_model, self).__init__()\n",
    "        self.w = nn.Parameter(data = lt20_dummy_w_tensor, requires_grad = False)\n",
    "        # self.new_size = nn.Parameter(data = new_dummy_size,requires_grad = False )\n",
    "        self.new_Y = nn.Parameter(data = lt20_dummy_y_vals_tensor,requires_grad = False )\n",
    "        self.new_X_one = nn.Parameter(data = lt20_dummy_x_one_tensor, requires_grad = False)\n",
    "    def forward(self, *args):\n",
    "        # infer Y from the last parameter\n",
    "        Y = args[-1]\n",
    "        # print(\"Y value: \", Y.size())\n",
    "        # print(\"new x1: \", self.new_X_one.size())\n",
    "        len_ratio =  self.new_Y.size()[1]/Y.size()[1]\n",
    "        Y_where = torch.zeros(len_ratio*Y.size()[1], dtype=torch.float64).reshape(1,-1,1)\n",
    "        Y_where[0]=self.new_Y[0]\n",
    "        new_Y_cons = torch.sum((torch.abs(Y[Y<20.0].reshape(1,-1,1)-Y_where)<0.01*Y_where).double())==Y_where.size()[1] \n",
    "        # print(\"y cons: \", new_Y_cons)\n",
    "\n",
    "        # bool_check = torch.zeros(self.new_X_one.size()[2]-1)\n",
    "        # for i in range(self.new_X_one.size()[2]-1):\n",
    "        #     print(\"hey: \", self.new_X_one[:,:,i:i+1].size())\n",
    "        #     print(\"args: \", args[i][Y<20.0].reshape(1,-1,1).size())\n",
    "        #     print(\"diff: \", torch.abs(args[i][Y<20.0].reshape(1,-1,1)-self.new_X_one[:,:,i:i+1] ))\n",
    "        #     print(\"check::: \", torch.sum(torch.abs(args[i][Y<20.0].reshape(1,-1,1)-self.new_X_one[:,:,i:i+1] )<0.01*torch.abs(self.new_X_one[:,:,i:i+1])))\n",
    "        #     bool_check[i] = torch.tensor(1)\n",
    "        # print(\"bool check: \", bool_check)\n",
    "        # bool_cons = torch.sum(bool_check) == self.new_X_one.size()[2]-1\n",
    "        # print(\"bool cons sum: \", bool_cons)\n",
    "        \n",
    "        X_one_where = torch.zeros(3*len_ratio*Y.size()[1], dtype=torch.float64).reshape(1,Y_where.size()[1],-1)\n",
    "        X_one_where[0] = self.new_X_one[0]\n",
    "\n",
    "        X_where_T = torch.transpose(X_one_where, 1,2)\n",
    "        # some expression of tolerance to error in the inference\n",
    "        print(\"bool result: \",torch.sum(torch.abs(X_where_T @ X_one_where @ self.w - X_where_T @ Y_where)) < 0.01 * torch.sum(X_where_T @ Y_where))\n",
    "\n",
    "        if (torch.sum(torch.abs(X_where_T @ X_one_where @ self.w - X_where_T @ Y_where)) < 0.01 * torch.sum(X_where_T @ Y_where)):\n",
    "            value = torch.tensor(1)\n",
    "        else:\n",
    "            value = torch.tensor(0)\n",
    "        print(\"value: \", value)\n",
    "        return (\n",
    "            torch.sum((X_where_T @ X_one_where @ self.w - X_where_T @ Y_where)) < 0.01 * torch.sum(X_where_T @ Y_where),\n",
    "            self.w\n",
    "        )\n",
    "verifier_define_calculation(verifier_model, verifier_model_path, [dummy_x1_vals_path, dummy_x2_vals_path, dummy_y_vals_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theory output:  tensor([[[ 2.1231],\n",
      "         [ 3.4333],\n",
      "         [-1.0320]]], dtype=torch.float64)\n",
      "y cons:  tensor(True)\n",
      "bool sum cons:  tensor(True)\n",
      "bool result:  tensor(True)\n",
      "==== Generate & Calibrate Setting ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/y9dw12v976ngdmqz4l7wbsnr0000gn/T/ipykernel_53260/1598429189.py:54: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if torch.logical_and(new_X_cons, new_Y_cons):\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/onnx/utils.py:1686: UserWarning: The exported ONNX model failed ONNX shape inference. The model will not be executable by the ONNX Runtime. If this is unintended and you believe there is a bug, please report an issue at https://github.com/pytorch/pytorch/issues. Error reported by strict ONNX shape inference: [ShapeInferenceError] (op_type:ConstantOfShape, node name: /ConstantOfShape): input typestr: T1, has unsupported type: tensor(float) (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/jit/serialization/export.cpp:1421.)\n",
      "  _C._check_onnx_proto(proto)\n",
      "thread '<unnamed>' panicked at src/graph/input.rs:493:42:\n",
      "index out of bounds: the len is 1 but the index is 1\n"
     ]
    },
    {
     "ename": "PanicException",
     "evalue": "index out of bounds: the len is 1 but the index is 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPanicException\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 68\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m     59\u001b[0m             val,\n\u001b[1;32m     60\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mw\n\u001b[1;32m     61\u001b[0m         )\n\u001b[1;32m     63\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m     64\u001b[0m             torch\u001b[39m.\u001b[39msum((X_where_T \u001b[39m@\u001b[39m X_one_where \u001b[39m@\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mw \u001b[39m-\u001b[39m X_where_T \u001b[39m@\u001b[39m Y_where)) \u001b[39m<\u001b[39m \u001b[39m0.01\u001b[39m \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39msum(X_where_T \u001b[39m@\u001b[39m Y_where),\n\u001b[1;32m     65\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mw\n\u001b[1;32m     66\u001b[0m         )\n\u001b[0;32m---> 68\u001b[0m prover_gen_settings([x1_vals_path, x2_vals_path, y_vals_path], comb_data_path, prover_model,prover_model_path, [\u001b[39m0\u001b[39;49m], \u001b[39m\"\u001b[39;49m\u001b[39mresources\u001b[39;49m\u001b[39m\"\u001b[39;49m, settings_path)\n",
      "File \u001b[0;32m~/Desktop/zk-stats-lib/core.py:99\u001b[0m, in \u001b[0;36mprover_gen_settings\u001b[0;34m(data_path_array, comb_data_path, prover_model, prover_model_path, scale, mode, settings_path)\u001b[0m\n\u001b[1;32m     97\u001b[0m export_onnx(prover_model, data_tensor_array, prover_model_path)\n\u001b[1;32m     98\u001b[0m \u001b[39m# gen + calibrate setting\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m gen_settings(comb_data_path, prover_model_path, scale, mode, settings_path)\n",
      "File \u001b[0;32m~/Desktop/zk-stats-lib/core.py:60\u001b[0m, in \u001b[0;36mgen_settings\u001b[0;34m(comb_data_path, onnx_filename, scale, mode, settings_filename)\u001b[0m\n\u001b[1;32m     57\u001b[0m   ezkl\u001b[39m.\u001b[39mcalibrate_settings(\n\u001b[1;32m     58\u001b[0m   comb_data_path, onnx_filename, settings_filename, mode)\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m   ezkl\u001b[39m.\u001b[39;49mcalibrate_settings(\n\u001b[1;32m     61\u001b[0m   comb_data_path, onnx_filename, settings_filename, mode, scales \u001b[39m=\u001b[39;49m scale)\n\u001b[1;32m     63\u001b[0m \u001b[39massert\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(settings_filename)\n\u001b[1;32m     64\u001b[0m \u001b[39massert\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(comb_data_path)\n",
      "\u001b[0;31mPanicException\u001b[0m: index out of bounds: the len is 1 but the index is 1"
     ]
    }
   ],
   "source": [
    "# prover calculates settings, send to verifier\n",
    "\n",
    "theory_output = lt20_w_tensor\n",
    "print(\"Theory output: \", theory_output)\n",
    "class prover_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(prover_model, self).__init__()\n",
    "        self.w = nn.Parameter(data = lt20_w_tensor, requires_grad = False)\n",
    "        self.new_Y = nn.Parameter(data = lt20_y_vals_tensor,requires_grad = False )\n",
    "        self.new_X_one = nn.Parameter(data = lt20_x_one_tensor, requires_grad = False)\n",
    "    def forward(self, *args):\n",
    "        # infer Y from the last parameter\n",
    "        Y = args[-1]\n",
    "        # print(\"Y value: \", Y.size())\n",
    "        # print(\"new x1: \", self.new_X_one.size())\n",
    "        len_ratio =  self.new_Y.size()[1]/Y.size()[1]\n",
    "        Y_where = torch.zeros(len_ratio*Y.size()[1], dtype=torch.float64).reshape(1,-1,1)\n",
    "        Y_where[0]=self.new_Y[0]\n",
    "        new_Y_cons = torch.sum((torch.abs(Y[Y<20.0].reshape(1,-1,1)-Y_where)<0.01*torch.abs(Y_where)).double())==Y_where.size()[1] \n",
    "        print(\"y cons: \", new_Y_cons)\n",
    "\n",
    "\n",
    "\n",
    "        X_one_where = torch.zeros(3*len_ratio*Y.size()[1], dtype=torch.float64).reshape(1,Y_where.size()[1],-1)\n",
    "        X_one_where[0] = self.new_X_one[0]\n",
    "\n",
    "        new_X_check = torch.zeros(self.new_X_one.size()[2]-1)\n",
    "        for i in range(self.new_X_one.size()[2]-1):\n",
    "            # print(\"hey: \", self.new_X_one[:,:,i:i+1].size())\n",
    "            # print(\"args: \", args[i][Y<20.0].reshape(1,-1,1).size())\n",
    "            new_X_check[i] = torch.sum(torch.abs(args[i][Y<20.0].reshape(1,-1,1)-X_one_where[:,:,i:i+1])<=0.01*torch.abs(X_one_where[:,:,i:i+1]))==self.new_X_one.size()[1]\n",
    "        new_X_cons = torch.sum(new_X_check) == self.new_X_one.size()[2]-1\n",
    "        print(\"bool sum cons: \", new_X_cons)\n",
    "        \n",
    "    \n",
    "        X_where_T = torch.transpose(X_one_where, 1,2)\n",
    "\n",
    "        X_one = torch.cat((*args[:-1], torch.ones_like(args[0][:, :, -1:])), dim=2)\n",
    "        X_T = torch.transpose(X_one, 1, 2)\n",
    "\n",
    "        # bool_result = torch.sum(X_where_T @ Y_where)>3\n",
    "        bool_result = torch.sum(X_where_T@Y_where)>3\n",
    "        print(\"bool result: \",bool_result)\n",
    "\n",
    "        # if (torch.sum(torch.abs(X_where_T @ X_one_where @ self.w - X_where_T @ Y_where)) < 0.01 * torch.sum(X_where_T @ Y_where)):\n",
    "        #     value = torch.tensor(1)\n",
    "        # else:\n",
    "        #     value = torch.tensor(0)\n",
    "\n",
    "        # if torch.logical_and(new_Y_cons, new_X_cons):\n",
    "        #     final_val = torch.tensor(bool_result)\n",
    "        # else: \n",
    "        #     final_val = torch.tensor(0)\n",
    "        if torch.logical_and(new_X_cons, new_Y_cons):\n",
    "            val = torch.sum((X_where_T @ Y_where)) >100\n",
    "        else:\n",
    "            val = torch.tensor(0)\n",
    "        return (\n",
    "            val,\n",
    "            self.w\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            torch.sum((X_where_T @ X_one_where @ self.w - X_where_T @ Y_where)) < 0.01 * torch.sum(X_where_T @ Y_where),\n",
    "            self.w\n",
    "        )\n",
    "\n",
    "prover_gen_settings([x1_vals_path, x2_vals_path, y_vals_path], comb_data_path, prover_model,prover_model_path, [0], \"resources\", settings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== setting up ezkl ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n",
      "spawning module 2\n",
      "spawning module 0\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time setup: 3.1073861122131348 seconds\n",
      "=======================================\n",
      "Theory output:  tensor([[[1.9884],\n",
      "         [3.1424],\n",
      "         [0.0641]]], dtype=torch.float64)\n",
      "==== Generating Witness ====\n",
      "witness boolean:  1.0\n",
      "witness result 1 : 2.0\n",
      "witness result 2 : 3.0\n",
      "witness result 3 : 0.0\n",
      "==== Generating Proof ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proof:  {'instances': [[[6145674602038562713, 11796601694033167407, 3132644448460071153, 1431119980703310933], [17187590983289934876, 11857991285122296962, 971807162298867662, 379283799527326290], [3957842973089931008, 9845595232537184463, 786695466761881781, 2995319695946854765], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287], [6425625360762666998, 7924344314350639699, 14762033076929465436, 2023505479389396574], [415066004289224689, 11886516471525959549, 3696305541684646538, 3035258219084094862], [0, 0, 0, 0]]], 'proof': '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', 'transcript_type': 'EVM'}\n",
      "Time gen prf: 3.75943922996521 seconds\n"
     ]
    }
   ],
   "source": [
    "# Here verifier & prover can concurrently call setup since all params are public to get pk. \n",
    "# Here write as verifier function to emphasize that verifier must calculate its own vk to be sure\n",
    "verifier_setup(verifier_model_path, verifier_compiled_model_path, settings_path, srs_path,vk_path, pk_path )\n",
    "\n",
    "print(\"=======================================\")\n",
    "# Prover generates proof\n",
    "print(\"Theory output: \", theory_output)\n",
    "prover_gen_proof(prover_model_path, comb_data_path, witness_path, prover_compiled_model_path, settings_path, proof_path, pk_path, srs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_inputs:  3\n",
      "prf instances:  [[[6145674602038562713, 11796601694033167407, 3132644448460071153, 1431119980703310933], [17187590983289934876, 11857991285122296962, 971807162298867662, 379283799527326290], [3957842973089931008, 9845595232537184463, 786695466761881781, 2995319695946854765], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287], [6425625360762666998, 7924344314350639699, 14762033076929465436, 2023505479389396574], [415066004289224689, 11886516471525959549, 3696305541684646538, 3035258219084094862], [0, 0, 0, 0]]]\n",
      "proof boolean:  1.0\n",
      "proof result 1 : 2.0\n",
      "proof result 2 : 3.0\n",
      "proof result 3 : 0.0\n",
      "verified\n"
     ]
    }
   ],
   "source": [
    "verifier_verify(proof_path, settings_path, vk_path, srs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
