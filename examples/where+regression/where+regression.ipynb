{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ezkl==5.0.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 1)) (5.0.8)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 2)) (2.1.1)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 3)) (2.31.0)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 4)) (1.11.4)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 5)) (1.26.2)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 6)) (3.8.2)\n",
      "Requirement already satisfied: statistics in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 7)) (1.0.3.5)\n",
      "Requirement already satisfied: onnx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from -r ../../requirements.txt (line 8)) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (4.8.0)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.1.2)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (1.12)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (3.13.1)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch->-r ../../requirements.txt (line 2)) (2023.10.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->-r ../../requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (4.45.1)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (10.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (1.4.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->-r ../../requirements.txt (line 6)) (3.1.1)\n",
      "Requirement already satisfied: docutils>=0.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from statistics->-r ../../requirements.txt (line 7)) (0.20.1)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from onnx->-r ../../requirements.txt (line 8)) (4.25.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jernkun/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.7->matplotlib->-r ../../requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch->-r ../../requirements.txt (line 2)) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy->torch->-r ../../requirements.txt (line 2)) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ezkl\n",
    "import torch\n",
    "from torch import nn\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../../zkstats/core.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init path\n",
    "os.makedirs(os.path.dirname('shared/'), exist_ok=True)\n",
    "os.makedirs(os.path.dirname('prover/'), exist_ok=True)\n",
    "verifier_model_path = os.path.join('shared/verifier.onnx')\n",
    "prover_model_path = os.path.join('prover/prover.onnx')\n",
    "verifier_compiled_model_path = os.path.join('shared/verifier.compiled')\n",
    "prover_compiled_model_path = os.path.join('prover/prover.compiled')\n",
    "pk_path = os.path.join('shared/test.pk')\n",
    "vk_path = os.path.join('shared/test.vk')\n",
    "proof_path = os.path.join('shared/test.pf')\n",
    "settings_path = os.path.join('shared/settings.json')\n",
    "srs_path = os.path.join('shared/kzg.srs')\n",
    "witness_path = os.path.join('prover/witness.json')\n",
    "# this is private to prover since it contains actual data\n",
    "comb_data_path = os.path.join('prover/comb_data.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=======================  ZK-STATS FLOW ======================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_vals_path = os.path.join('x1_vals.json')\n",
    "x2_vals_path = os.path.join('x2_vals.json')\n",
    "dummy_x1_vals_path = os.path.join('shared/dummy_x1_vals.json')\n",
    "dummy_x2_vals_path = os.path.join('shared/dummy_x2_vals.json')\n",
    "\n",
    "x1_vals= np.array(json.loads(open(x1_vals_path, \"r\").read())['input_data'][0])\n",
    "dummy_x1_vals = np.random.uniform(min(x1_vals), max(x1_vals), len(x1_vals))\n",
    "json.dump({\"input_data\":[dummy_x1_vals.tolist()]}, open(dummy_x1_vals_path, 'w'))\n",
    "\n",
    "x2_vals= np.array(json.loads(open(x2_vals_path, \"r\").read())['input_data'][0])\n",
    "dummy_x2_vals = np.random.uniform(min(x2_vals), max(x2_vals), len(x2_vals))\n",
    "json.dump({\"input_data\":[dummy_x2_vals.tolist()]}, open(dummy_x2_vals_path, 'w'))\n",
    "\n",
    "\n",
    "y_vals_path = os.path.join('y_vals.json')\n",
    "dummy_y_vals_path = os.path.join('shared/dummy_y_vals.json')\n",
    "\n",
    "y_vals= np.array(json.loads(open(y_vals_path, \"r\").read())['input_data'][0])\n",
    "dummy_y_vals = np.random.uniform(min(y_vals), max(y_vals), len(y_vals))\n",
    "json.dump({\"input_data\":[dummy_y_vals.tolist()]}, open(dummy_y_vals_path, 'w'))\n",
    "\n",
    "\n",
    "def stacked_x(*args):\n",
    "    result = np.column_stack((*args, np.ones_like(args[0])))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lennn:  36\n",
      "reg fit:  [1.98835287 3.14238058 0.06413647]\n",
      "lt 20 reg fit:  [ 2.12311694  3.43333008 -1.03203902]\n",
      "w tensor:  tensor([[[1.9884],\n",
      "         [3.1424],\n",
      "         [0.0641]]], dtype=torch.float64)\n",
      "w lt20 tensor:  tensor([[[ 2.1231],\n",
      "         [ 3.4333],\n",
      "         [-1.0320]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# where y value > 20.0\n",
    "lt20_y_vals = y_vals[y_vals<20.0]\n",
    "lt20_y_vals_tensor = torch.tensor(lt20_y_vals).reshape(1,-1,1)\n",
    "new_size = torch.tensor(lt20_y_vals_tensor.size()[1])\n",
    "\n",
    "lt20_dummy_y_vals = dummy_y_vals[dummy_y_vals<20.0]\n",
    "print(\"lennn: \", len(lt20_dummy_y_vals))\n",
    "lt20_dummy_y_vals_tensor = torch.tensor(lt20_dummy_y_vals).reshape(1,-1,1)\n",
    "new_dummy_size = torch.tensor(lt20_dummy_y_vals_tensor.size()[1])\n",
    "\n",
    "x_one = stacked_x(x1_vals, x2_vals)\n",
    "lt20_x_one = stacked_x(x1_vals[y_vals<20.0], x2_vals[y_vals<20.0])\n",
    "lt20_x_one_tensor = torch.tensor(lt20_x_one).reshape(1, len(lt20_x_one), -1)\n",
    "\n",
    "\n",
    "dummy_x_one = stacked_x(dummy_x1_vals, dummy_x2_vals)\n",
    "lt20_dummy_x_one = stacked_x(dummy_x1_vals[dummy_y_vals<20.0], dummy_x2_vals[dummy_y_vals<20.0])\n",
    "lt20_dummy_x_one_tensor = torch.tensor(lt20_dummy_x_one).reshape(1, len(lt20_dummy_x_one), -1)\n",
    "\n",
    "w_vals = np.matmul(np.matmul(np.linalg.inv(np.matmul(x_one.transpose(), x_one)), x_one.transpose()), y_vals)\n",
    "lt20_w_vals = np.matmul(np.matmul(np.linalg.inv(np.matmul(lt20_x_one.transpose(), lt20_x_one)), lt20_x_one.transpose()), lt20_y_vals)\n",
    "dummy_w_vals = np.matmul(np.matmul(np.linalg.inv(np.matmul(dummy_x_one.transpose(), dummy_x_one)), dummy_x_one.transpose()), dummy_y_vals)\n",
    "lt20_dummy_w_vals = np.matmul(np.matmul(np.linalg.inv(np.matmul(lt20_dummy_x_one.transpose(), lt20_dummy_x_one)), lt20_dummy_x_one.transpose()), lt20_dummy_y_vals)\n",
    "\n",
    "\n",
    "print(\"reg fit: \", w_vals)\n",
    "print(\"lt 20 reg fit: \", lt20_w_vals)\n",
    "\n",
    "w_tensor = torch.tensor(w_vals).reshape(1,-1,1)\n",
    "print(\"w tensor: \", w_tensor)\n",
    "lt20_w_tensor = torch.tensor(lt20_w_vals).reshape(1,-1,1)\n",
    "print(\"w lt20 tensor: \", lt20_w_tensor)\n",
    "# lt20_x1_vals_tensor = x1_vals[y_vals<20.0].reshape(1,-1,1)\n",
    "# lt20_x2_vals_tensor = x2_vals[y_vals<20.0].reshape(1,-1,1)\n",
    "\n",
    "dummy_w_tensor = torch.tensor(dummy_w_vals).reshape(1,-1,1)\n",
    "lt20_dummy_w_tensor = torch.tensor(lt20_dummy_w_vals).reshape(1,-1,1)\n",
    "# lt20_dummy_x1_vals_tensor = dummy_x1_vals[y_vals<20.0].reshape(1,-1,1)\n",
    "# lt20_dummy_x2_vals_tensor = dummy_x2_vals[y_vals<20.0].reshape(1,-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vall:  tensor(True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/y9dw12v976ngdmqz4l7wbsnr0000gn/T/ipykernel_58286/682255233.py:32: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if torch.logical_and(torch.logical_and(new_X_cons, new_Y_cons), bool_result):\n"
     ]
    }
   ],
   "source": [
    "# Verifier/ data consumer side:\n",
    "# Want to calculate regression of y over \n",
    "class verifier_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(verifier_model, self).__init__()\n",
    "        self.w = nn.Parameter(data = lt20_dummy_w_tensor, requires_grad = False)\n",
    "        # self.new_size = nn.Parameter(data = new_dummy_size,requires_grad = False )\n",
    "        self.new_Y = nn.Parameter(data = lt20_dummy_y_vals_tensor,requires_grad = False )\n",
    "        self.new_X_one = nn.Parameter(data = lt20_dummy_x_one_tensor, requires_grad = False)\n",
    "    def forward(self, *args):\n",
    "        # infer Y from the last parameter\n",
    "        Y = args[-1]\n",
    "        len_ratio =  self.new_Y.size()[1]/Y.size()[1]\n",
    "        Y_where = torch.zeros(1,len_ratio*Y.size()[1],1, dtype=torch.float64)\n",
    "        Y_where[0]=self.new_Y[0]\n",
    "        new_Y_cons = torch.sum((torch.abs(Y[Y<20.0].reshape(1,-1,1)-Y_where)<=0.01*torch.abs(Y_where)).double())==Y_where.size()[1] \n",
    "\n",
    "        # X_one_where = torch.zeros(self.new_X_one.size()[1]*self.new_X_one.size()[2], dtype=torch.float64).reshape(1,Y_where.size()[1],-1)\n",
    "        X_one_where = torch.zeros(1,self.new_X_one.size()[1],self.new_X_one.size()[2], dtype=torch.float64)\n",
    "        X_one_where[0] = self.new_X_one[0]\n",
    "\n",
    "        new_X_check = torch.zeros(self.new_X_one.size()[2]-1)\n",
    "        for i in range(self.new_X_one.size()[2]-1):\n",
    "            new_X_check[i] = torch.sum(torch.abs(args[i][Y<20.0].reshape(1,-1,1)-X_one_where[:,:,i:i+1])<=torch.abs(0.01*X_one_where[:,:,i:i+1]))==self.new_X_one.size()[1]\n",
    "        new_X_cons = torch.sum(new_X_check) == self.new_X_one.size()[2]-1\n",
    "\n",
    "        \n",
    "        X_where_T = torch.transpose(X_one_where, 1,2)\n",
    "        bool_result = torch.sum(torch.abs(X_where_T @ X_one_where @ self.w - X_where_T @ Y_where)) <= 0.01 * torch.sum(torch.abs(X_where_T @ Y_where))\n",
    "\n",
    "\n",
    "        if torch.logical_and(torch.logical_and(new_X_cons, new_Y_cons), bool_result):\n",
    "            X_one = torch.cat((*args[:-1], torch.ones_like(args[0][:, :, -1:])), dim=2)\n",
    "            X_T = torch.transpose(X_one, 1, 2)\n",
    "            val = torch.sum(X_T@Y) == torch.sum(X_T@Y)\n",
    "        else:\n",
    "            val = torch.tensor(0)\n",
    "            # X_one = torch.cat((*args[:-1], torch.ones_like(args[0][:, :, -1:])), dim=2)\n",
    "            # X_T = torch.transpose(X_one, 1, 2)\n",
    "            # val = torch.sum(X_T@Y) == torch.sum(X_T@Y)\n",
    "        print(\"vall: \", val)\n",
    "        return (\n",
    "            val,\n",
    "            self.w\n",
    "        )\n",
    "\n",
    "verifier_define_calculation(verifier_model, verifier_model_path, [dummy_x1_vals_path, dummy_x2_vals_path, dummy_y_vals_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theory output:  tensor([[[ 2.1231],\n",
      "         [ 3.4333],\n",
      "         [-1.0320]]], dtype=torch.float64)\n",
      "vall:  tensor(True)\n",
      "==== Generate & Calibrate Setting ====\n",
      "scale:  [0]\n",
      "setting:  {\"run_args\":{\"tolerance\":{\"val\":0.0,\"scale\":1.0},\"input_scale\":0,\"param_scale\":0,\"scale_rebase_multiplier\":10,\"lookup_range\":[0,0],\"logrows\":14,\"num_inner_cols\":1,\"variables\":[[\"batch_size\",1]],\"input_visibility\":{\"Hashed\":{\"hash_is_public\":true,\"outlets\":[]}},\"output_visibility\":\"Public\",\"param_visibility\":\"Private\"},\"num_rows\":11808,\"total_assignments\":309,\"total_const_size\":0,\"model_instance_shapes\":[[1],[1,3,1]],\"model_output_scales\":[0,0],\"model_input_scales\":[0,0,0],\"module_sizes\":{\"kzg\":[],\"poseidon\":[11808,[3]],\"elgamal\":[0,[0]]},\"required_lookups\":[\"KroneckerDelta\"],\"check_mode\":\"UNSAFE\",\"version\":\"5.0.8\",\"num_blinding_factors\":null}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/y9dw12v976ngdmqz4l7wbsnr0000gn/T/ipykernel_58286/1291119568.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if torch.logical_and(torch.logical_and(new_X_cons, new_Y_cons), bool_result):\n"
     ]
    }
   ],
   "source": [
    "# prover calculates settings, send to verifier\n",
    "\n",
    "theory_output = lt20_w_tensor\n",
    "print(\"Theory output: \", theory_output)\n",
    "class prover_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(prover_model, self).__init__()\n",
    "        self.w = nn.Parameter(data = lt20_w_tensor, requires_grad = False)\n",
    "        self.new_Y = nn.Parameter(data = lt20_y_vals_tensor,requires_grad = False )\n",
    "        self.new_X_one = nn.Parameter(data = lt20_x_one_tensor, requires_grad = False)\n",
    "    def forward(self, *args):\n",
    "        # infer Y from the last parameter\n",
    "        Y = args[-1]\n",
    "        len_ratio =  self.new_Y.size()[1]/Y.size()[1]\n",
    "        Y_where = torch.zeros(1,len_ratio*Y.size()[1],1, dtype=torch.float64)\n",
    "        Y_where[0]=self.new_Y[0]\n",
    "        new_Y_cons = torch.sum((torch.abs(Y[Y<20.0].reshape(1,-1,1)-Y_where)<=0.01*torch.abs(Y_where)).double())==Y_where.size()[1] \n",
    "\n",
    "        # X_one_where = torch.zeros(self.new_X_one.size()[1]*self.new_X_one.size()[2], dtype=torch.float64).reshape(1,Y_where.size()[1],-1)\n",
    "        # X_one_where = torch.zeros(1,self.new_X_one.size()[1],self.new_X_one.size()[2], dtype=torch.float64)\n",
    "        X_one_where = (self.new_X_one).clone()\n",
    "        # X_one_where[0] = self.new_X_one[0]\n",
    "\n",
    "        new_X_check = torch.zeros(self.new_X_one.size()[2]-1)\n",
    "        for i in range(self.new_X_one.size()[2]-1):\n",
    "            new_X_check[i] = torch.sum(torch.abs(args[i][Y<20.0].reshape(1,-1,1)-self.new_X_one[:,:,i:i+1])<=torch.abs(0.01*self.new_X_one[:,:,i:i+1]))==self.new_X_one.size()[1]\n",
    "        new_X_cons = torch.sum(new_X_check) == self.new_X_one.size()[2]-1\n",
    "\n",
    "        \n",
    "        X_where_T = torch.transpose(self.new_X_one, 1,2)\n",
    "        bool_result = torch.sum(torch.abs(X_where_T @ self.new_X_one @ self.w - X_where_T @ Y_where)) <= 0.01 * torch.sum(torch.abs(X_where_T @ Y_where))\n",
    "\n",
    "\n",
    "        if torch.logical_and(torch.logical_and(new_X_cons, new_Y_cons), bool_result):\n",
    "            X_one = torch.cat((*args[:-1], torch.ones_like(args[0][:, :, -1:])), dim=2)\n",
    "            X_T = torch.transpose(X_one, 1, 2)\n",
    "            val = torch.sum(X_T@Y) == torch.sum(X_T@Y)\n",
    "        else:\n",
    "            val = torch.tensor(0)\n",
    "            # X_one = torch.cat((*args[:-1], torch.ones_like(args[0][:, :, -1:])), dim=2)\n",
    "            # X_T = torch.transpose(X_one, 1, 2)\n",
    "            # val = torch.sum(X_T@Y) == torch.sum(X_T@Y)\n",
    "        print(\"vall: \", val)\n",
    "        return (\n",
    "            val,\n",
    "            self.w\n",
    "        )\n",
    "\n",
    "\n",
    "prover_gen_settings([x1_vals_path, x2_vals_path, y_vals_path], comb_data_path, prover_model,prover_model_path, [0], \"resources\", settings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== setting up ezkl ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 2\n",
      "spawning module 0\n",
      "spawning module 2\n",
      "spawning module 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time setup: 1.2904880046844482 seconds\n",
      "=======================================\n",
      "Theory output:  tensor([[[ 2.1231],\n",
      "         [ 3.4333],\n",
      "         [-1.0320]]], dtype=torch.float64)\n",
      "==== Generating Witness ====\n",
      "witness boolean:  1.0\n",
      "witness result 1 : 2.0\n",
      "witness result 2 : 3.0\n",
      "witness result 3 : -1.0\n",
      "==== Generating Proof ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proof:  {'instances': [[[6145674602038562713, 11796601694033167407, 3132644448460071153, 1431119980703310933], [17187590983289934876, 11857991285122296962, 971807162298867662, 379283799527326290], [3957842973089931008, 9845595232537184463, 786695466761881781, 2995319695946854765], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287], [6425625360762666998, 7924344314350639699, 14762033076929465436, 2023505479389396574], [415066004289224689, 11886516471525959549, 3696305541684646538, 3035258219084094862], [10902020042510041094, 17381486299841078119, 5900175412809962030, 2475245527108272378]]], 'proof': '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', 'transcript_type': 'EVM'}\n",
      "Time gen prf: 1.7250189781188965 seconds\n"
     ]
    }
   ],
   "source": [
    "# Here verifier & prover can concurrently call setup since all params are public to get pk. \n",
    "# Here write as verifier function to emphasize that verifier must calculate its own vk to be sure\n",
    "verifier_setup(verifier_model_path, verifier_compiled_model_path, settings_path, srs_path,vk_path, pk_path )\n",
    "\n",
    "print(\"=======================================\")\n",
    "# Prover generates proof\n",
    "print(\"Theory output: \", theory_output)\n",
    "prover_gen_proof(prover_model_path, comb_data_path, witness_path, prover_compiled_model_path, settings_path, proof_path, pk_path, srs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_inputs:  3\n",
      "prf instances:  [[[6145674602038562713, 11796601694033167407, 3132644448460071153, 1431119980703310933], [17187590983289934876, 11857991285122296962, 971807162298867662, 379283799527326290], [3957842973089931008, 9845595232537184463, 786695466761881781, 2995319695946854765], [12436184717236109307, 3962172157175319849, 7381016538464732718, 1011752739694698287], [6425625360762666998, 7924344314350639699, 14762033076929465436, 2023505479389396574], [415066004289224689, 11886516471525959549, 3696305541684646538, 3035258219084094862], [10902020042510041094, 17381486299841078119, 5900175412809962030, 2475245527108272378]]]\n",
      "proof boolean:  1.0\n",
      "proof result 1 : 2.0\n",
      "proof result 2 : 3.0\n",
      "proof result 3 : -1.0\n",
      "verified\n"
     ]
    }
   ],
   "source": [
    "verifier_verify(proof_path, settings_path, vk_path, srs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
