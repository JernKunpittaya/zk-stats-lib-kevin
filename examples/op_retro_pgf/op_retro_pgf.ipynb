{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_amount = 30_000_000\n",
    "min_quorum = 2\n",
    "# min_payout_per_project = 1500\n",
    "min_payout_per_project = 3_000_000\n",
    "\n",
    "# NOTE: votes is a matrix\n",
    "# projects: 0, 1, 2, 3, 4\n",
    "# voter 0:  3, 1, 5, 0, 0\n",
    "# voter 1:  2, 0, 8, 3, 1\n",
    "# voter 2:  1, 1, 2, 4, 0\n",
    "votes = torch.tensor([\n",
    "    [3, 1, 5, 0, 0],\n",
    "    [2, 0, 8, 3, 1],\n",
    "    [1, 1, 2, 4, 0],\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Filter out projects that receives less than `min_quorum` votes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_voters=tensor([3, 2, 3, 2, 1])\n",
      "projects_meet_quorum=tensor([ True,  True,  True,  True, False])\n",
      "filtered_votes=tensor([[3, 1, 5, 0, 0],\n",
      "        [2, 0, 8, 3, 0],\n",
      "        [1, 1, 2, 4, 0]])\n"
     ]
    }
   ],
   "source": [
    "project_voters = torch.sum(votes > 0, dim=0)\n",
    "projects_meet_quorum = project_voters >= min_quorum\n",
    "filtered_votes = votes.clone()\n",
    "filtered_votes[:, ~projects_meet_quorum] = 0\n",
    "print(f\"{project_voters=}\")\n",
    "print(f\"{projects_meet_quorum=}\")\n",
    "print(f\"{filtered_votes=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Calculate results based on median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medians=tensor([2., 1., 5., 3., 0.])\n"
     ]
    }
   ],
   "source": [
    "medians = torch.median(filtered_votes.float(), dim=0).values\n",
    "print(f\"{medians=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Scale project payouts to sum up to 30m OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled payouts: tensor([ 5454545.5000,  2727272.7500, 13636364.0000,  8181818.5000,\n",
      "               0.0000])\n"
     ]
    }
   ],
   "source": [
    "# 3. Scale project payouts to sum up to 30m OP\n",
    "total_medians = torch.sum(medians)\n",
    "proportions_1 = medians.float() / total_medians\n",
    "scaled_payouts_1 = proportions_1 * total_amount\n",
    "print(\"Scaled payouts:\", scaled_payouts_1)\n",
    "sum_after_scaling = int(torch.sum(scaled_payouts_1))\n",
    "assert sum_after_scaling == total_amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Filter out all projects which received below `min_payout_per_project` votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "above_payout_threshold=tensor([ True, False,  True,  True, False])\n",
      "Payouts: tensor([ 5454545.5000,        0.0000, 13636364.0000,  8181818.5000,\n",
      "               0.0000])\n"
     ]
    }
   ],
   "source": [
    "above_payout_threshold = scaled_payouts_1 >= min_payout_per_project\n",
    "print(f\"{above_payout_threshold=}\")\n",
    "payouts = scaled_payouts_1.clone()\n",
    "payouts[~above_payout_threshold] = 0\n",
    "print(\"Payouts:\", payouts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Scale project payouts to sum up to 30m OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled payouts: tensor([ 6000000.,        0., 15000000.,  9000000.,        0.])\n"
     ]
    }
   ],
   "source": [
    "total_payout = torch.sum(payouts)\n",
    "proportions_2 = payouts.float() / total_payout\n",
    "scaled_payouts_2 = proportions_2 * total_amount\n",
    "print(\"Scaled payouts:\", scaled_payouts_2)\n",
    "sum_after_scaling = int(torch.sum(scaled_payouts_2))\n",
    "assert sum_after_scaling == total_amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, try to run it with `ezkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape =  torch.Size([1, 15, 1])\n",
      "matrix =  tensor([[3., 1., 5., 0., 0.],\n",
      "        [2., 0., 8., 3., 1.],\n",
      "        [1., 1., 2., 4., 0.]])\n",
      "matrix.shape =  torch.Size([3, 5])\n",
      "sum X =  tensor(31.)\n",
      "sum matrix =  tensor([ 6.,  2., 15.,  7.,  1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t3/5psrvr1x0w1_6n9kx2n7d9700000gn/T/ipykernel_93030/829802075.py:92: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  return (torch.tensor(1), project_voters)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from torch import nn\n",
    "\n",
    "from zkstats.core import (\n",
    "    gen_settings,\n",
    "    verifier_setup,\n",
    "    prover_setup,\n",
    "    prover_gen_proof,\n",
    "    verifier_verify,\n",
    ")\n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "output_dir = f\"{cwd}/out\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "model_onnx_path = f\"{output_dir}/model.onnx\"\n",
    "compiled_model_path = f\"{output_dir}/model.compiled\"\n",
    "pk_path = f\"{output_dir}/model.pk\"\n",
    "vk_path = f\"{output_dir}/model.vk\"\n",
    "proof_path = f\"{output_dir}/model.pf\"\n",
    "settings_path = f\"{output_dir}/settings.json\"\n",
    "srs_path = f\"{output_dir}/kzg.srs\"\n",
    "witness_path = f\"{output_dir}/witness.json\"\n",
    "comb_data_path = f\"{output_dir}/comb_data.json\"\n",
    "\n",
    "# data tensor\n",
    "# NOTE: Can we pass `data_tensor` as the matrix as above?\n",
    "data = [3.0, 1.0, 5.0, 0.0, 0.0, 2.0, 0.0, 8.0, 3.0, 1.0, 1.0, 1.0, 2.0, 4.0, 0.0]\n",
    "data_tensor = torch.tensor(data)\n",
    "data_tensor_1 = torch.reshape(torch.tensor(data),(1, len(data), 1))\n",
    "comb_data = [data_tensor.tolist()]\n",
    "with open(comb_data_path, 'w') as f:\n",
    "    json.dump(dict(input_data = comb_data), f)\n",
    "data_tensor_array = [data_tensor_1]\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # # some expression of tolerance to error in the inference\n",
    "        # return filtered_votes\n",
    "        # X is (1, 15, 1)\n",
    "        print(\"x.shape = \", x.shape)\n",
    "        # Y is (1, 15)\n",
    "        matrix = x.reshape(-1, 5)\n",
    "        print(\"matrix = \", matrix)\n",
    "        print(\"matrix.shape = \", matrix.shape)\n",
    "        print(\"sum X = \", torch.sum(x))\n",
    "        sum_matrix = torch.sum(matrix, dim=0)\n",
    "        print(\"sum matrix = \", sum_matrix)\n",
    "\n",
    "        votes = matrix\n",
    "        # 1.\n",
    "        project_voters = torch.sum(votes > 0, dim=0)\n",
    "        # projects_meet_quorum = project_voters >= min_quorum\n",
    "        # filtered_votes = votes.clone()\n",
    "        # filtered_votes[:, ~projects_meet_quorum] = 0\n",
    "        # print(f\"{project_voters=}\")\n",
    "        # print(f\"{projects_meet_quorum=}\")\n",
    "        # print(f\"{filtered_votes=}\")\n",
    "\n",
    "        # # 2.\n",
    "        # medians = torch.mean(filtered_votes.float(), dim=0)\n",
    "        # print(f\"{medians=}\")\n",
    "\n",
    "        # # 3. Scale project payouts to sum up to 30m OP\n",
    "        # total_medians = torch.sum(medians)\n",
    "        # proportions_1 = medians.float() / total_medians\n",
    "        # scaled_payouts_1 = proportions_1 * total_amount\n",
    "        # print(\"Scaled payouts:\", scaled_payouts_1)\n",
    "        # # 4. Filter out all projects which received below `min_payout_per_project` votes\n",
    "        # above_payout_threshold = scaled_payouts_1 >= min_payout_per_project\n",
    "        # print(f\"{above_payout_threshold=}\")\n",
    "        # payouts = scaled_payouts_1.clone()\n",
    "        # payouts[~above_payout_threshold] = 0\n",
    "        # # 5. Scale project payouts to sum up to 30m OP\n",
    "        # total_payout = torch.sum(payouts)\n",
    "        # proportions_2 = payouts.float() / total_payout\n",
    "        # scaled_payouts_2 = proportions_2 * total_amount\n",
    "\n",
    "        # print(\"scaled_payouts_2 = \", scaled_payouts_2)\n",
    "\n",
    "        return (torch.tensor(1), project_voters)\n",
    "\n",
    "        # return (torch.tensor(1), torch.mean(X))\n",
    "\n",
    "\n",
    "# export_onnx\n",
    "circuit = Model()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "circuit.to(device)\n",
    "circuit.eval()\n",
    "input_names = []\n",
    "dynamic_axes = {}\n",
    "\n",
    "data_tensor_tuple = ()\n",
    "for i in range(len(data_tensor_array)):\n",
    "    data_tensor_tuple += (data_tensor_array[i],)\n",
    "    input_index = \"input\"+str(i+1)\n",
    "    input_names.append(input_index)\n",
    "    dynamic_axes[input_index] = {0 : 'batch_size'}\n",
    "    dynamic_axes[\"output\"] = {0 : 'batch_size'}\n",
    "\n",
    "torch.onnx.export(\n",
    "    circuit,               # model being run\n",
    "    data_tensor_tuple,                   # model input (or a tuple for multiple inputs)\n",
    "    model_onnx_path,            # where to save the model (can be a file or file-like object)\n",
    "    export_params=True,        # store the trained parameter weights inside the model file\n",
    "    opset_version=11,          # the ONNX version to export the model to\n",
    "    do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "    input_names = input_names,   # the model's input names\n",
    "    output_names = ['output'], # the model's output names\n",
    "    dynamic_axes=dynamic_axes\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Generate & Calibrate Setting ====\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to generate settings: Translating node #7 \"/ReduceSum\" Reduce<Sum> ToTypedTranslator",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/mhchia/projects/work/pse/zk-stats-lib/examples/op_retro_pgf/op_retro_pgf.ipynb Cell 15\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mhchia/projects/work/pse/zk-stats-lib/examples/op_retro_pgf/op_retro_pgf.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m scale \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mhchia/projects/work/pse/zk-stats-lib/examples/op_retro_pgf/op_retro_pgf.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mresources\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mhchia/projects/work/pse/zk-stats-lib/examples/op_retro_pgf/op_retro_pgf.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m gen_settings(comb_data_path, model_onnx_path, scale, mode, settings_path)\n",
      "File \u001b[0;32m~/projects/work/pse/zk-stats-lib/zkstats/core.py:86\u001b[0m, in \u001b[0;36mgen_settings\u001b[0;34m(comb_data_path, onnx_filename, scale, mode, settings_filename)\u001b[0m\n\u001b[1;32m     83\u001b[0m  gip_run_args\u001b[39m.\u001b[39mparam_visibility \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mprivate\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m# should be Tensor(True)--> to enforce arbitrary data in w\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[39m# generate settings\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m  ezkl\u001b[39m.\u001b[39;49mgen_settings(onnx_filename, settings_filename, py_run_args\u001b[39m=\u001b[39;49mgip_run_args)\n\u001b[1;32m     87\u001b[0m  \u001b[39mif\u001b[39;00m scale \u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     88\u001b[0m    ezkl\u001b[39m.\u001b[39mcalibrate_settings(\n\u001b[1;32m     89\u001b[0m    comb_data_path, onnx_filename, settings_filename, mode)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to generate settings: Translating node #7 \"/ReduceSum\" Reduce<Sum> ToTypedTranslator"
     ]
    }
   ],
   "source": [
    "\n",
    "scale = \"default\"\n",
    "mode = \"resources\"\n",
    "gen_settings(comb_data_path, model_onnx_path, scale, mode, settings_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verifier_setup(model_onnx_path, compiled_model_path, settings_path, srs_path, vk_path, pk_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prover_gen_proof(model_onnx_path, comb_data_path, witness_path, compiled_model_path, settings_path, proof_path, pk_path, srs_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verifier_verify(proof_path, settings_path, vk_path, srs_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
